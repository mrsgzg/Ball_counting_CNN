#!/usr/bin/env python
"""
ä¿®å¤äº†JSONåºåˆ—åŒ–é—®é¢˜çš„JointPCAè¿è¡Œè„šæœ¬
"""

import argparse
import os
import sys
import numpy as np
from datetime import datetime

# ç¡®ä¿èƒ½æ‰¾åˆ°ä½ çš„æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def numpy_to_python(obj):
    """é€’å½’è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹"""
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):
        return float(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, dict):
        return {k: numpy_to_python(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [numpy_to_python(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(numpy_to_python(item) for item in obj)
    else:
        return obj

def main():
    parser = argparse.ArgumentParser(description='JointPCAåˆ†æï¼ˆä¿®å¤ç‰ˆï¼‰')
    
    parser.add_argument('--checkpoint', type=str, required=True,
                       help='æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--val_csv', type=str,
                       default='scratch/Ball_counting_CNN/Tools_script/ball_dynamic_val.csv',
                       help='éªŒè¯é›†CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--data_root', type=str, 
                       default='/mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/Ball_counting_CNN/ball_data_collection',
                       help='æ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--num_samples_per_label', type=int, default=5,
                       help='æ¯ä¸ªæ ‡ç­¾çš„æ ·æœ¬æ•°')
    parser.add_argument('--save_dir', type=str, default='./jointpca_analysis_fixed',
                       help='ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--quick_mode', action='store_true',
                       help='å¿«é€Ÿæ¨¡å¼ï¼šåªæ”¶é›†LSTMè½¨è¿¹ï¼Œä¸ç”Ÿæˆå•æ ·æœ¬å¯è§†åŒ–')
    
    args = parser.parse_args()
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_dir = os.path.join(args.save_dir, f'analysis_{timestamp}')
    os.makedirs(save_dir, exist_ok=True)
    
    print("ğŸ¯ JointPCAåˆ†æï¼ˆä¿®å¤ç‰ˆï¼‰")
    print("="*50)
    print(f"æ¨¡å‹: {args.checkpoint}")
    print(f"æ¯ä¸ªæ ‡ç­¾æ ·æœ¬æ•°: {args.num_samples_per_label}")
    print(f"ä¿å­˜ç›®å½•: {save_dir}")
    print(f"æ¨¡å¼: {'å¿«é€Ÿ' if args.quick_mode else 'å®Œæ•´'}")
    print("="*50)
    
    try:
        # æ ¹æ®æ˜¯å¦å·²ç»ä¿®å¤äº†LSTM_Attention_Viz_JPCA.pyæ¥é€‰æ‹©å¯¼å…¥
        try:
            # å°è¯•å¯¼å…¥ä¿®å¤åçš„ç‰ˆæœ¬
            from LSTM_Attention_Viz_JPCA import UniversalModelVisualizer, load_model_and_data
        except ImportError:
            print("âš ï¸ ä½¿ç”¨åŸå§‹ç‰ˆæœ¬ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨ä¿®å¤JSONåºåˆ—åŒ–")
            from Universal_LSTM_Viz_with_JointPCA import UniversalModelVisualizer, load_model_and_data
        
        from DataLoader_embodiment import BallCountingDataset
        
        # åŠ è½½æ¨¡å‹å’Œæ•°æ®
        print("\nğŸ“¥ åŠ è½½æ¨¡å‹å’Œæ•°æ®...")
        model, dataset, device, config = load_model_and_data(
            args.checkpoint, args.val_csv, args.data_root
        )
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = UniversalModelVisualizer(model, device)
        
        # å‡†å¤‡å¹³è¡¡çš„æ ·æœ¬é›†
        print("\nğŸ“Š å‡†å¤‡å¹³è¡¡çš„æ ·æœ¬é›†...")
        samples_by_label = {i: [] for i in range(1, 11)}
        
        # æ”¶é›†æ¯ä¸ªæ ‡ç­¾çš„æ ·æœ¬ç´¢å¼•
        for idx in range(len(dataset)):
            sample = dataset[idx]
            label = sample['label'].item()
            if label in samples_by_label and len(samples_by_label[label]) < args.num_samples_per_label:
                samples_by_label[label].append(idx)
        
        # é€‰æ‹©è¦åˆ†æçš„æ ·æœ¬
        selected_indices = []
        label_counts = {}
        for label in sorted(samples_by_label.keys()):
            indices = samples_by_label[label][:args.num_samples_per_label]
            selected_indices.extend(indices)
            label_counts[label] = len(indices)
            print(f"  æ ‡ç­¾ {label}: {len(indices)} ä¸ªæ ·æœ¬")
        
        print(f"\næ€»è®¡: {len(selected_indices)} ä¸ªæ ·æœ¬")
        
        if args.quick_mode:
            # å¿«é€Ÿæ¨¡å¼ï¼šåªæ”¶é›†LSTMè½¨è¿¹
            print("\nğŸš€ å¿«é€Ÿæ¨¡å¼ï¼šåªæ”¶é›†LSTMè½¨è¿¹...")
            for i, idx in enumerate(selected_indices):
                if i % 10 == 0:
                    print(f"  è¿›åº¦: {i}/{len(selected_indices)}")
                
                sample_data = dataset[idx]
                
                # å‡†å¤‡åºåˆ—æ•°æ®
                sequence_data = {
                    'images': sample_data['sequence_data']['images'].unsqueeze(0).to(device),
                    'joints': sample_data['sequence_data']['joints'].unsqueeze(0).to(device),
                    'timestamps': sample_data['sequence_data']['timestamps'].unsqueeze(0).to(device),
                    'labels': sample_data['sequence_data']['labels'].unsqueeze(0).to(device)
                }
                
                # è·å–æ¨¡å‹è¾“å‡º
                visualizer._prepare_model_for_visualization()
                outputs = visualizer._get_model_outputs(sequence_data)
                viz_data = visualizer._extract_visualization_data(outputs)
                
                # æ”¶é›†LSTMè½¨è¿¹
                if viz_data['lstm_states']:
                    true_label = sample_data['label'].item()
                    visualizer.collected_lstm_trajectories[(true_label, idx)] = viz_data['lstm_states']
        else:
            # å®Œæ•´æ¨¡å¼ï¼šç”Ÿæˆæ¯ä¸ªæ ·æœ¬çš„å¯è§†åŒ–
            print("\nğŸ¨ å®Œæ•´æ¨¡å¼ï¼šç”Ÿæˆå•æ ·æœ¬å¯è§†åŒ–å¹¶æ”¶é›†è½¨è¿¹...")
            for i, idx in enumerate(selected_indices):
                print(f"  å¤„ç†æ ·æœ¬ {i+1}/{len(selected_indices)} (ç´¢å¼•: {idx})")
                sample_data = dataset[idx]
                visualizer.visualize_sample_sequence(sample_data, idx, save_dir, 
                                                   collect_for_joint_pca=True)
        
        print(f"\nâœ… æ”¶é›†äº† {len(visualizer.collected_lstm_trajectories)} ä¸ªè½¨è¿¹")
        
        # æ‰§è¡ŒJointPCAåˆ†æ
        print("\nğŸ¨ æ‰§è¡ŒJointPCAåˆ†æ...")
        
        # å¦‚æœåŸå§‹è„šæœ¬æ²¡æœ‰ä¿®å¤ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œæ•è·é”™è¯¯å¹¶æ‰‹åŠ¨å¤„ç†
        try:
            analyzer = visualizer.perform_joint_pca_analysis(save_dir)
        except TypeError as e:
            if "JSON serializable" in str(e):
                print("âš ï¸ æ£€æµ‹åˆ°JSONåºåˆ—åŒ–é”™è¯¯ï¼Œå°è¯•æ‰‹åŠ¨ä¿®å¤...")
                
                # æ‰‹åŠ¨æ‰§è¡Œåˆ†æçš„æ ¸å¿ƒéƒ¨åˆ†
                from circular_dynamics_analysis import CircularDynamicsAnalyzer
                
                analyzer = CircularDynamicsAnalyzer()
                
                # æ·»åŠ è½¨è¿¹
                for (label, sample_id), lstm_states in visualizer.collected_lstm_trajectories.items():
                    analyzer.add_trajectory(lstm_states, label, sample_id)
                
                # æ‰§è¡Œåˆ†æ
                analyzer.compute_joint_pca(n_components=3)
                patterns = analyzer.detect_rotation_patterns(min_circularity=0.5)
                
                # åˆ›å»ºå¯è§†åŒ–
                joint_pca_dir = os.path.join(save_dir, 'joint_pca_analysis')
                os.makedirs(joint_pca_dir, exist_ok=True)
                
                analyzer.plot_joint_trajectories(
                    save_path=os.path.join(joint_pca_dir, 'joint_pca_trajectories.png')
                )
                
                analyzer.plot_circular_analysis(
                    save_path=os.path.join(joint_pca_dir, 'circular_patterns.png')
                )
                
                analyzer.plot_rotation_metrics_summary(
                    save_path=os.path.join(joint_pca_dir, 'rotation_metrics_summary.png')
                )
                
                print("âœ… æ‰‹åŠ¨ä¿®å¤æˆåŠŸï¼Œå¯è§†åŒ–å·²ç”Ÿæˆ")
            else:
                raise e
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        if 'analyzer' in locals() and analyzer:
            circular_count = sum(1 for p in analyzer.analysis_results['rotation_patterns'] 
                               if p['is_circular'])
            total_count = len(analyzer.analysis_results['rotation_patterns'])
            
            print(f"\nğŸ“Š åˆ†æç»“æœ:")
            print(f"  â€¢ æ€»è½¨è¿¹æ•°: {total_count}")
            print(f"  â€¢ ç¯å½¢è½¨è¿¹: {circular_count} ({circular_count/total_count*100:.1f}%)")
            print(f"  â€¢ PCAè§£é‡Šæ–¹å·®: {analyzer.analysis_results['joint_pca']['total_variance']:.1%}")
        
        print("\nğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {save_dir}")
        if os.path.exists(os.path.join(save_dir, 'joint_pca_analysis')):
            print("ğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
            print("  â€¢ joint_pca_trajectories.png - è·¨æ ·æœ¬è½¨è¿¹å¯è§†åŒ–")
            print("  â€¢ circular_patterns.png - æ£€æµ‹åˆ°çš„ç¯å½¢æ¨¡å¼")
            print("  â€¢ rotation_metrics_summary.png - æ—‹è½¬æŒ‡æ ‡æ±‡æ€»")
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        # å°è¯•ä¿å­˜å·²æ”¶é›†çš„æ•°æ®
        if 'visualizer' in locals() and hasattr(visualizer, 'collected_lstm_trajectories'):
            import pickle
            backup_path = os.path.join(save_dir, 'lstm_trajectories_backup.pkl')
            with open(backup_path, 'wb') as f:
                pickle.dump(visualizer.collected_lstm_trajectories, f)
            print(f"\nğŸ’¾ å·²ä¿å­˜LSTMè½¨è¿¹å¤‡ä»½åˆ°: {backup_path}")
            print("   å¯ä»¥æ‰‹åŠ¨åŠ è½½å¹¶åˆ†æè¿™äº›æ•°æ®")


if __name__ == "__main__":
    if len(sys.argv) == 1:
        print("ğŸ¯ JointPCAåˆ†æå·¥å…·ï¼ˆä¿®å¤ç‰ˆï¼‰")
        print("="*50)
        print("ä¿®å¤äº†JSONåºåˆ—åŒ–é—®é¢˜ï¼Œæ›´ç¨³å®šåœ°åˆ†æLSTMåŠ¨åŠ›å­¦")
        print()
        print("ä½¿ç”¨ç¤ºä¾‹:")
        print()
        print("# å¿«é€Ÿæ¨¡å¼ï¼ˆæ¨èï¼‰")
        print("python run_jointpca_fixed.py --checkpoint ./best_model.pth --quick_mode")
        print()
        print("# å®Œæ•´æ¨¡å¼ï¼ˆç”Ÿæˆå•æ ·æœ¬å¯è§†åŒ–ï¼‰")
        print("python run_jointpca_fixed.py --checkpoint ./best_model.pth")
        print()
        print("# è‡ªå®šä¹‰å‚æ•°")
        print("python run_jointpca_fixed.py \\")
        print("    --checkpoint ./model.pth \\")
        print("    --num_samples_per_label 10 \\")
        print("    --save_dir ./my_analysis \\")
        print("    --quick_mode")
        print()
        print("å‚æ•°è¯´æ˜:")
        print("  --checkpoint              æ¨¡å‹è·¯å¾„ï¼ˆå¿…éœ€ï¼‰")
        print("  --val_csv                 éªŒè¯é›†CSVè·¯å¾„")
        print("  --data_root              æ•°æ®æ ¹ç›®å½•")
        print("  --num_samples_per_label  æ¯ä¸ªæ ‡ç­¾çš„æ ·æœ¬æ•°ï¼ˆé»˜è®¤5ï¼‰")
        print("  --save_dir               ä¿å­˜ç›®å½•")
        print("  --quick_mode             å¿«é€Ÿæ¨¡å¼ï¼Œè·³è¿‡å•æ ·æœ¬å¯è§†åŒ–")
        print()
        print("ğŸ’¡ æç¤º:")
        print("  â€¢ å¿«é€Ÿæ¨¡å¼ä¸‹è¿è¡Œé€Ÿåº¦å¿«10å€ä»¥ä¸Š")
        print("  â€¢ è‡ªåŠ¨å¤„ç†JSONåºåˆ—åŒ–é—®é¢˜")
        print("  â€¢ å¦‚æœåˆ†æå¤±è´¥ï¼Œä¼šä¿å­˜LSTMè½¨è¿¹å¤‡ä»½")
    else:
        main()