"""
æ¶ˆèå®éªŒæ•°æ®åŠ è½½å™¨
æä¾›æ•°æ®æ‰“ä¹±åŠŸèƒ½ç”¨äºShuffled Batchå’ŒShuffled Temporalæ¶ˆèå®éªŒ
"""

import torch
from torch.utils.data import DataLoader


class ShuffledBatchWrapper:
    """
    Shuffled Batchæ¶ˆè: æ‰“ä¹±æ ·æœ¬é—´çš„è§†è§‰-å…³èŠ‚é…å¯¹
    
    åœ¨batchç»´åº¦éšæœºæ‰“ä¹±jointsï¼Œç ´åè§†è§‰-è¿åŠ¨çš„è¯­ä¹‰å¯¹åº”å…³ç³»
    ä¿ç•™: æ—¶åºé¡ºåº
    ç ´å: åœºæ™¯é…å¯¹
    """
    
    def __init__(self, dataloader, seed=None):
        self.dataloader = dataloader
        self.seed = seed
        self.rng = torch.Generator()
        if seed is not None:
            self.rng.manual_seed(seed)
    
    def __iter__(self):
        for batch in self.dataloader:
            # ğŸ”¥ å…¼å®¹ä¸¤ç§batchæ ¼å¼
            if 'sequence_data' in batch:
                # åµŒå¥—æ ¼å¼
                images = batch['sequence_data']['images']
                joints = batch['sequence_data']['joints']
                labels = batch['sequence_data']['labels']
                timestamps = batch['sequence_data'].get('timestamps', None)
            else:
                # æ‰å¹³æ ¼å¼
                images = batch['images']
                joints = batch['joints']
                labels = batch['labels']
                timestamps = batch.get('timestamps', None)
            
            # è·å–batch size
            batch_size = images.shape[0]
            
            # ç”Ÿæˆéšæœºæ’åˆ—
            perm = torch.randperm(batch_size, generator=self.rng)
            
            # ğŸ”¥ è¿”å›æ‰å¹³æ ¼å¼ï¼ˆä¸åŸå§‹DataLoaderä¸€è‡´ï¼‰
            shuffled_batch = {
                'images': images,          # ä¿æŒåŸæ ·
                'joints': joints[perm],    # ğŸ”¥ æ‰“ä¹±
                'labels': labels
            }
            if timestamps is not None:
                shuffled_batch['timestamps'] = timestamps
            
            yield shuffled_batch
    
    def __len__(self):
        return len(self.dataloader)
    
    @property
    def dataset(self):
        return self.dataloader.dataset


class ShuffledTemporalWrapper:
    """
    Shuffled Temporalæ¶ˆè: æ‰“ä¹±æ¯ä¸ªæ ·æœ¬å†…éƒ¨çš„æ—¶åº
    
    åœ¨æ—¶åºç»´åº¦éšæœºæ‰“ä¹±jointsï¼Œç ´åæ—¶åºåŒæ­¥
    ä¿ç•™: æ ·æœ¬èº«ä»½ï¼ˆåŒä¸€åœºæ™¯ï¼‰
    ç ´å: æ—¶åºå¯¹åº”
    """
    
    def __init__(self, dataloader, seed=None):
        self.dataloader = dataloader
        self.seed = seed
        self.rng = torch.Generator()
        if seed is not None:
            self.rng.manual_seed(seed)
    
    def __iter__(self):
        for batch in self.dataloader:
            # ğŸ”¥ å…¼å®¹ä¸¤ç§batchæ ¼å¼
            if 'sequence_data' in batch:
                # åµŒå¥—æ ¼å¼
                images = batch['sequence_data']['images']
                joints = batch['sequence_data']['joints']
                labels = batch['sequence_data']['labels']
                timestamps = batch['sequence_data'].get('timestamps', None)
            else:
                # æ‰å¹³æ ¼å¼
                images = batch['images']
                joints = batch['joints']
                labels = batch['labels']
                timestamps = batch.get('timestamps', None)
            
            batch_size, seq_len = images.shape[:2]
            
            # æ¯ä¸ªæ ·æœ¬ç‹¬ç«‹æ‰“ä¹±æ—¶åº
            shuffled_joints = []
            for i in range(batch_size):
                # ä¸ºæ¯ä¸ªæ ·æœ¬ç”Ÿæˆç‹¬ç«‹çš„éšæœºæ’åˆ—
                perm = torch.randperm(seq_len, generator=self.rng)
                shuffled_joints.append(joints[i, perm])
            
            # ğŸ”¥ è¿”å›æ‰å¹³æ ¼å¼ï¼ˆä¸åŸå§‹DataLoaderä¸€è‡´ï¼‰
            shuffled_batch = {
                'images': images,  # ä¿æŒåŸæ ·
                'joints': torch.stack(shuffled_joints, dim=0),  # ğŸ”¥ æ—¶åºæ‰“ä¹±
                'labels': labels
            }
            if timestamps is not None:
                shuffled_batch['timestamps'] = timestamps
            
            yield shuffled_batch
    
    def __len__(self):
        return len(self.dataloader)
    
    @property
    def dataset(self):
        return self.dataloader.dataset


def wrap_dataloader(dataloader, ablation_type, seed=None):
    """
    æ ¹æ®æ¶ˆèç±»å‹åŒ…è£…dataloader
    
    Args:
        dataloader: åŸå§‹dataloader
        ablation_type: æ¶ˆèç±»å‹
        seed: éšæœºç§å­
    
    Returns:
        åŒ…è£…åçš„dataloaderæˆ–åŸå§‹dataloader
    """
    if ablation_type == 'shuffled_batch':
        return ShuffledBatchWrapper(dataloader, seed=seed)
    elif ablation_type == 'shuffled_temporal':
        return ShuffledTemporalWrapper(dataloader, seed=seed)
    else:
        # å…¶ä»–æ¶ˆèä¸éœ€è¦ä¿®æ”¹æ•°æ®
        return dataloader


if __name__ == "__main__":
    """æµ‹è¯•æ•°æ®åŒ…è£…å™¨"""
    print("=== æµ‹è¯•æ•°æ®åŒ…è£…å™¨ ===\n")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    class DummyDataset:
        def __init__(self, num_samples=10):
            self.num_samples = num_samples
        
        def __len__(self):
            return self.num_samples
        
        def __getitem__(self, idx):
            return {
                'sequence_data': {
                    'images': torch.randn(11, 3, 224, 224),
                    'joints': torch.randn(11, 7),
                    'timestamps': torch.randn(11),
                    'labels': torch.randint(0, 11, (11,))
                }
            }
    
    dataset = DummyDataset(num_samples=8)
    dataloader = DataLoader(dataset, batch_size=4, shuffle=False)
    
    # æµ‹è¯•åŸå§‹dataloader
    print("åŸå§‹DataLoader:")
    for i, batch in enumerate(dataloader):
        if i == 0:
            print(f"  Batch {i}: images shape = {batch['sequence_data']['images'].shape}")
            print(f"  Batch {i}: joints shape = {batch['sequence_data']['joints'].shape}")
            print(f"  Batch {i}: joints[0,0,:3] = {batch['sequence_data']['joints'][0,0,:3]}")
            break
    
    # æµ‹è¯•Shuffled Batch
    print("\nShuffled Batch Wrapper:")
    shuffled_batch_loader = ShuffledBatchWrapper(dataloader, seed=42)
    for i, batch in enumerate(shuffled_batch_loader):
        if i == 0:
            # ğŸ”¥ Wrapperè¾“å‡ºæ˜¯æ‰å¹³æ ¼å¼
            print(f"  Batch {i}: images shape = {batch['images'].shape}")
            print(f"  Batch {i}: joints shape = {batch['joints'].shape}")
            print(f"  Batch {i}: joints[0,0,:3] = {batch['joints'][0,0,:3]}")
            print("  (æ³¨æ„: jointså·²åœ¨batchç»´åº¦æ‰“ä¹±)")
            break
    
    # æµ‹è¯•Shuffled Temporal
    print("\nShuffled Temporal Wrapper:")
    shuffled_temporal_loader = ShuffledTemporalWrapper(dataloader, seed=42)
    for i, batch in enumerate(shuffled_temporal_loader):
        if i == 0:
            # ğŸ”¥ Wrapperè¾“å‡ºæ˜¯æ‰å¹³æ ¼å¼
            print(f"  Batch {i}: images shape = {batch['images'].shape}")
            print(f"  Batch {i}: joints shape = {batch['joints'].shape}")
            print(f"  Batch {i}: joints[0,:3,0] = {batch['joints'][0,:3,0]}")
            print("  (æ³¨æ„: jointså·²åœ¨æ—¶åºç»´åº¦æ‰“ä¹±)")
            break
    
    # æµ‹è¯•wrap_dataloaderå‡½æ•°
    print("\næµ‹è¯•wrap_dataloaderå‡½æ•°:")
    for ablation in ['full_model', 'shuffled_batch', 'shuffled_temporal']:
        wrapped = wrap_dataloader(dataloader, ablation, seed=42)
        print(f"  {ablation}: {type(wrapped).__name__}")
    
    print("\n=== æµ‹è¯•å®Œæˆ ===")