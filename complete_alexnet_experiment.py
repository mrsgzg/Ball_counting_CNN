"""
æ‰¹é‡AlexNetå¯¹æ¯”å®éªŒè„šæœ¬ - å®Œæ•´ç‰ˆ
åŒ…å«TensorBoardè®°å½•ã€per-digit accuracyã€å®Œæ•´è®­ç»ƒç›‘æ§ã€æ¨¡å‹checkpointä¿å­˜
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
import numpy as np
import pandas as pd
import os
import time
import csv
from datetime import datetime
from sklearn.metrics import confusion_matrix
from tqdm import tqdm
import argparse
import json
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®matplotlibä¸ºéäº¤äº’å¼åç«¯
plt.switch_backend('Agg')

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å‹å’Œæ•°æ®åŠ è½½å™¨
from Model_alexnet_embodiment import create_model
from DataLoader_embodiment import get_ball_counting_data_loaders


class CompleteTrainer:
    """å®Œæ•´çš„è®­ç»ƒå™¨ - åŒ…å«TensorBoardè®°å½•å’Œcheckpointä¿å­˜"""
    
    def __init__(self, model, train_loader, val_loader, config, device, log_dir, checkpoint_dir):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.config = config
        self.device = device
        self.checkpoint_dir = checkpoint_dir
        
        # åˆ›å»ºcheckpointç›®å½•
        os.makedirs(self.checkpoint_dir, exist_ok=True)
        
        # TensorBoardè®°å½•å™¨
        self.writer = SummaryWriter(log_dir)
        
        # ä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(
            model.parameters(),
            lr=config['learning_rate'],
            betas=config.get('adam_betas', (0.9, 0.999)),
            weight_decay=config.get('weight_decay', 1e-5)
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = self._create_scheduler()
        
        # æ¢¯åº¦è£å‰ªé˜ˆå€¼
        self.grad_clip_norm = config.get('grad_clip_norm', 1.0)
        
        # æŸå¤±æƒé‡
        self.embodiment_loss_weight = config.get('embodiment_loss_weight', 0.3)
        self.attention_loss_weight = config.get('attention_loss_weight', 0.1)
        
        # è®­ç»ƒçŠ¶æ€è®°å½•
        self.best_val_accuracy = 0.0
        self.best_val_loss = float('inf')
        self.training_history = []
        
        # è®°å½•é…ç½®åˆ°TensorBoard
        config_text = f"Model: {config['model_type']}\n"
        config_text += f"Learning Rate: {config['learning_rate']}\n"
        config_text += f"Batch Size: {config['batch_size']}\n"
        config_text += f"Embodiment Loss Weight: {self.embodiment_loss_weight}\n"
        self.writer.add_text('Config', config_text, 0)
        
    def _create_scheduler(self):
        """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        scheduler_type = self.config.get('scheduler_type', 'none')
        
        if scheduler_type == 'cosine':
            return optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer, T_max=self.config.get('total_epochs', 1000)
            )
        elif scheduler_type == 'plateau':
            return optim.lr_scheduler.ReduceLROnPlateau(
                self.optimizer, mode='min', factor=0.5,
                patience=self.config.get('scheduler_patience', 5)
            )
        else:
            return None
    
    def compute_loss(self, outputs, targets):
        """è®¡ç®—æŸå¤±"""
        losses = {}
        
        # è®¡æ•°åˆ†ç±»æŸå¤±
        count_logits = outputs['counts']
        target_counts = targets['labels'].long()
        
        count_loss = F.cross_entropy(
            count_logits.view(-1, 11),
            target_counts.view(-1),
            ignore_index=-1
        )
        losses['count_loss'] = count_loss
        
        # åŠ¨ä½œå›å½’æŸå¤±
        pred_joints = outputs['joints'][:, :-1]
        target_joints = targets['joints'][:, 1:]
        motion_loss = F.mse_loss(pred_joints, target_joints)
        losses['motion_loss'] = motion_loss
        
        # æ³¨æ„åŠ›æ­£åˆ™åŒ–æŸå¤±
        if 'attention_weights' in outputs:
            attention_weights = outputs['attention_weights']
            batch_size, seq_len, H, W = attention_weights.shape
            attention_flat = attention_weights.view(batch_size * seq_len, -1)
            attention_entropy = -(attention_flat * torch.log(attention_flat + 1e-8)).sum(dim=1).mean()
            losses['attention_loss'] = attention_entropy
        else:
            losses['attention_loss'] = torch.tensor(0.0, device=self.device)
        
        # æ€»æŸå¤±
        total_loss = (count_loss + 
                     self.embodiment_loss_weight * motion_loss +
                     self.attention_loss_weight * losses['attention_loss'])
        losses['total_loss'] = total_loss
        
        return losses
    
    def compute_metrics(self, outputs, targets):
        """è®¡ç®—æŒ‡æ ‡"""
        metrics = {}
        
        # è®¡æ•°åˆ†ç±»æŒ‡æ ‡
        count_logits = outputs['counts']
        pred_labels = torch.argmax(count_logits, dim=-1)
        target_counts = targets['labels'].long()
        
        # æ•´ä½“å‡†ç¡®ç‡
        valid_mask = target_counts >= 0
        if valid_mask.sum() > 0:
            metrics['count_accuracy'] = (pred_labels[valid_mask] == target_counts[valid_mask]).float().mean().item()
        else:
            metrics['count_accuracy'] = 0.0
        
        # æœ€ç»ˆè®¡æ•°å‡†ç¡®ç‡
        metrics['final_count_accuracy'] = (pred_labels[:, -1] == target_counts[:, -1]).float().mean().item()
        
        # çœŸå®çš„æœ€ç»ˆè®¡æ•°å‡†ç¡®ç‡
        try:
            true_final_positions = self.find_true_final_positions(target_counts)
            batch_size = pred_labels.shape[0]
            
            true_final_correct = 0
            for i in range(batch_size):
                true_pos = true_final_positions[i]
                if pred_labels[i, true_pos] == target_counts[i, true_pos]:
                    true_final_correct += 1
            
            metrics['true_final_count_accuracy'] = true_final_correct / batch_size
        except:
            metrics['true_final_count_accuracy'] = metrics['final_count_accuracy']
        
        # åŠ¨ä½œæŒ‡æ ‡
        if outputs['joints'].shape[1] > 1:
            pred_joints = outputs['joints'][:, :-1]
            target_joints = targets['joints'][:, 1:]
            metrics['joint_mse'] = F.mse_loss(pred_joints, target_joints).item()
            metrics['joint_mae'] = F.l1_loss(pred_joints, target_joints).item()
        else:
            metrics['joint_mse'] = 0.0
            metrics['joint_mae'] = 0.0
        
        return metrics
    
    def find_true_final_positions(self, target_counts):
        """æ‰¾åˆ°æ¯ä¸ªæ ·æœ¬çš„çœŸå®final countä½ç½®"""
        batch_size = target_counts.shape[0]
        true_final_positions = []
        
        for i in range(batch_size):
            max_count = target_counts[i].max().item()
            final_pos = (target_counts[i] == max_count).nonzero(as_tuple=True)[0]
            if len(final_pos) > 0:
                true_final_positions.append(final_pos[0].item())
            else:
                true_final_positions.append(target_counts.shape[1] - 1)
        
        return torch.tensor(true_final_positions, device=target_counts.device)
    
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        total_count = 0
        epoch_metrics = {}
        
        for batch_idx, batch in enumerate(self.train_loader):
            # æ•°æ®å‡†å¤‡
            sequence_data = {
                'images': batch['sequence_data']['images'].to(self.device),
                'joints': batch['sequence_data']['joints'].to(self.device),
                'timestamps': batch['sequence_data']['timestamps'].to(self.device),
                'labels': batch['sequence_data']['labels'].to(self.device)
            }
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(
                sequence_data=sequence_data,
                use_teacher_forcing=True
            )
            
            # è®¡ç®—æŸå¤±
            targets = {
                'labels': sequence_data['labels'],
                'joints': sequence_data['joints']
            }
            losses = self.compute_loss(outputs, targets)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            losses['total_loss'].backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip_norm)
            
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += losses['total_loss'].item()
            total_count += 1
            
            # è®¡ç®—æŒ‡æ ‡
            with torch.no_grad():
                batch_metrics = self.compute_metrics(outputs, targets)
                for key, value in batch_metrics.items():
                    epoch_metrics[key] = epoch_metrics.get(key, 0) + value
            
            # è®°å½•batchçº§åˆ«çš„æŸå¤±åˆ°TensorBoard
            global_step = epoch * len(self.train_loader) + batch_idx
            self.writer.add_scalar('Batch/Train_Loss', losses['total_loss'].item(), global_step)
            self.writer.add_scalar('Batch/Count_Loss', losses['count_loss'].item(), global_step)
            self.writer.add_scalar('Batch/Motion_Loss', losses['motion_loss'].item(), global_step)
        
        # è®¡ç®—å¹³å‡å€¼
        avg_loss = total_loss / total_count
        avg_metrics = {key: value / total_count for key, value in epoch_metrics.items()}
        
        return avg_loss, avg_metrics
    
    @torch.no_grad()
    def validate(self, epoch):
        """éªŒè¯ - åŒ…å«æ¯ä¸ªæ•°å­—çš„å‡†ç¡®ç‡"""
        self.model.eval()
        total_loss = 0
        total_metrics = {}
        total_count = 0
        
        # æ”¶é›†æ‰€æœ‰é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
        all_pred_labels = []
        all_target_labels = []
        
        for batch in self.val_loader:
            # æ•°æ®å‡†å¤‡
            sequence_data = {
                'images': batch['sequence_data']['images'].to(self.device),
                'joints': batch['sequence_data']['joints'].to(self.device),
                'timestamps': batch['sequence_data']['timestamps'].to(self.device),
                'labels': batch['sequence_data']['labels'].to(self.device)
            }
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(
                sequence_data=sequence_data,
                use_teacher_forcing=False
            )
            
            # è®¡ç®—æŸå¤±
            targets = {
                'labels': sequence_data['labels'],
                'joints': sequence_data['joints']
            }
            losses = self.compute_loss(outputs, targets)
            total_loss += losses['total_loss'].item()
            
            # è®¡ç®—æŒ‡æ ‡
            metrics = self.compute_metrics(outputs, targets)
            for key, value in metrics.items():
                total_metrics[key] = total_metrics.get(key, 0) + value
            
            # æ”¶é›†é¢„æµ‹æ ‡ç­¾
            count_logits = outputs['counts']
            pred_labels = torch.argmax(count_logits, dim=-1)
            all_pred_labels.append(pred_labels.cpu())
            all_target_labels.append(sequence_data['labels'].cpu())
            
            total_count += 1
        
        # å¹³å‡æŒ‡æ ‡
        avg_loss = total_loss / total_count
        avg_metrics = {key: value / total_count for key, value in total_metrics.items()}
        
        # è®¡ç®—æ··æ·†çŸ©é˜µå’Œæ¯ä¸ªæ•°å­—çš„å‡†ç¡®ç‡
        all_pred_labels = torch.cat(all_pred_labels, dim=0).numpy()
        all_target_labels = torch.cat(all_target_labels, dim=0).numpy()
        
        # åªä½¿ç”¨æœ€ç»ˆæ—¶åˆ»çš„é¢„æµ‹
        final_pred = all_pred_labels[:, -1]
        final_target = all_target_labels[:, -1]
        
        # è¿‡æ»¤æ— æ•ˆæ ‡ç­¾
        valid_mask = final_target >= 0
        if valid_mask.sum() > 0:
            cm = confusion_matrix(final_target[valid_mask], final_pred[valid_mask], labels=list(range(11)))
            
            # è®¡ç®—æ¯ä¸ªæ•°å­—çš„å‡†ç¡®ç‡
            per_digit_accuracy = {}
            for digit in range(1, 11):  # 1åˆ°10
                digit_mask = final_target[valid_mask] == digit
                if digit_mask.sum() > 0:
                    digit_correct = (final_pred[valid_mask][digit_mask] == final_target[valid_mask][digit_mask]).sum()
                    per_digit_accuracy[f'acc_digit_{digit}'] = digit_correct / digit_mask.sum()
                else:
                    per_digit_accuracy[f'acc_digit_{digit}'] = 0.0
            
            # æ·»åŠ åˆ°å¹³å‡æŒ‡æ ‡ä¸­
            avg_metrics.update(per_digit_accuracy)
            
            # è®°å½•per-digit accuracyåˆ°TensorBoard
            for digit in range(1, 11):
                self.writer.add_scalar(f'Accuracy_per_Digit/Digit_{digit}', 
                                     per_digit_accuracy[f'acc_digit_{digit}'], epoch)
        else:
            cm = np.zeros((11, 11), dtype=int)
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè®¾ç½®æ‰€æœ‰æ•°å­—å‡†ç¡®ç‡ä¸º0
            for digit in range(1, 11):
                avg_metrics[f'acc_digit_{digit}'] = 0.0
        
        return avg_loss, avg_metrics, cm
    
    def plot_confusion_matrix(self, cm, epoch):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        # æ·»åŠ è¿™ä¸€è¡Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„åç«¯
        import matplotlib
        matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=list(range(11)),
                    yticklabels=list(range(11)))
        plt.xlabel('Predicted Count')
        plt.ylabel('True Count')
        plt.title(f'AlexNet Model - Confusion Matrix - Epoch {epoch}')
        return plt.gcf()

    def save_checkpoint(self, epoch, val_loss, val_metrics, checkpoint_type='regular'):
        """ä¿å­˜æ¨¡å‹checkpoint"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'config': self.config,
            'val_loss': val_loss,
            'val_metrics': val_metrics,
            'best_val_accuracy': self.best_val_accuracy,
            'best_val_loss': self.best_val_loss,
            'training_history': self.training_history,
            'timestamp': datetime.now().isoformat()
        }
        
        # ç¡®å®šä¿å­˜è·¯å¾„
        if checkpoint_type == 'best':
            checkpoint_path = os.path.join(self.checkpoint_dir, 
                                         f"best_{self.config['model_type']}_seed_{self.config.get('seed', 0)}.pth")
        elif checkpoint_type == 'final':
            checkpoint_path = os.path.join(self.checkpoint_dir, 
                                         f"final_{self.config['model_type']}_seed_{self.config.get('seed', 0)}.pth")
        elif checkpoint_type == 'periodic':
            checkpoint_path = os.path.join(self.checkpoint_dir, 
                                         f"epoch_{epoch}_{self.config['model_type']}_seed_{self.config.get('seed', 0)}.pth")
        else:
            checkpoint_path = os.path.join(self.checkpoint_dir, 
                                         f"{checkpoint_type}_{self.config['model_type']}_seed_{self.config.get('seed', 0)}.pth")
        
        try:
            # å…ˆä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_path = checkpoint_path + '.tmp'
            torch.save(checkpoint, temp_path)
            
            # éªŒè¯ä¿å­˜çš„æ–‡ä»¶
            test_checkpoint = torch.load(temp_path, map_location='cpu')
            required_keys = ['model_state_dict', 'optimizer_state_dict', 'epoch']
            for key in required_keys:
                if key not in test_checkpoint:
                    raise ValueError(f"Missing key in checkpoint: {key}")
            
            # é‡å‘½åä¸ºæœ€ç»ˆæ–‡ä»¶
            os.rename(temp_path, checkpoint_path)
            
            print(f"âœ… Checkpoint saved: {os.path.basename(checkpoint_path)}")
            
            return checkpoint_path
            
        except Exception as e:
            print(f"âŒ Failed to save checkpoint: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                os.remove(temp_path)
            return None
    
    def log_to_tensorboard(self, epoch, train_loss, train_metrics, val_loss, val_metrics,confusion_matrix):
        """è®°å½•åˆ°TensorBoard"""
        # æŸå¤±
        self.writer.add_scalars('Loss/Total', {
            'Train': train_loss,
            'Val': val_loss
        }, epoch)
        
        self.writer.add_scalars('Loss/Count', {
            'Train': train_metrics.get('count_loss', 0),
            'Val': val_metrics.get('count_loss', 0)
        }, epoch)
        
        self.writer.add_scalars('Loss/Motion', {
            'Train': train_metrics.get('motion_loss', 0),
            'Val': val_metrics.get('motion_loss', 0)
        }, epoch)
        
        if confusion_matrix.sum() > 0:  # ç¡®ä¿æ··æ·†çŸ©é˜µä¸ä¸ºç©º
            cm_figure = self.plot_confusion_matrix(confusion_matrix, epoch)
            self.writer.add_figure('Confusion_Matrix/Final_Count', cm_figure, epoch)
            plt.close(cm_figure)

        # å‡†ç¡®ç‡
        self.writer.add_scalars('Accuracy/Count', {
            'Train': train_metrics['count_accuracy'],
            'Val': val_metrics['count_accuracy']
        }, epoch)
        
        self.writer.add_scalars('Accuracy/Final_Count', {
            'Train': train_metrics['final_count_accuracy'],
            'Val': val_metrics['final_count_accuracy']
        }, epoch)
        
        self.writer.add_scalars('Accuracy/True_Final_Count', {
            'Train': train_metrics['true_final_count_accuracy'],
            'Val': val_metrics['true_final_count_accuracy']
        }, epoch)
        
        # åŠ¨ä½œæŒ‡æ ‡
        self.writer.add_scalars('Motion/MSE', {
            'Train': train_metrics['joint_mse'],
            'Val': val_metrics['joint_mse']
        }, epoch)
        
        self.writer.add_scalars('Motion/MAE', {
            'Train': train_metrics['joint_mae'],
            'Val': val_metrics['joint_mae']
        }, epoch)
        
        # å­¦ä¹ ç‡
        current_lr = self.optimizer.param_groups[0]['lr']
        self.writer.add_scalar('Learning_Rate', current_lr, epoch)
    
    def train_full(self, total_epochs, validate_every=50, print_every=100, save_checkpoints=True):
        """å®Œæ•´è®­ç»ƒè¿‡ç¨‹ - å®šæœŸéªŒè¯å¹¶è®°å½•"""
        print(f"å¼€å§‹è®­ç»ƒ {total_epochs} epochs...")
        print(f"æ¨¡å‹ç±»å‹: {self.config['model_type']}")
        print(f"éšæœºç§å­: {self.config.get('seed', 'N/A')}")
        print(f"Checkpointç›®å½•: {self.checkpoint_dir}")
        
        start_time = time.time()
        final_results = None
        
        # ä¿å­˜åˆå§‹checkpoint
        if save_checkpoints:
            self.save_checkpoint(-1, float('inf'), {}, 'initial')
        
        for epoch in range(total_epochs):
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss, train_metrics = self.train_epoch(epoch)
            
            # æ›´æ–°å­¦ä¹ ç‡
            if self.scheduler:
                if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                    # éœ€è¦éªŒè¯æŸå¤±ï¼Œå¦‚æœæ²¡æœ‰åˆ™è·³è¿‡
                    pass
                else:
                    self.scheduler.step()
            
            # å®šæœŸéªŒè¯
            if (epoch + 1) % validate_every == 0 or epoch == total_epochs - 1:
                val_loss, val_metrics, confusion_matrix = self.validate(epoch)
                
                # è®°å½•è®­ç»ƒå†å²
                history_entry = {
                    'epoch': epoch,
                    'train_loss': train_loss,
                    'val_loss': val_loss,
                    'val_accuracy': val_metrics['count_accuracy'],
                    'final_count_accuracy': val_metrics['final_count_accuracy'],
                    'timestamp': datetime.now().isoformat()
                }
                self.training_history.append(history_entry)
                
                # è®°å½•åˆ°TensorBoard
                self.log_to_tensorboard(epoch, train_loss, train_metrics, val_loss, val_metrics,confusion_matrix)
                
                # æ›´æ–°æœ€ä½³æ¨¡å‹
                is_best = False
                if val_metrics['count_accuracy'] > self.best_val_accuracy:
                    self.best_val_accuracy = val_metrics['count_accuracy']
                    self.best_val_loss = val_loss
                    is_best = True
                    
                    # ä¿å­˜æœ€ä½³æ¨¡å‹
                    if save_checkpoints:
                        self.save_checkpoint(epoch, val_loss, val_metrics, 'best')
                
                # å¦‚æœæ˜¯æœ€åä¸€ä¸ªepochï¼Œä¿å­˜æœ€ç»ˆç»“æœå’Œæ¨¡å‹
                if epoch == total_epochs - 1:
                    final_results = {
                        'final_val_loss': val_loss,
                        'final_val_metrics': val_metrics,
                        'confusion_matrix': confusion_matrix,
                        'training_time_hours': (time.time() - start_time) / 3600,
                        'best_val_accuracy': self.best_val_accuracy,
                        'best_val_loss': self.best_val_loss,
                        'training_history': self.training_history
                    }
                    
                    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
                    if save_checkpoints:
                        final_checkpoint_path = self.save_checkpoint(epoch, val_loss, val_metrics, 'final')
                        final_results['final_checkpoint_path'] = final_checkpoint_path
                
                # æ‰“å°éªŒè¯ç»“æœ
                status = "ğŸŒŸ NEW BEST!" if is_best else ""
                print(f"Epoch {epoch+1}/{total_epochs} - "
                      f"Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f} - "
                      f"Val Acc: {val_metrics['count_accuracy']:.4f} - "
                      f"Final Acc: {val_metrics['final_count_accuracy']:.4f} {status}")
            
            # å®šæœŸæ‰“å°è®­ç»ƒè¿›åº¦
            elif (epoch + 1) % print_every == 0:
                elapsed = time.time() - start_time
                remaining = elapsed / (epoch + 1) * (total_epochs - epoch - 1)
                print(f"Epoch {epoch+1}/{total_epochs} - Loss: {train_loss:.4f} - "
                      f"Elapsed: {elapsed/3600:.1f}h - Remaining: {remaining/3600:.1f}h")
            
            # å®šæœŸä¿å­˜checkpoint (å¯é€‰)
            if save_checkpoints and (epoch + 1) % (validate_every * 5) == 0:  # æ¯250ä¸ªepochä¿å­˜ä¸€æ¬¡
                self.save_checkpoint(epoch, train_loss, train_metrics, 'periodic')
        
        # å…³é—­TensorBoard
        self.writer.close()
        
        print(f"\nè®­ç»ƒå®Œæˆ!")
        print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_val_accuracy:.4f}")
        print(f"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {final_results['final_val_metrics']['count_accuracy']:.4f}")
        print(f"è®­ç»ƒæ—¶é—´: {final_results['training_time_hours']:.2f} å°æ—¶")
        
        return final_results


def set_random_seed(seed):
    """è®¾ç½®éšæœºç§å­"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def create_config(model_type, seed=None):
    """åˆ›å»ºé…ç½®"""
    config = {
        # æ•°æ®é…ç½®
        'image_mode': 'rgb',
        'batch_size': 16,
        'sequence_length': 11,
        'normalize': True,
        'num_workers': 4,
        
        # æ¨¡å‹é…ç½®
        'model_config': {
            'cnn_layers': 3,
            'cnn_channels': [64, 128, 256],
            'lstm_layers': 2,
            'lstm_hidden_size': 512,
            'feature_dim': 256,
            'joint_dim': 7,
            'dropout': 0.1,
            'use_fovea_bias': True
        },
        
        # è®­ç»ƒé…ç½®
        'learning_rate': 1e-4,
        'weight_decay': 1e-5,
        'adam_betas': (0.9, 0.999),
        'grad_clip_norm': 1.0,
        
        # æŸå¤±æƒé‡
        'embodiment_loss_weight': 0.3,
        'attention_loss_weight': 0.1,
        
        # å­¦ä¹ ç‡è°ƒåº¦
        'scheduler_type': 'none',
        'scheduler_patience': 5,
        
        # å…¶ä»–
        'model_type': model_type,
        'seed': seed
    }
    
    return config


def run_single_experiment(model_type, seed, data_config, results_file, log_base_dir, 
                         checkpoint_base_dir, total_epochs=1000, save_checkpoints=True):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    print(f"\n{'='*60}")
    print(f"å®éªŒ: {model_type} - ç§å­: {seed}")
    print(f"{'='*60}")
    
    # è®¾ç½®éšæœºç§å­
    set_random_seed(seed)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    try:
        # åˆ›å»ºé…ç½®
        config = create_config(model_type, seed)
        config['total_epochs'] = total_epochs
        
        # åˆ›å»ºç›®å½•
        experiment_name = f'{model_type}_seed_{seed}'
        log_dir = os.path.join(log_base_dir, experiment_name)
        checkpoint_dir = os.path.join(checkpoint_base_dir, experiment_name)
        
        os.makedirs(log_dir, exist_ok=True)
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print("åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        train_loader, val_loader, normalizer = get_ball_counting_data_loaders(
            train_csv_path=data_config['train_csv'],
            val_csv_path=data_config['val_csv'],
            data_root=data_config['data_root'],
            batch_size=config['batch_size'],
            sequence_length=config['sequence_length'],
            normalize=config['normalize'],
            num_workers=config['num_workers'],
            image_mode=config['image_mode']
        )
        
        # åˆ›å»ºæ¨¡å‹
        print("åˆ›å»ºæ¨¡å‹...")
        model = create_model(config, model_type=model_type).to(device)
        
        # ç»Ÿè®¡å‚æ•°
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"æ¨¡å‹å‚æ•°æ•°é‡: {total_params:,}")
        print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}")
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = CompleteTrainer(model, train_loader, val_loader, config, 
                                device, log_dir, checkpoint_dir)
        
        # è®­ç»ƒ
        results = trainer.train_full(total_epochs, validate_every=100, 
                                   print_every=100, save_checkpoints=save_checkpoints)
        
        # æ•´ç†ç»“æœ
        final_results = {
            'model_type': model_type,
            'seed': seed,
            'total_epochs': total_epochs,
            'final_val_accuracy': results['final_val_metrics']['count_accuracy'],
            'final_count_accuracy': results['final_val_metrics']['final_count_accuracy'],
            'true_final_count_accuracy': results['final_val_metrics']['true_final_count_accuracy'],
            'joint_mse': results['final_val_metrics']['joint_mse'],
            'joint_mae': results['final_val_metrics']['joint_mae'],
            'val_loss': results['final_val_loss'],
            'best_val_accuracy': results['best_val_accuracy'],
            'best_val_loss': results['best_val_loss'],
            'training_time_hours': results['training_time_hours'],
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'tensorboard_log': log_dir,
            'checkpoint_dir': checkpoint_dir,
            'final_checkpoint_path': results.get('final_checkpoint_path', ''),
            'timestamp': datetime.now().isoformat()
        }
        
        # æ·»åŠ æ¯ä¸ªæ•°å­—çš„å‡†ç¡®ç‡
        for digit in range(1, 11):
            acc_key = f'acc_digit_{digit}'
            final_results[acc_key] = results['final_val_metrics'].get(acc_key, 0.0)
        
        # ä¿å­˜ç»“æœåˆ°CSV
        save_result_to_csv(final_results, results_file)
        
        # ä¿å­˜è¯¦ç»†è®­ç»ƒå†å²
        history_file = os.path.join(checkpoint_dir, 'training_history.json')
        with open(history_file, 'w') as f:
            json.dump(results['training_history'], f, indent=2)
        
        print(f"å®éªŒå®Œæˆ!")
        print(f"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {final_results['final_val_accuracy']:.4f}")
        print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {final_results['best_val_accuracy']:.4f}")
        print(f"è®­ç»ƒæ—¶é—´: {final_results['training_time_hours']:.2f} å°æ—¶")
        print(f"TensorBoardæ—¥å¿—: {log_dir}")
        print(f"æ¨¡å‹checkpoints: {checkpoint_dir}")
        
        return final_results
        
    except Exception as e:
        print(f"å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        # è®°å½•å¤±è´¥çš„å®éªŒ
        failure_result = {
            'model_type': model_type,
            'seed': seed,
            'total_epochs': total_epochs,
            'error': str(e),
            'timestamp': datetime.now().isoformat(),
            'status': 'FAILED'
        }
        
        return failure_result
        
    finally:
        # æ¸…ç†å†…å­˜
        if 'model' in locals():
            del model
        if 'train_loader' in locals():
            del train_loader
        if 'val_loader' in locals():
            del val_loader
        if device.type == 'cuda':
            torch.cuda.empty_cache()


def save_result_to_csv(result, csv_file):
    """ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶"""
    file_exists = os.path.exists(csv_file)
    
    with open(csv_file, 'a', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=result.keys())
        
        if not file_exists:
            writer.writeheader()
        
        writer.writerow(result)


def generate_summary_stats(results_file, summary_file):
    """ç”Ÿæˆç»Ÿè®¡æ‘˜è¦"""
    if not os.path.exists(results_file):
        print(f"ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {results_file}")
        return
    
    df = pd.read_csv(results_file)
    
    # è¿‡æ»¤æ‰å¤±è´¥çš„å®éªŒ - ä¿®å¤pandasè¯­æ³•
    if 'status' in df.columns:
        successful_df = df[df['status'] != 'FAILED'].copy()
    else:
        # å¦‚æœæ²¡æœ‰statusåˆ—ï¼Œå‡è®¾éƒ½æ˜¯æˆåŠŸçš„
        successful_df = df.copy()
    
    if len(successful_df) == 0:
        print("æ²¡æœ‰æˆåŠŸçš„å®éªŒç»“æœ")
        return
    
    # æŒ‰æ¨¡å‹ç±»å‹åˆ†ç»„ç»Ÿè®¡
    summary_stats = []
    
    for model_type in successful_df['model_type'].unique():
        model_data = successful_df[successful_df['model_type'] == model_type]
        
        if len(model_data) > 0:
            stats = {
                'model_type': model_type,
                'n_experiments': len(model_data),
                'mean_final_val_accuracy': model_data['final_val_accuracy'].mean(),
                'std_final_val_accuracy': model_data['final_val_accuracy'].std(),
                'max_final_val_accuracy': model_data['final_val_accuracy'].max(),
                'min_final_val_accuracy': model_data['final_val_accuracy'].min(),
                'mean_best_val_accuracy': model_data['best_val_accuracy'].mean(),
                'std_best_val_accuracy': model_data['best_val_accuracy'].std(),
                'mean_training_time_hours': model_data['training_time_hours'].mean(),
                'std_training_time_hours': model_data['training_time_hours'].std(),
                'total_parameters': model_data['total_parameters'].iloc[0] if 'total_parameters' in model_data.columns else None,
                'trainable_parameters': model_data['trainable_parameters'].iloc[0] if 'trainable_parameters' in model_data.columns else None
            }
            
            # æ·»åŠ æ¯ä¸ªæ•°å­—çš„å¹³å‡å‡†ç¡®ç‡
            for digit in range(1, 11):
                acc_col = f'acc_digit_{digit}'
                if acc_col in model_data.columns:
                    stats[f'mean_{acc_col}'] = model_data[acc_col].mean()
                    stats[f'std_{acc_col}'] = model_data[acc_col].std()
            
            # æ·»åŠ å…³èŠ‚é¢„æµ‹æŒ‡æ ‡
            if 'joint_mse' in model_data.columns:
                stats['mean_joint_mse'] = model_data['joint_mse'].mean()
                stats['std_joint_mse'] = model_data['joint_mse'].std()
            
            if 'joint_mae' in model_data.columns:
                stats['mean_joint_mae'] = model_data['joint_mae'].mean()
                stats['std_joint_mae'] = model_data['joint_mae'].std()
            
            summary_stats.append(stats)
    
    # ä¿å­˜æ‘˜è¦
    summary_df = pd.DataFrame(summary_stats)
    summary_df.to_csv(summary_file, index=False)
    
    # æ‰“å°æ‘˜è¦è¡¨æ ¼
    print(f"\nğŸ“Š å®éªŒç»Ÿè®¡æ‘˜è¦:")
    print("="*80)
    display_cols = ['model_type', 'n_experiments', 'mean_final_val_accuracy', 
                   'std_final_val_accuracy', 'mean_best_val_accuracy', 'mean_training_time_hours']
    display_df = summary_df[display_cols].round(4)
    print(display_df.to_string(index=False))
    
    # æ‰“å°å¤±è´¥çš„å®éªŒ
    if 'status' in df.columns:
        failed_df = df[df['status'] == 'FAILED']
        if len(failed_df) > 0:
            print(f"\nâŒ å¤±è´¥çš„å®éªŒ ({len(failed_df)} ä¸ª):")
            for _, row in failed_df.iterrows():
                print(f"  {row['model_type']} - ç§å­ {row['seed']}: {row.get('error', 'Unknown error')}")
    else:
        print("\nâœ… æ‰€æœ‰å®éªŒéƒ½æˆåŠŸå®Œæˆ")
    
    print(f"\nğŸ“„ å®Œæ•´æ‘˜è¦å·²ä¿å­˜: {summary_file}")
    return summary_df


def create_experiment_report(results_file, summary_file, report_file):
    """åˆ›å»ºè¯¦ç»†çš„å®éªŒæŠ¥å‘Š"""
    if not os.path.exists(results_file) or not os.path.exists(summary_file):
        print("ç¼ºå°‘å¿…è¦çš„ç»“æœæ–‡ä»¶ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
        return
    
    df = pd.read_csv(results_file)
    summary_df = pd.read_csv(summary_file)
    
    report_content = f"""# AlexNetå¯¹æ¯”å®éªŒæŠ¥å‘Š

## å®éªŒæ¦‚è¿°
- å®éªŒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- æ€»å®éªŒæ•°: {len(df)}
- æˆåŠŸå®éªŒæ•°: {len(df[df.get('status', 'SUCCESS') != 'FAILED'])}
- å¤±è´¥å®éªŒæ•°: {len(df[df.get('status', 'SUCCESS') == 'FAILED'])}

## æ¨¡å‹å¯¹æ¯”

### æ€§èƒ½æ€»ç»“
"""
    
    for _, row in summary_df.iterrows():
        report_content += f"""
#### {row['model_type']}
- å®éªŒæ¬¡æ•°: {row['n_experiments']}
- æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {row['mean_final_val_accuracy']:.4f} Â± {row['std_final_val_accuracy']:.4f}
- æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {row['mean_best_val_accuracy']:.4f} Â± {row['std_best_val_accuracy']:.4f}
- å¹³å‡è®­ç»ƒæ—¶é—´: {row['mean_training_time_hours']:.2f} Â± {row['std_training_time_hours']:.2f} å°æ—¶
- å‚æ•°æ•°é‡: {row.get('total_parameters', 'N/A'):,} (å¯è®­ç»ƒ: {row.get('trainable_parameters', 'N/A'):,})
"""

    # æ·»åŠ æ¯ä¸ªæ•°å­—çš„å‡†ç¡®ç‡åˆ†æ
    report_content += "\n### å„æ•°å­—å‡†ç¡®ç‡åˆ†æ\n"
    
    for model_type in summary_df['model_type']:
        model_row = summary_df[summary_df['model_type'] == model_type].iloc[0]
        report_content += f"\n#### {model_type}\n"
        
        for digit in range(1, 11):
            mean_key = f'mean_acc_digit_{digit}'
            std_key = f'std_acc_digit_{digit}'
            if mean_key in model_row and pd.notna(model_row[mean_key]):
                report_content += f"- æ•°å­— {digit}: {model_row[mean_key]:.3f} Â± {model_row[std_key]:.3f}\n"
    
    # æ·»åŠ å»ºè®®å’Œç»“è®º
    report_content += f"""

## å®éªŒç»“è®º

### ä¸»è¦å‘ç°
1. **æ€§èƒ½æ’åº**: æ ¹æ®æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡è¿›è¡Œæ’åº
2. **è®­ç»ƒæ•ˆç‡**: è®­ç»ƒæ—¶é—´ä¸æ€§èƒ½çš„æƒè¡¡
3. **ç¨³å®šæ€§**: ä¸åŒéšæœºç§å­ä¸‹çš„æ€§èƒ½æ–¹å·®

### æœ€ä½³æ¨¡å‹
"""
    
    if len(summary_df) > 0:
        best_model = summary_df.loc[summary_df['mean_final_val_accuracy'].idxmax()]
        report_content += f"""
- æ¨¡å‹ç±»å‹: {best_model['model_type']}
- æœ€ç»ˆå‡†ç¡®ç‡: {best_model['mean_final_val_accuracy']:.4f} Â± {best_model['std_final_val_accuracy']:.4f}
- æœ€ä½³å‡†ç¡®ç‡: {best_model['mean_best_val_accuracy']:.4f} Â± {best_model['std_best_val_accuracy']:.4f}
- å¹³å‡è®­ç»ƒæ—¶é—´: {best_model['mean_training_time_hours']:.2f} å°æ—¶
"""

    report_content += f"""

## æŠ€æœ¯ç»†èŠ‚

### å®éªŒè®¾ç½®
- è®­ç»ƒepochs: {df['total_epochs'].iloc[0] if 'total_epochs' in df.columns else 'N/A'}
- æ‰¹æ¬¡å¤§å°: 16
- å­¦ä¹ ç‡: 1e-4
- ä¼˜åŒ–å™¨: Adam
- éšæœºç§å­: {list(df['seed'].unique()) if 'seed' in df.columns else 'N/A'}

### æ•°æ®é›†ä¿¡æ¯
- åºåˆ—é•¿åº¦: 11
- å›¾åƒæ¨¡å¼: RGB
- æ•°æ®å½’ä¸€åŒ–: æ˜¯

### è¯„ä¼°æŒ‡æ ‡
- æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æœ€ç»ˆå‡†ç¡®ç‡
- æœ€ä½³éªŒè¯å‡†ç¡®ç‡: è®­ç»ƒè¿‡ç¨‹ä¸­è¾¾åˆ°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡
- å„æ•°å­—å‡†ç¡®ç‡: æ¯ä¸ªæ•°å­—ç±»åˆ«çš„å‡†ç¡®ç‡
- å…³èŠ‚é¢„æµ‹è¯¯å·®: MSEå’ŒMAE

## æ–‡ä»¶è¯´æ˜
- è¯¦ç»†ç»“æœ: {os.path.basename(results_file)}
- ç»Ÿè®¡æ‘˜è¦: {os.path.basename(summary_file)}
- TensorBoardæ—¥å¿—: å„æ¨¡å‹çš„tensorboard_logsç›®å½•
- æ¨¡å‹checkpoints: å„æ¨¡å‹çš„checkpointsç›®å½•

## å¤ç°è¯´æ˜
ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­å’Œè¶…å‚æ•°è®¾ç½®å¯ä»¥å¤ç°å®éªŒç»“æœã€‚æ¯ä¸ªå®éªŒçš„å…·ä½“é…ç½®ä¿å­˜åœ¨å¯¹åº”çš„checkpointç›®å½•ä¸­ã€‚
"""

    # ä¿å­˜æŠ¥å‘Š
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"ğŸ“‹ è¯¦ç»†å®éªŒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")


def load_and_test_checkpoint(checkpoint_path, data_config, device='cuda'):
    """åŠ è½½checkpointå¹¶è¿›è¡Œæµ‹è¯•"""
    print(f"åŠ è½½checkpoint: {checkpoint_path}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(checkpoint_path):
        print(f"Checkpointæ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        return None
    
    try:
        # åŠ è½½checkpoint
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        config = checkpoint['config']
        
        # åˆ›å»ºæ¨¡å‹
        model = create_model(config, model_type=config['model_type'])
        model.load_state_dict(checkpoint['model_state_dict'])
        
        device = torch.device(device if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        model.eval()
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"   æ¨¡å‹ç±»å‹: {config['model_type']}")
        print(f"   è®­ç»ƒepoch: {checkpoint['epoch']}")
        print(f"   éªŒè¯å‡†ç¡®ç‡: {checkpoint['val_metrics']['count_accuracy']:.4f}")
        
        return model, config, checkpoint
        
    except Exception as e:
        print(f"âŒ åŠ è½½checkpointå¤±è´¥: {e}")
        return None


def main():
    parser = argparse.ArgumentParser(description='AlexNetå¯¹æ¯”å®éªŒ - å®Œæ•´ç‰ˆ')
    
    # æ•°æ®è·¯å¾„
    parser.add_argument('--data_root', type=str, 
                       default='/mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/Ball_counting_CNN/ball_data_collection')
    parser.add_argument('--train_csv', type=str,
                       default='scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_train.csv')
    parser.add_argument('--val_csv', type=str,
                       default='scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_val.csv')
    
    # å®éªŒå‚æ•°
    parser.add_argument('--total_epochs', type=int, default=1000,
                       help='è®­ç»ƒæ€»epochæ•°')
    parser.add_argument('--model_types', nargs='+', 
                       default=['baseline', 'alexnet_no_pretrain', 'alexnet_pretrain'],
                       help='è¦æµ‹è¯•çš„æ¨¡å‹ç±»å‹')
    parser.add_argument('--seeds', nargs='+', type=int,
                       default=[42, 123, 456, 789, 1024, 2048, 3071, 4096, 5555, 9999],
                       help='éšæœºç§å­åˆ—è¡¨')
    
    # ç»“æœä¿å­˜
    parser.add_argument('--results_dir', type=str, default='./alexnet_experiment_results',
                       help='ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--save_checkpoints', action='store_true', default=True,
                       help='æ˜¯å¦ä¿å­˜æ¨¡å‹checkpoints')
    parser.add_argument('--no_checkpoints', action='store_true', default=False,
                       help='ä¸ä¿å­˜æ¨¡å‹checkpoints')
    
    # è¿è¡Œæ¨¡å¼
    parser.add_argument('--mode', type=str, default='experiment',
                       choices=['experiment', 'analyze', 'test_checkpoint'],
                       help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--checkpoint_path', type=str, default=None,
                       help='ç”¨äºæµ‹è¯•çš„checkpointè·¯å¾„')
    
    args = parser.parse_args()
    
    # å¤„ç†checkpointä¿å­˜é€‰é¡¹
    save_checkpoints = args.save_checkpoints and not args.no_checkpoints
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs(args.results_dir, exist_ok=True)
    
    # æ–‡ä»¶è·¯å¾„
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_file = os.path.join(args.results_dir, f'detailed_results_{timestamp}.csv')
    summary_file = os.path.join(args.results_dir, f'summary_stats_{timestamp}.csv')
    report_file = os.path.join(args.results_dir, f'experiment_report_{timestamp}.md')
    log_base_dir = os.path.join(args.results_dir, f'tensorboard_logs_{timestamp}')
    checkpoint_base_dir = os.path.join(args.results_dir, f'checkpoints_{timestamp}')
    
    # æ•°æ®é…ç½®
    data_config = {
        'data_root': args.data_root,
        'train_csv': args.train_csv,
        'val_csv': args.val_csv
    }
    
    if args.mode == 'experiment':
        # è¿è¡Œå®éªŒæ¨¡å¼
        print("ğŸš€ å¼€å§‹AlexNetå¯¹æ¯”å®éªŒ - å®Œæ•´ç‰ˆ")
        print(f"æ¨¡å‹ç±»å‹: {args.model_types}")
        print(f"éšæœºç§å­: {args.seeds}")
        print(f"æ€»å®éªŒæ•°: {len(args.model_types) * len(args.seeds)}")
        print(f"æ¯ä¸ªå®éªŒè®­ç»ƒepochs: {args.total_epochs}")
        print(f"ä¿å­˜checkpoints: {'æ˜¯' if save_checkpoints else 'å¦'}")
        print(f"ç»“æœä¿å­˜: {results_file}")
        print(f"TensorBoardæ—¥å¿—: {log_base_dir}")
        if save_checkpoints:
            print(f"æ¨¡å‹checkpoints: {checkpoint_base_dir}")
        
        # è¿è¡Œæ‰€æœ‰å®éªŒ
        total_experiments = len(args.model_types) * len(args.seeds)
        current_exp = 0
        start_time = time.time()
        
        for model_type in args.model_types:
            for seed in args.seeds:
                current_exp += 1
                elapsed_time = time.time() - start_time
                avg_time_per_exp = elapsed_time / current_exp if current_exp > 0 else 0
                remaining_time = avg_time_per_exp * (total_experiments - current_exp)
                
                print(f"\nğŸ“Š è¿›åº¦: {current_exp}/{total_experiments}")
                print(f"â±ï¸ å·²ç”¨æ—¶: {elapsed_time/3600:.1f}h, é¢„è®¡å‰©ä½™: {remaining_time/3600:.1f}h")
                
                result = run_single_experiment(
                    model_type, seed, data_config, results_file, 
                    log_base_dir, checkpoint_base_dir, args.total_epochs, save_checkpoints
                )
        
        # ç”Ÿæˆç»Ÿè®¡æ‘˜è¦å’ŒæŠ¥å‘Š
        print(f"\nğŸ“ˆ ç”Ÿæˆç»Ÿè®¡æ‘˜è¦...")
        summary_df = generate_summary_stats(results_file, summary_file)
        
        print(f"\nğŸ“‹ ç”Ÿæˆå®éªŒæŠ¥å‘Š...")
        create_experiment_report(results_file, summary_file, report_file)
        
        total_time = time.time() - start_time
        print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆ!")
        print(f"â±ï¸ æ€»è€—æ—¶: {total_time/3600:.1f} å°æ—¶")
        print(f"ğŸ“Š è¯¦ç»†ç»“æœ: {results_file}")
        print(f"ğŸ“ˆ ç»Ÿè®¡æ‘˜è¦: {summary_file}")
        print(f"ğŸ“‹ å®éªŒæŠ¥å‘Š: {report_file}")
        print(f"ğŸ“º TensorBoard: tensorboard --logdir {log_base_dir}")
        if save_checkpoints:
            print(f"ğŸ’¾ æ¨¡å‹checkpoints: {checkpoint_base_dir}")
    
    elif args.mode == 'analyze':
        # åˆ†æç°æœ‰ç»“æœ
        print("ğŸ“Š åˆ†ææ¨¡å¼ - é‡æ–°ç”Ÿæˆç»Ÿè®¡æ‘˜è¦")
        
        # æŸ¥æ‰¾æœ€æ–°çš„ç»“æœæ–‡ä»¶
        result_files = [f for f in os.listdir(args.results_dir) if f.startswith('detailed_results_') and f.endswith('.csv')]
        if not result_files:
            print("æœªæ‰¾åˆ°å®éªŒç»“æœæ–‡ä»¶")
            return
        
        latest_result_file = os.path.join(args.results_dir, sorted(result_files)[-1])
        print(f"ä½¿ç”¨ç»“æœæ–‡ä»¶: {latest_result_file}")
        
        summary_df = generate_summary_stats(latest_result_file, summary_file)
        create_experiment_report(latest_result_file, summary_file, report_file)
        
        print(f"ğŸ“ˆ ç»Ÿè®¡æ‘˜è¦: {summary_file}")
        print(f"ğŸ“‹ å®éªŒæŠ¥å‘Š: {report_file}")
    
    elif args.mode == 'test_checkpoint':
        # æµ‹è¯•checkpointæ¨¡å¼
        if not args.checkpoint_path:
            print("æµ‹è¯•æ¨¡å¼éœ€è¦æŒ‡å®š --checkpoint_path")
            return
        
        print("ğŸ§ª æµ‹è¯•checkpointæ¨¡å¼")
        result = load_and_test_checkpoint(args.checkpoint_path, data_config)
        
        if result:
            model, config, checkpoint = result
            print("âœ… Checkpointæµ‹è¯•æˆåŠŸ")
            print(f"å¯ä»¥ä½¿ç”¨æ­¤æ¨¡å‹è¿›è¡Œæ¨ç†æˆ–è¿›ä¸€æ­¥åˆ†æ")
        else:
            print("âŒ Checkpointæµ‹è¯•å¤±è´¥")


if __name__ == "__main__":
    main()