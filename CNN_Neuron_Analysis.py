"""
Integrated Single Image CNN Model Analysis Tool
é›†æˆçš„å•å›¾åƒCNNæ¨¡å‹åˆ†æå·¥å…· - åŒ…å«é™ç»´å¯è§†åŒ–å’Œæ•°å€¼ç¥ç»å…ƒåˆ†æ
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')  # è®¾ç½®éäº¤äº’å¼åç«¯ï¼Œé€‚åˆæœåŠ¡å™¨ç¯å¢ƒ
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from scipy.stats import pearsonr
import os
import sys
import json
import argparse
import time
from collections import defaultdict
from datetime import datetime
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# ç¡®ä¿ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class SingleImageFeatureExtractor:
    """Single Image Modelç‰¹å¾æå–å™¨"""
    
    def __init__(self, model, device='cuda'):
        self.model = model
        self.device = device
        self.model.eval()
        self.features = {}
        self.hooks = []
        
    def inspect_model_structure(self):
        """æ£€æŸ¥SingleImageClassifieræ¨¡å‹ç»“æ„"""
        print("=== Single Image Model ç»“æ„æ£€æŸ¥ ===")
        available_layers = []
        
        def print_module_structure(module, prefix="", max_depth=3, current_depth=0):
            if current_depth > max_depth:
                return
            
            for name, child in module.named_children():
                full_name = f"{prefix}.{name}" if prefix else name
                print(f"{'  ' * current_depth}{full_name}: {child.__class__.__name__}")
                available_layers.append(full_name)
                
                # é€’å½’æ‰“å°å­æ¨¡å—
                if len(list(child.children())) > 0:
                    print_module_structure(child, full_name, max_depth, current_depth + 1)
        
        print_module_structure(self.model)
        print(f"\næ€»å…±å‘ç° {len(available_layers)} ä¸ªå±‚")
        
        return available_layers
    
    def auto_detect_key_layers(self):
        """è‡ªåŠ¨æ£€æµ‹SingleImageClassifierçš„å…³é”®å±‚"""
        available_layers = self.inspect_model_structure()
        
        # SingleImageClassifierçš„å…³é”®å±‚
        target_layers = [
            'visual_encoder',      # è§†è§‰ç¼–ç å™¨
            'visual_encoder.cnn',  # CNNç‰¹å¾æå–
            'spatial_attention',   # ç©ºé—´æ³¨æ„åŠ›
            'classifier'           # åˆ†ç±»å™¨
        ]
        
        detected_layers = []
        
        # ç²¾ç¡®åŒ¹é…
        for target in target_layers:
            if target in available_layers:
                detected_layers.append(target)
                print(f"âœ… æ£€æµ‹åˆ°å…³é”®å±‚: {target}")
        
        # æ¨¡ç³ŠåŒ¹é…CNNå­å±‚
        cnn_layers = []
        for layer_name in available_layers:
            if 'visual_encoder.cnn' in layer_name and any(x in layer_name.lower() for x in ['conv', 'relu', 'pool']):
                cnn_layers.append(layer_name)
        
        if cnn_layers:
            # é€‰æ‹©ä¸€äº›ä»£è¡¨æ€§çš„CNNå±‚
            selected_cnn = cnn_layers[::max(1, len(cnn_layers)//3)][:3]  # é€‰æ‹©3ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„å±‚
            detected_layers.extend(selected_cnn)
            print(f"ğŸ” æ£€æµ‹åˆ°CNNå­å±‚: {selected_cnn}")
        
        print(f"\nå»ºè®®æå–çš„å±‚: {detected_layers}")
        return detected_layers
        
    def register_hooks(self, layers_to_extract):
        """æ³¨å†Œé’©å­å‡½æ•°æ¥æå–ä¸­é—´å±‚ç‰¹å¾"""
        def get_activation(name):
            def hook(model, input, output):
                if isinstance(output, tuple):
                    # å¦‚æœè¾“å‡ºæ˜¯å…ƒç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                    self.features[name] = output[0].detach().cpu()
                else:
                    self.features[name] = output.detach().cpu()
            return hook
        
        successful_hooks = []
        failed_hooks = []
        
        # æ³¨å†Œé’©å­
        for layer_name in layers_to_extract:
            try:
                # é€šè¿‡ç‚¹å·åˆ†å‰²çš„è·¯å¾„è®¿é—®åµŒå¥—æ¨¡å—
                module = self.model
                for part in layer_name.split('.'):
                    module = getattr(module, part)
                
                handle = module.register_forward_hook(get_activation(layer_name))
                self.hooks.append(handle)
                successful_hooks.append(layer_name)
                print(f"âœ… æˆåŠŸæ³¨å†Œé’©å­: {layer_name}")
                
            except AttributeError as e:
                failed_hooks.append(layer_name)
                print(f"âŒ æ³¨å†Œé’©å­å¤±è´¥: {layer_name} - {e}")
        
        print(f"\né’©å­æ³¨å†Œç»“æœ: æˆåŠŸ {len(successful_hooks)}, å¤±è´¥ {len(failed_hooks)}")
        
        if not successful_hooks and failed_hooks:
            print("âš ï¸ æ²¡æœ‰æˆåŠŸæ³¨å†Œä»»ä½•é’©å­ï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹...")
            auto_layers = self.auto_detect_key_layers()
            if auto_layers:
                print(f"ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹çš„å±‚: {auto_layers}")
                return self.register_hooks(auto_layers[:4])  # åªå–å‰4ä¸ªé¿å…å¤ªå¤š
        
        return successful_hooks
    
    def remove_hooks(self):
        """ç§»é™¤æ‰€æœ‰é’©å­"""
        for handle in self.hooks:
            handle.remove()
        self.hooks = []
        
    def _process_feature_tensor(self, feature_tensor):
        """å¤„ç†ä¸åŒå½¢çŠ¶çš„ç‰¹å¾å¼ é‡"""
        if len(feature_tensor.shape) == 4:  # [batch, channel, h, w]
            # å…¨å±€å¹³å‡æ± åŒ–
            pooled = feature_tensor.mean(dim=(-2, -1))  # [batch, channel]
            return pooled.cpu().numpy()
        elif len(feature_tensor.shape) == 3:  # [batch, seq, dim] æˆ–å…¶ä»–3D
            # å¦‚æœæœ‰åºåˆ—ç»´åº¦ï¼Œå–æœ€åä¸€ä¸ª
            if feature_tensor.shape[1] > feature_tensor.shape[2]:
                # å‡è®¾æ˜¯ [batch, spatial, channel]
                pooled = feature_tensor.mean(dim=1)
            else:
                # å‡è®¾æ˜¯ [batch, channel, spatial]
                pooled = feature_tensor.mean(dim=-1)
            return pooled.cpu().numpy()
        elif len(feature_tensor.shape) == 2:  # [batch, dim]
            return feature_tensor.cpu().numpy()
        else:
            # å…¶ä»–æƒ…å†µï¼Œå±•å¹³
            return feature_tensor.view(feature_tensor.shape[0], -1).cpu().numpy()
    
    def extract_features(self, data_loader, max_samples=1000):
        """æå–ç‰¹å¾å¹¶æ”¶é›†é¢„æµ‹ç»“æœ - é€‚é…SingleImageDataset"""
        all_features = defaultdict(list)
        all_predictions = []
        all_labels = []
        all_sample_ids = []
        
        sample_count = 0
        
        with torch.no_grad():
            for batch in tqdm(data_loader, desc="æå–å•å›¾åƒç‰¹å¾"):
                if sample_count >= max_samples:
                    break
                
                # å•å›¾åƒæ•°æ®æ ¼å¼
                images = batch['image'].to(self.device)
                labels = batch['label'].cpu().numpy()
                sample_ids = batch['sample_id']
                
                # è®¡ç®—å®é™…å¤„ç†çš„æ ·æœ¬æ•°
                remaining_samples = max_samples - sample_count
                actual_batch_size = min(len(labels), remaining_samples)
                
                # æˆªæ–­æ‰¹æ¬¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if actual_batch_size < len(labels):
                    images = images[:actual_batch_size]
                    labels = labels[:actual_batch_size]
                    sample_ids = sample_ids[:actual_batch_size]
                
                # æ¸…ç©ºç‰¹å¾å­—å…¸
                self.features = {}
                
                # å‰å‘ä¼ æ’­
                logits = self.model(images)
                
                # æ”¶é›†é¢„æµ‹ç»“æœ
                pred_labels = torch.argmax(logits, dim=-1).cpu().numpy()
                
                all_predictions.extend(pred_labels)
                all_labels.extend(labels)
                all_sample_ids.extend(sample_ids)
                
                # æ”¶é›†ä¸­é—´å±‚ç‰¹å¾
                for feature_name, feature_tensor in self.features.items():
                    processed_features = self._process_feature_tensor(feature_tensor)
                    all_features[feature_name].append(processed_features)
                
                sample_count += actual_batch_size
                
                if sample_count >= max_samples:
                    break
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        final_features = {}
        for feature_name, feature_list in all_features.items():
            if feature_list:
                final_features[feature_name] = np.vstack(feature_list)
        
        result = {
            'features': final_features,
            'predictions': np.array(all_predictions),
            'labels': np.array(all_labels),
            'sample_ids': all_sample_ids
        }
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"å•å›¾åƒç‰¹å¾æå–å®Œæˆ:")
        print(f"  å®é™…æ ·æœ¬æ•°: {len(result['labels'])}")
        print(f"  çœŸå®æ ‡ç­¾èŒƒå›´: {result['labels'].min()} - {result['labels'].max()}")
        print(f"  é¢„æµ‹æ ‡ç­¾èŒƒå›´: {result['predictions'].min()} - {result['predictions'].max()}")
        print(f"  çœŸå®æ ‡ç­¾å”¯ä¸€å€¼: {sorted(np.unique(result['labels']))}")
        print(f"  é¢„æµ‹æ ‡ç­¾å”¯ä¸€å€¼: {sorted(np.unique(result['predictions']))}")
        print(f"  æå–çš„ç‰¹å¾å±‚: {list(final_features.keys())}")
        
        return result


class NumberLineAnalyzer:
    """Number Lineåˆ†æå™¨"""
    
    def __init__(self, features_dict, labels, layer_names=None):
        """
        Args:
            features_dict: {layer_name: features_array} å„å±‚ç‰¹å¾
            labels: çœŸå®æ•°å€¼æ ‡ç­¾ (1-10)
            layer_names: è¦åˆ†æçš„å±‚åç§°åˆ—è¡¨
        """
        self.features_dict = features_dict
        self.labels = np.array(labels)
        self.layer_names = layer_names or list(features_dict.keys())
        self.results = {}
        
    def find_number_line_neurons(self, layer_name, min_r2=0.5, method='linear'):
        """
        å¯»æ‰¾å…·æœ‰number lineç‰¹æ€§çš„ç¥ç»å…ƒ
        
        Args:
            layer_name: å±‚åç§°
            min_r2: æœ€å°RÂ²é˜ˆå€¼
            method: 'linear', 'log', 'sqrt' - ä¸åŒçš„æ•°å€¼ç¼–ç å‡è®¾
        
        Returns:
            dict: number lineç¥ç»å…ƒçš„åˆ†æç»“æœ
        """
        features = self.features_dict[layer_name]  # [samples, neurons]
        
        if method == 'linear':
            target = self.labels
        elif method == 'log':
            target = np.log(self.labels)
        elif method == 'sqrt':
            target = np.sqrt(self.labels)
        else:
            raise ValueError(f"Unknown method: {method}")
        
        n_neurons = features.shape[1]
        number_line_neurons = []
        
        print(f"ğŸ” åˆ†æ {layer_name} å±‚çš„ {n_neurons} ä¸ªç¥ç»å…ƒ...")
        
        for neuron_idx in tqdm(range(n_neurons), desc="å¯»æ‰¾number lineç¥ç»å…ƒ"):
            neuron_response = features[:, neuron_idx]
            
            # çº¿æ€§å›å½’æ‹Ÿåˆ
            reg = LinearRegression()
            reg.fit(target.reshape(-1, 1), neuron_response)
            predicted = reg.predict(target.reshape(-1, 1))
            
            # è®¡ç®—æ‹Ÿåˆè´¨é‡
            r2 = r2_score(neuron_response, predicted)
            correlation, p_value = pearsonr(target, neuron_response)
            
            if r2 >= min_r2 and p_value < 0.05:
                number_line_neurons.append({
                    'neuron_idx': neuron_idx,
                    'r2_score': r2,
                    'correlation': correlation,
                    'p_value': p_value,
                    'slope': reg.coef_[0],
                    'intercept': reg.intercept_,
                    'response': neuron_response.copy(),
                    'target_values': target.copy()
                })
        
        # æŒ‰RÂ²åˆ†æ•°æ’åº
        number_line_neurons.sort(key=lambda x: x['r2_score'], reverse=True)
        
        result = {
            'layer_name': layer_name,
            'method': method,
            'total_neurons': n_neurons,
            'number_line_neurons': number_line_neurons,
            'proportion': len(number_line_neurons) / n_neurons
        }
        
        print(f"âœ… æ‰¾åˆ° {len(number_line_neurons)} ä¸ªnumber lineç¥ç»å…ƒ "
              f"({result['proportion']:.1%} of total)")
        
        return result
    
    def find_number_selective_neurons(self, layer_name, selectivity_threshold=0.3):
        """
        å¯»æ‰¾æ•°å€¼é€‰æ‹©æ€§ç¥ç»å…ƒ
        
        Args:
            layer_name: å±‚åç§°
            selectivity_threshold: é€‰æ‹©æ€§é˜ˆå€¼
        
        Returns:
            dict: æ•°å€¼é€‰æ‹©æ€§ç¥ç»å…ƒåˆ†æç»“æœ
        """
        features = self.features_dict[layer_name]
        n_neurons = features.shape[1]
        
        # è®¡ç®—æ¯ä¸ªç¥ç»å…ƒå¯¹æ¯ä¸ªæ•°å€¼çš„å¹³å‡å“åº”
        unique_numbers = np.unique(self.labels)
        response_matrix = np.zeros((len(unique_numbers), n_neurons))
        
        for i, num in enumerate(unique_numbers):
            mask = self.labels == num
            if np.sum(mask) > 0:
                response_matrix[i, :] = np.mean(features[mask, :], axis=0)
        
        selective_neurons = []
        
        print(f"ğŸ” åˆ†æ {layer_name} å±‚çš„æ•°å€¼é€‰æ‹©æ€§...")
        
        for neuron_idx in tqdm(range(n_neurons), desc="è®¡ç®—é€‰æ‹©æ€§"):
            responses = response_matrix[:, neuron_idx]
            
            # è®¡ç®—é€‰æ‹©æ€§æŒ‡æ•°
            max_response = np.max(responses)
            min_response = np.min(responses)
            
            if max_response != min_response:
                selectivity_index = (max_response - min_response) / (max_response + min_response + 1e-8)
            else:
                selectivity_index = 0
            
            # æ‰¾åˆ°æœ€ä½³æ•°å€¼
            preferred_number = unique_numbers[np.argmax(responses)]
            
            # è®¡ç®—è°ƒè°æ›²çº¿çš„é”åº¦
            tuning_width = self._calculate_tuning_width(responses, unique_numbers)
            
            if selectivity_index >= selectivity_threshold:
                selective_neurons.append({
                    'neuron_idx': neuron_idx,
                    'selectivity_index': selectivity_index,
                    'preferred_number': preferred_number,
                    'tuning_width': tuning_width,
                    'response_profile': responses.copy(),
                    'max_response': max_response,
                    'response_ratio': max_response / (min_response + 1e-8)
                })
        
        # æŒ‰é€‰æ‹©æ€§æŒ‡æ•°æ’åº
        selective_neurons.sort(key=lambda x: x['selectivity_index'], reverse=True)
        
        result = {
            'layer_name': layer_name,
            'total_neurons': n_neurons,
            'selective_neurons': selective_neurons,
            'proportion': len(selective_neurons) / n_neurons,
            'unique_numbers': unique_numbers,
            'response_matrix': response_matrix
        }
        
        print(f"âœ… æ‰¾åˆ° {len(selective_neurons)} ä¸ªæ•°å€¼é€‰æ‹©æ€§ç¥ç»å…ƒ "
              f"({result['proportion']:.1%} of total)")
        
        return result
    
    def _calculate_tuning_width(self, responses, numbers):
        """è®¡ç®—è°ƒè°æ›²çº¿å®½åº¦"""
        # æ ‡å‡†åŒ–å“åº”
        responses_norm = (responses - np.min(responses)) / (np.max(responses) - np.min(responses) + 1e-8)
        
        # è®¡ç®—åŠé«˜å®½åº¦
        max_idx = np.argmax(responses_norm)
        half_max = responses_norm[max_idx] / 2
        
        # æ‰¾åˆ°åŠé«˜ç‚¹
        left_half = np.where(responses_norm[:max_idx] <= half_max)[0]
        right_half = np.where(responses_norm[max_idx:] <= half_max)[0]
        
        if len(left_half) > 0 and len(right_half) > 0:
            left_bound = left_half[-1] if len(left_half) > 0 else 0
            right_bound = max_idx + right_half[0] if len(right_half) > 0 else len(responses) - 1
            tuning_width = numbers[right_bound] - numbers[left_bound]
        else:
            tuning_width = len(numbers)  # å¾ˆå®½çš„è°ƒè°
        
        return tuning_width


class IntegratedVisualizationEngine:
    """é›†æˆçš„å¯è§†åŒ–å¼•æ“ - åªåŒ…å«å¿…è¦çš„åˆ†æ"""
    
    def __init__(self, figsize=(15, 10)):
        self.figsize = figsize
        
    def reduce_dimensions(self, features, method='tsne', n_components=2):
        """é™ç»´"""
        if method == 'tsne':
            reducer = TSNE(n_components=n_components, random_state=42, perplexity=min(30, len(features)//4))
        elif method == 'pca':
            reducer = PCA(n_components=n_components)
        else:
            raise ValueError(f"Unsupported method: {method}")
        
        reduced_features = reducer.fit_transform(features)
        return reduced_features
    
    def plot_scatter(self, features_2d, labels, title, save_path=None, alpha=0.7):
        """ç»˜åˆ¶æ•£ç‚¹å›¾"""
        plt.figure(figsize=self.figsize)
        
        unique_labels = np.unique(labels)
        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
        
        for i, label in enumerate(unique_labels):
            mask = labels == label
            plt.scatter(features_2d[mask, 0], features_2d[mask, 1], 
                       c=[colors[i]], label=f'Count {label}', alpha=alpha, s=50)
        
        plt.title(title, fontsize=16)
        plt.xlabel('Dimension 1', fontsize=12)
        plt.ylabel('Dimension 2', fontsize=12)
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_number_line_neurons(self, number_line_result, save_path=None, top_n=6):
        """å¯è§†åŒ–number lineç¥ç»å…ƒ"""
        neurons = number_line_result['number_line_neurons'][:top_n]
        layer_name = number_line_result['layer_name']
        
        if not neurons:
            print(f"âš ï¸ {layer_name} å±‚æ²¡æœ‰æ‰¾åˆ°number lineç¥ç»å…ƒ")
            return
        
        n_cols = min(3, len(neurons))
        n_rows = (len(neurons) + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))
        if len(neurons) == 1:
            axes = [axes]
        elif n_rows == 1:
            axes = axes if n_cols > 1 else [axes]
        else:
            axes = axes.flatten()
        
        unique_numbers = np.unique(neurons[0]['target_values'])
        
        for i, neuron in enumerate(neurons):
            if i >= len(axes):
                break
                
            ax = axes[i]
            
            # æ•°å€¼ vs ç¥ç»å…ƒå“åº”
            target_values = neuron['target_values']
            responses = neuron['response']
            
            # è®¡ç®—æ¯ä¸ªæ•°å€¼çš„å¹³å‡å“åº”å’Œæ ‡å‡†å·®
            avg_responses = []
            std_responses = []
            for num in unique_numbers:
                mask = target_values == num
                if np.sum(mask) > 0:
                    avg_responses.append(np.mean(responses[mask]))
                    std_responses.append(np.std(responses[mask]))
                else:
                    avg_responses.append(0)
                    std_responses.append(0)
            
            ax.errorbar(unique_numbers, avg_responses, yerr=std_responses, 
                       marker='o', capsize=5, linewidth=2, markersize=8)
            
            # æ·»åŠ æ‹Ÿåˆçº¿
            reg_line = neuron['slope'] * unique_numbers + neuron['intercept']
            ax.plot(unique_numbers, reg_line, '--', color='red', linewidth=2, alpha=0.7)
            
            ax.set_title(f'Neuron {neuron["neuron_idx"]}\n'
                        f'RÂ² = {neuron["r2_score"]:.3f}, r = {neuron["correlation"]:.3f}')
            ax.set_xlabel('Number')
            ax.set_ylabel('Neural Response')
            ax.grid(True, alpha=0.3)
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(neurons), len(axes)):
            axes[i].axis('off')
        
        fig.suptitle(f'Number Line Neurons - {layer_name}', fontsize=16)
        plt.tight_layout()
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_number_selective_neurons(self, selective_result, save_path=None, top_n=6):
        """å¯è§†åŒ–æ•°å€¼é€‰æ‹©æ€§ç¥ç»å…ƒ"""
        neurons = selective_result['selective_neurons'][:top_n]
        layer_name = selective_result['layer_name']
        unique_numbers = selective_result['unique_numbers']
        
        if not neurons:
            print(f"âš ï¸ {layer_name} å±‚æ²¡æœ‰æ‰¾åˆ°number selectiveç¥ç»å…ƒ")
            return
        
        n_cols = min(3, len(neurons))
        n_rows = (len(neurons) + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))
        if len(neurons) == 1:
            axes = [axes]
        elif n_rows == 1:
            axes = axes if n_cols > 1 else [axes]
        else:
            axes = axes.flatten()
        
        for i, neuron in enumerate(neurons):
            if i >= len(axes):
                break
                
            ax = axes[i]
            
            # è°ƒè°æ›²çº¿
            responses = neuron['response_profile']
            ax.bar(unique_numbers, responses, alpha=0.7, 
                  color='skyblue', edgecolor='navy', linewidth=1)
            
            # æ ‡è®°åå¥½æ•°å€¼
            preferred_idx = np.argmax(responses)
            ax.bar(unique_numbers[preferred_idx], responses[preferred_idx], 
                  color='red', alpha=0.8, label=f'Preferred: {neuron["preferred_number"]}')
            
            ax.set_title(f'Neuron {neuron["neuron_idx"]}\n'
                        f'Selectivity = {neuron["selectivity_index"]:.3f}')
            ax.set_xlabel('Number')
            ax.set_ylabel('Average Response')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(neurons), len(axes)):
            axes[i].axis('off')
        
        fig.suptitle(f'Number Selective Neurons - {layer_name}', fontsize=16)
        plt.tight_layout()
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_layer_comparison(self, all_results, save_path=None):
        """å¯¹æ¯”ä¸åŒå±‚çš„numberç¥ç»å…ƒæ¯”ä¾‹"""
        layer_names = []
        number_line_props = []
        selective_props = []
        
        for layer_name, results in all_results.items():
            layer_names.append(layer_name)
            
            if 'number_line' in results:
                number_line_props.append(results['number_line']['proportion'])
            else:
                number_line_props.append(0)
                
            if 'selective' in results:
                selective_props.append(results['selective']['proportion'])
            else:
                selective_props.append(0)
        
        x = np.arange(len(layer_names))
        width = 0.35
        
        fig, ax = plt.subplots(figsize=(12, 6))
        
        ax.bar(x - width/2, number_line_props, width, label='Number Line Neurons', alpha=0.8)
        ax.bar(x + width/2, selective_props, width, label='Number Selective Neurons', alpha=0.8)
        
        ax.set_xlabel('Layer')
        ax.set_ylabel('Proportion of Neurons')
        ax.set_title('Number Neurons Across Layers')
        ax.set_xticks(x)
        ax.set_xticklabels(layer_names, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()


def load_single_image_model_and_data(checkpoint_path, val_csv, data_root, batch_size=16):
    """åŠ è½½å•å›¾åƒæ¨¡å‹å’Œæ•°æ®"""
    print("ğŸ“¥ åŠ è½½å•å›¾åƒæ¨¡å‹å’Œæ•°æ®...")
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    config = checkpoint['config']
    
    # å¯¼å…¥æ¨¡å‹ç±»
    try:
        from Model_single_image import create_single_image_model
        from DataLoader_single_image import get_single_image_data_loaders
    except ImportError:
        print("âŒ æ— æ³•å¯¼å…¥å•å›¾åƒæ¨¡å‹ç›¸å…³æ¨¡å—")
        raise
    
    # é‡å»ºæ¨¡å‹
    model = create_single_image_model(config)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()
    
    image_mode = config.get('image_mode', 'rgb')
    print(f"âœ… å•å›¾åƒæ¨¡å‹åŠ è½½å®Œæˆ (å›¾åƒæ¨¡å¼: {image_mode}, è®¾å¤‡: {device})")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    _, val_loader = get_single_image_data_loaders(
        train_csv_path=config['train_csv'],
        val_csv_path=val_csv,
        data_root=data_root,
        batch_size=batch_size,
        num_workers=2,
        image_mode=image_mode,
        normalize_images=True
    )
    
    print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆï¼ŒéªŒè¯é›†å¤§å°: {len(val_loader.dataset)}")
    
    return model, val_loader, device, config


def analyze_single_image_integrated(checkpoint_path, val_csv, data_root, 
                                   save_dir='./integrated_analysis', 
                                   max_samples=500, specific_layers=None,
                                   min_r2=0.5, selectivity_threshold=0.3):
    """é›†æˆçš„å•å›¾åƒCNNæ¨¡å‹åˆ†æ - é™ç»´+æ•°å€¼ç¥ç»å…ƒ"""
    
    print("ğŸ–¼ï¸ å¼€å§‹é›†æˆçš„å•å›¾åƒCNNæ¨¡å‹åˆ†æ...")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    
    try:
        # 1. åŠ è½½æ¨¡å‹å’Œæ•°æ®
        model, val_loader, device, config = load_single_image_model_and_data(
            checkpoint_path, val_csv, data_root
        )
        
        # 2. åˆ›å»ºç‰¹å¾æå–å™¨
        feature_extractor = SingleImageFeatureExtractor(model, device)
        
        # 3. ç¡®å®šè¦åˆ†æçš„å±‚
        if specific_layers is None:
            print("ğŸ” è‡ªåŠ¨æ£€æµ‹å…³é”®å±‚...")
            key_layers = feature_extractor.auto_detect_key_layers()
            if not key_layers:
                key_layers = ['visual_encoder', 'classifier']
        else:
            key_layers = specific_layers
        
        print(f"ğŸ“‹ å‡†å¤‡åˆ†æçš„å±‚: {key_layers}")
        
        # 4. æ³¨å†Œé’©å­å¹¶æå–ç‰¹å¾
        successful_layers = feature_extractor.register_hooks(key_layers)
        
        if not successful_layers:
            print("âŒ æ²¡æœ‰æˆåŠŸæ³¨å†Œä»»ä½•é’©å­ï¼")
            return None
        
        try:
            # 5. æå–ç‰¹å¾
            print("ğŸ¯ æå–ç‰¹å¾...")
            data = feature_extractor.extract_features(val_loader, max_samples)
            
            features = data['features']
            predictions = data['predictions']
            true_labels = data['labels']
            
            print(f"âœ… ç‰¹å¾æå–å®Œæˆ:")
            print(f"   æ ·æœ¬æ•°: {len(true_labels)}")
            print(f"   æå–å±‚: {list(features.keys())}")
            
            # 6. åˆ›å»ºå¯è§†åŒ–å¼•æ“
            visualizer = IntegratedVisualizationEngine()
            
            # 7. é™ç»´åˆ†æ - åªä¿ç•™PCAå’Œt-SNE
            print("ğŸ¨ ç”Ÿæˆé™ç»´å¯è§†åŒ–...")
            
            for layer_name, layer_features in features.items():
                if layer_features is None:
                    continue
                    
                print(f"   åˆ†æ {layer_name} å±‚...")
                
                # PCAé™ç»´
                try:
                    features_pca = visualizer.reduce_dimensions(layer_features, 'pca')
                    visualizer.plot_scatter(
                        features_pca, true_labels,
                        f'{layer_name} - PCA',
                        save_path=os.path.join(save_dir, f'{layer_name}_pca.png')
                    )
                except Exception as e:
                    print(f"     PCAåˆ†æå¤±è´¥: {e}")
                
                # t-SNEé™ç»´
                try:
                    features_tsne = visualizer.reduce_dimensions(layer_features, 'tsne')
                    visualizer.plot_scatter(
                        features_tsne, true_labels,
                        f'{layer_name} - t-SNE',
                        save_path=os.path.join(save_dir, f'{layer_name}_tsne.png')
                    )
                except Exception as e:
                    print(f"     t-SNEåˆ†æå¤±è´¥: {e}")
            
            # 8. æ•°å€¼ç¥ç»å…ƒåˆ†æ
            print("ğŸ§  å¼€å§‹æ•°å€¼ç¥ç»å…ƒåˆ†æ...")
            
            # åˆ›å»ºæ•°å€¼ç¥ç»å…ƒåˆ†æå™¨
            number_analyzer = NumberLineAnalyzer(features, true_labels)
            
            all_number_results = {}
            
            for layer_name in features.keys():
                print(f"\nğŸ“Š åˆ†æå±‚: {layer_name}")
                
                layer_results = {}
                
                # Number Lineåˆ†æ
                print("ğŸ” å¯»æ‰¾Number Lineç¥ç»å…ƒ...")
                number_line_result = number_analyzer.find_number_line_neurons(
                    layer_name, min_r2=min_r2, method='linear'
                )
                layer_results['number_line'] = number_line_result
                
                # å¯è§†åŒ–Number Lineç¥ç»å…ƒ
                visualizer.plot_number_line_neurons(
                    number_line_result,
                    save_path=os.path.join(save_dir, f'{layer_name}_number_line_neurons.png')
                )
                
                # Number Selectiveåˆ†æ
                print("ğŸ” å¯»æ‰¾Number Selectiveç¥ç»å…ƒ...")
                selective_result = number_analyzer.find_number_selective_neurons(
                    layer_name, selectivity_threshold=selectivity_threshold
                )
                layer_results['selective'] = selective_result
                
                # å¯è§†åŒ–Number Selectiveç¥ç»å…ƒ
                visualizer.plot_number_selective_neurons(
                    selective_result,
                    save_path=os.path.join(save_dir, f'{layer_name}_number_selective_neurons.png')
                )
                
                all_number_results[layer_name] = layer_results
            
            # 9. è·¨å±‚æ¯”è¾ƒ
            print("\nğŸ“ˆ ç”Ÿæˆè·¨å±‚æ¯”è¾ƒ...")
            visualizer.plot_layer_comparison(
                all_number_results,
                save_path=os.path.join(save_dir, 'number_neurons_layer_comparison.png')
            )
            
            # 10. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            print("ğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
            generate_integrated_report(
                all_number_results, features, true_labels, predictions, config, save_dir
            )
            
            print(f"ğŸ‰ é›†æˆåˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {save_dir}")
            return {
                'features': features,
                'number_results': all_number_results,
                'labels': true_labels,
                'predictions': predictions
            }
            
        finally:
            feature_extractor.remove_hooks()
            
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def generate_integrated_report(all_number_results, features, true_labels, predictions, config, save_dir):
    """ç”Ÿæˆé›†æˆåˆ†ææŠ¥å‘Š"""
    
    from sklearn.metrics import accuracy_score
    
    # åŸºç¡€ç»Ÿè®¡
    accuracy = accuracy_score(true_labels, predictions)
    unique_true = len(np.unique(true_labels))
    unique_pred = len(np.unique(predictions))
    
    # å±‚çº§ç‰¹å¾å¤æ‚åº¦
    layer_complexity = {}
    for layer_name, layer_features in features.items():
        if layer_features is not None:
            layer_complexity[layer_name] = {
                'feature_dim': int(layer_features.shape[1]),
                'feature_variance': float(np.var(layer_features)),
                'feature_range': [float(np.min(layer_features)), float(np.max(layer_features))],
                'feature_mean': float(np.mean(layer_features)),
                'feature_std': float(np.std(layer_features)),
                'effective_rank': float(np.linalg.matrix_rank(layer_features))
            }
    
    # æ•°å€¼ç¥ç»å…ƒæ€»ç»“
    number_neuron_summary = {}
    for layer_name, results in all_number_results.items():
        layer_summary = {}
        
        if 'number_line' in results:
            nl_result = results['number_line']
            layer_summary['number_line'] = {
                'total_neurons': nl_result['total_neurons'],
                'number_line_count': len(nl_result['number_line_neurons']),
                'proportion': nl_result['proportion'],
                'best_r2': max([n['r2_score'] for n in nl_result['number_line_neurons']], default=0),
                'avg_r2': np.mean([n['r2_score'] for n in nl_result['number_line_neurons']]) if nl_result['number_line_neurons'] else 0
            }
        
        if 'selective' in results:
            sel_result = results['selective']
            layer_summary['selective'] = {
                'selective_count': len(sel_result['selective_neurons']),
                'proportion': sel_result['proportion'],
                'best_selectivity': max([n['selectivity_index'] for n in sel_result['selective_neurons']], default=0),
                'avg_selectivity': np.mean([n['selectivity_index'] for n in sel_result['selective_neurons']]) if sel_result['selective_neurons'] else 0
            }
        
        number_neuron_summary[layer_name] = layer_summary
    
    # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
    report = {
        'analysis_type': 'Integrated Single Image CNN Analysis',
        'timestamp': pd.Timestamp.now().isoformat(),
        'model_config': {
            'image_mode': config.get('image_mode', 'rgb'),
            'use_attention': config.get('use_attention', True),
            'num_classes': config.get('num_classes', 10)
        },
        'summary': {
            'total_samples': int(len(true_labels)),
            'overall_accuracy': float(accuracy),
            'unique_true_labels': int(unique_true),
            'unique_predictions': int(unique_pred),
            'analyzed_layers': list(features.keys())
        },
        'layer_complexity': layer_complexity,
        'number_neuron_summary': number_neuron_summary,
        'recommendations': generate_integrated_recommendations(all_number_results, features, accuracy, config)
    }
    
    # ä¿å­˜JSONæŠ¥å‘Š
    try:
        with open(os.path.join(save_dir, 'integrated_analysis_report.json'), 'w') as f:
            json.dump(report, f, indent=2)
        print(f"âœ… JSONæŠ¥å‘Šå·²ä¿å­˜")
    except Exception as e:
        print(f"âš ï¸ JSONæŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
    
    # ç”Ÿæˆå¯è¯»æŠ¥å‘Š
    try:
        with open(os.path.join(save_dir, 'integrated_analysis_summary.txt'), 'w', encoding='utf-8') as f:
            f.write("=== é›†æˆå•å›¾åƒCNNæ¨¡å‹åˆ†ææŠ¥å‘Š ===\n\n")
            f.write(f"åˆ†ææ—¶é—´: {report['timestamp']}\n")
            f.write(f"æ€»æ ·æœ¬æ•°: {report['summary']['total_samples']}\n")
            f.write(f"æ•´ä½“å‡†ç¡®ç‡: {report['summary']['overall_accuracy']:.4f}\n")
            f.write(f"åˆ†æå±‚æ•°: {len(report['summary']['analyzed_layers'])}\n\n")
            
            # æ¨¡å‹é…ç½®
            f.write("=== æ¨¡å‹é…ç½® ===\n")
            for key, value in report['model_config'].items():
                f.write(f"{key}: {value}\n")
            f.write("\n")
            
            # å±‚çº§å¤æ‚åº¦
            f.write("=== å±‚çº§ç‰¹å¾å¤æ‚åº¦ ===\n")
            for layer_name, complexity in layer_complexity.items():
                f.write(f"{layer_name}:\n")
                f.write(f"  ç‰¹å¾ç»´åº¦: {complexity['feature_dim']}\n")
                f.write(f"  ç‰¹å¾æ–¹å·®: {complexity['feature_variance']:.4f}\n")
                f.write(f"  ç‰¹å¾å‡å€¼: {complexity['feature_mean']:.4f}\n")
                f.write(f"  ç‰¹å¾æ ‡å‡†å·®: {complexity['feature_std']:.4f}\n")
                f.write(f"  æœ‰æ•ˆç§©: {complexity['effective_rank']:.1f}\n")
                f.write(f"  æ•°å€¼èŒƒå›´: [{complexity['feature_range'][0]:.4f}, {complexity['feature_range'][1]:.4f}]\n\n")
            
            # æ•°å€¼ç¥ç»å…ƒåˆ†æ
            f.write("=== æ•°å€¼ç¥ç»å…ƒåˆ†æ ===\n")
            for layer_name, summary in number_neuron_summary.items():
                f.write(f"{layer_name}:\n")
                
                if 'number_line' in summary:
                    nl = summary['number_line']
                    f.write(f"  Number Lineç¥ç»å…ƒ:\n")
                    f.write(f"    æ€»ç¥ç»å…ƒæ•°: {nl['total_neurons']}\n")
                    f.write(f"    Number Lineæ•°é‡: {nl['number_line_count']}\n")
                    f.write(f"    æ¯”ä¾‹: {nl['proportion']:.2%}\n")
                    f.write(f"    æœ€ä½³RÂ²: {nl['best_r2']:.3f}\n")
                    f.write(f"    å¹³å‡RÂ²: {nl['avg_r2']:.3f}\n")
                
                if 'selective' in summary:
                    sel = summary['selective']
                    f.write(f"  Number Selectiveç¥ç»å…ƒ:\n")
                    f.write(f"    Selectiveæ•°é‡: {sel['selective_count']}\n")
                    f.write(f"    æ¯”ä¾‹: {sel['proportion']:.2%}\n")
                    f.write(f"    æœ€ä½³é€‰æ‹©æ€§: {sel['best_selectivity']:.3f}\n")
                    f.write(f"    å¹³å‡é€‰æ‹©æ€§: {sel['avg_selectivity']:.3f}\n")
                f.write("\n")
            
            # å»ºè®®
            f.write("=== åˆ†æå»ºè®® ===\n")
            for rec in report['recommendations']:
                f.write(f"â€¢ {rec}\n")
        
        print(f"âœ… æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜")
        
    except Exception as e:
        print(f"âš ï¸ æ–‡æœ¬æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")


def generate_integrated_recommendations(all_number_results, features, accuracy, config):
    """åŸºäºé›†æˆåˆ†æç»“æœç”Ÿæˆå»ºè®®"""
    recommendations = []
    
    # å‡†ç¡®ç‡å»ºè®®
    if accuracy < 0.6:
        recommendations.append("æ¨¡å‹å‡†ç¡®ç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡ã€å¢åŠ è®­ç»ƒè½®æ•°æˆ–è°ƒæ•´å­¦ä¹ ç‡")
    elif accuracy > 0.95:
        recommendations.append("æ¨¡å‹å‡†ç¡®ç‡å¾ˆé«˜ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆï¼Œå»ºè®®åœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯")
    elif accuracy > 0.85:
        recommendations.append("æ¨¡å‹å‡†ç¡®ç‡è‰¯å¥½ï¼Œå¯ä»¥è€ƒè™‘åœ¨æ›´å¤æ‚çš„ä»»åŠ¡ä¸Šæµ‹è¯•")
    
    # æ•°å€¼ç¥ç»å…ƒå»ºè®®
    total_number_line = sum(len(r['number_line']['number_line_neurons']) for r in all_number_results.values() if 'number_line' in r)
    total_selective = sum(len(r['selective']['selective_neurons']) for r in all_number_results.values() if 'selective' in r)
    total_neurons = sum(r['number_line']['total_neurons'] for r in all_number_results.values() if 'number_line' in r)
    
    if total_number_line == 0:
        recommendations.append("æœªå‘ç°Number Lineç¥ç»å…ƒï¼Œæ¨¡å‹å¯èƒ½æ²¡æœ‰å­¦åˆ°æ•°å€¼çš„è¿ç»­è¡¨å¾")
    elif total_number_line / total_neurons < 0.01:
        recommendations.append("Number Lineç¥ç»å…ƒæ¯”ä¾‹å¾ˆä½ï¼Œå»ºè®®å¢åŠ æ•°å€¼ç›¸å…³çš„è®­ç»ƒæ•°æ®æˆ–è°ƒæ•´æ¨¡å‹æ¶æ„")
    elif total_number_line / total_neurons > 0.1:
        recommendations.append("å‘ç°å¤§é‡Number Lineç¥ç»å…ƒï¼Œè¡¨æ˜æ¨¡å‹å¾ˆå¥½åœ°å­¦ä¹ äº†æ•°å€¼çš„çº¿æ€§è¡¨å¾")
    
    if total_selective == 0:
        recommendations.append("æœªå‘ç°Number Selectiveç¥ç»å…ƒï¼Œæ¨¡å‹å¯èƒ½ç¼ºä¹å¯¹ç‰¹å®šæ•°å€¼çš„ä¸“é—¨è¡¨å¾")
    elif total_selective / total_neurons < 0.01:
        recommendations.append("Number Selectiveç¥ç»å…ƒæ¯”ä¾‹å¾ˆä½ï¼Œå¯èƒ½éœ€è¦æ›´å¤šç‰¹å®šæ•°å€¼çš„è®­ç»ƒæ ·æœ¬")
    elif total_selective / total_neurons > 0.05:
        recommendations.append("å‘ç°è¾ƒå¤šNumber Selectiveç¥ç»å…ƒï¼Œè¡¨æ˜æ¨¡å‹å¯¹ä¸åŒæ•°å€¼æœ‰è‰¯å¥½çš„åŒºåˆ†èƒ½åŠ›")
    
    # å±‚çº§åˆ†æå»ºè®®
    layer_number_line_props = {name: r['number_line']['proportion'] for name, r in all_number_results.items() if 'number_line' in r}
    if layer_number_line_props:
        best_layer = max(layer_number_line_props, key=layer_number_line_props.get)
        worst_layer = min(layer_number_line_props, key=layer_number_line_props.get)
        
        if layer_number_line_props[best_layer] > 0.05:
            recommendations.append(f"{best_layer}å±‚æ˜¾ç¤ºå‡ºæœ€å¼ºçš„æ•°å€¼çº¿æ€§ç¼–ç èƒ½åŠ›ï¼Œæ˜¯æ•°å€¼å¤„ç†çš„å…³é”®å±‚")
        if layer_number_line_props[worst_layer] < 0.01:
            recommendations.append(f"{worst_layer}å±‚çš„æ•°å€¼ç¼–ç èƒ½åŠ›è¾ƒå¼±ï¼Œå¯èƒ½æ›´ä¸“æ³¨äºå…¶ä»–ç‰¹å¾")
    
    # ç‰¹å¾ç»´åº¦å»ºè®®
    high_dim_layers = [name for name, feats in features.items() 
                      if feats is not None and feats.shape[1] > 1024]
    if high_dim_layers:
        recommendations.append(f"å±‚ {high_dim_layers} ç‰¹å¾ç»´åº¦å¾ˆé«˜ï¼Œå¯è€ƒè™‘é™ç»´æˆ–æ­£åˆ™åŒ–é˜²æ­¢è¿‡æ‹Ÿåˆ")
    
    return recommendations


def inspect_single_image_model_structure(checkpoint_path):
    """æ£€æŸ¥å•å›¾åƒæ¨¡å‹ç»“æ„"""
    print("ğŸ”¬ æ£€æŸ¥å•å›¾åƒæ¨¡å‹ç»“æ„...")
    
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        config = checkpoint['config']
        
        from Model_single_image import create_single_image_model
        
        model = create_single_image_model(config)
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        
        feature_extractor = SingleImageFeatureExtractor(model, device)
        available_layers = feature_extractor.inspect_model_structure()
        auto_layers = feature_extractor.auto_detect_key_layers()
        
        print(f"\nâœ¨ è‡ªåŠ¨æ£€æµ‹çš„å…³é”®å±‚: {auto_layers}")
        print(f"\nğŸ“‹ æ¨èçš„åˆ†æç­–ç•¥:")
        print("  --mode quick --max_samples 100              # å¿«é€Ÿåˆ†æ")
        print("  --mode full --max_samples 500               # å®Œæ•´åˆ†æ") 
        print("  --layers visual_encoder classifier --max_samples 300  # è‡ªå®šä¹‰å±‚åˆ†æ")
        
        return available_layers, auto_layers
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹ç»“æ„æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    parser = argparse.ArgumentParser(description='é›†æˆçš„å•å›¾åƒCNNæ¨¡å‹åˆ†æå·¥å…·')
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('--checkpoint', type=str, required=True,
                       help='å•å›¾åƒæ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--val_csv', type=str, default='scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_val.csv',
                       help='éªŒè¯é›†CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--data_root', type=str, default='/mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/Ball_counting_CNN/ball_data_collection',
                       help='æ•°æ®æ ¹ç›®å½•')
    
    # åˆ†æé€‰é¡¹
    parser.add_argument('--mode', type=str, default='full',
                       choices=['inspect', 'quick', 'full'],
                       help='åˆ†ææ¨¡å¼')
    parser.add_argument('--save_dir', type=str, default=None,
                       help='ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--max_samples', type=int, default=1100,
                       help='æœ€å¤§åˆ†ææ ·æœ¬æ•°')
    parser.add_argument('--layers', nargs='+', default=None,
                       help='æŒ‡å®šè¦åˆ†æçš„å±‚åç§°')
    
    # æ•°å€¼ç¥ç»å…ƒåˆ†æå‚æ•°
    parser.add_argument('--min_r2', type=float, default=0.5,
                       help='Number Lineç¥ç»å…ƒçš„æœ€å°RÂ²é˜ˆå€¼')
    parser.add_argument('--selectivity_threshold', type=float, default=0.3,
                       help='Number Selectiveç¥ç»å…ƒçš„é€‰æ‹©æ€§é˜ˆå€¼')
    
    # å…¶ä»–é€‰é¡¹
    parser.add_argument('--batch_size', type=int, default=32,
                       help='æ•°æ®åŠ è½½æ‰¹æ¬¡å¤§å°')
    
    args = parser.parse_args()
    
    # è®¾ç½®é»˜è®¤ä¿å­˜ç›®å½•
    if args.save_dir is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        args.save_dir = f'./integrated_single_image_analysis_{args.mode}_{timestamp}'
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    for path, name in [(args.checkpoint, 'æ£€æŸ¥ç‚¹æ–‡ä»¶'), 
                       (args.val_csv, 'éªŒè¯CSVæ–‡ä»¶'), 
                       (args.data_root, 'æ•°æ®æ ¹ç›®å½•')]:
        if not os.path.exists(path):
            print(f"âŒ {name}ä¸å­˜åœ¨: {path}")
            return
    
    print("ğŸ–¼ï¸ é›†æˆçš„å•å›¾åƒCNNæ¨¡å‹åˆ†æå·¥å…·")
    print("="*50)
    print(f"æ¨¡å¼: {args.mode}")
    print(f"æ£€æŸ¥ç‚¹: {args.checkpoint}")
    print(f"éªŒè¯é›†: {args.val_csv}")
    print(f"æ•°æ®æ ¹ç›®å½•: {args.data_root}")
    print(f"ä¿å­˜ç›®å½•: {args.save_dir}")
    print(f"åˆ†æå†…å®¹: é™ç»´å¯è§†åŒ–(PCA+t-SNE) + æ•°å€¼ç¥ç»å…ƒåˆ†æ")
    print("="*50)
    
    start_time = time.time()
    
    try:
        if args.mode == 'inspect':
            print("ğŸ”¬ æ£€æŸ¥æ¨¡å‹ç»“æ„...")
            inspect_single_image_model_structure(args.checkpoint)
        
        elif args.mode == 'quick':
            print("âš¡ å¿«é€Ÿåˆ†æ...")
            results = analyze_single_image_integrated(
                args.checkpoint, args.val_csv, args.data_root, 
                args.save_dir, max_samples=min(100, args.max_samples),
                specific_layers=args.layers,
                min_r2=args.min_r2, 
                selectivity_threshold=args.selectivity_threshold
            )
        
        elif args.mode == 'full':
            print("ğŸ–¼ï¸ å®Œæ•´åˆ†æ...")
            results = analyze_single_image_integrated(
                args.checkpoint, args.val_csv, args.data_root, 
                args.save_dir, args.max_samples, args.layers,
                min_r2=args.min_r2,
                selectivity_threshold=args.selectivity_threshold
            )
        
        elapsed_time = time.time() - start_time
        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"â±ï¸ æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {args.save_dir}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­åˆ†æ")
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œæ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    if len(sys.argv) == 1:
        print("ğŸ–¼ï¸ é›†æˆçš„å•å›¾åƒCNNæ¨¡å‹åˆ†æå·¥å…·")
        print("="*50)
        print("åŠŸèƒ½: é™ç»´å¯è§†åŒ–(PCA+t-SNE) + æ•°å€¼ç¥ç»å…ƒåˆ†æ")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("python integrated_single_image_analysis.py --checkpoint MODEL.pth --val_csv VAL.csv --data_root DATA_DIR")
        print("\nå¯ç”¨æ¨¡å¼:")
        print("  --mode inspect      # æ£€æŸ¥æ¨¡å‹ç»“æ„")
        print("  --mode quick        # å¿«é€Ÿåˆ†æï¼ˆå°‘é‡æ ·æœ¬ï¼‰")
        print("  --mode full         # å®Œæ•´åˆ†æï¼ˆæ¨èï¼‰")
        print("\nåŸºæœ¬ç¤ºä¾‹:")
        print("python integrated_single_image_analysis.py \\")
        print("    --checkpoint ./best_single_image_model.pth \\")
        print("    --val_csv ./val.csv \\")
        print("    --data_root ./data \\")
        print("    --mode full")
        print("\né«˜çº§ç¤ºä¾‹:")
        print("python integrated_single_image_analysis.py \\")
        print("    --checkpoint ./best_single_image_model.pth \\")
        print("    --val_csv ./val.csv \\")
        print("    --data_root ./data \\")
        print("    --mode full \\")
        print("    --layers visual_encoder classifier \\")
        print("    --max_samples 1000 \\")
        print("    --min_r2 0.6 \\")
        print("    --selectivity_threshold 0.4 \\")
        print("    --save_dir ./my_integrated_analysis")
        print("\nğŸ“‹ æ¨èå·¥ä½œæµ:")
        print("1. é¦–å…ˆè¿è¡Œ: --mode inspect    # æŸ¥çœ‹æ¨¡å‹ç»“æ„")
        print("2. ç„¶åè¿è¡Œ: --mode quick      # å¿«é€ŸéªŒè¯")
        print("3. æœ€åè¿è¡Œ: --mode full       # å®Œæ•´åˆ†æ")
        print("\nğŸ’¡ è¾“å‡ºå†…å®¹:")
        print("- å„å±‚PCAå’Œt-SNEé™ç»´å¯è§†åŒ–")
        print("- Number Lineç¥ç»å…ƒåˆ†æå’Œå¯è§†åŒ–")
        print("- Number Selectiveç¥ç»å…ƒåˆ†æå’Œå¯è§†åŒ–")
        print("- è·¨å±‚æ•°å€¼ç¥ç»å…ƒæ¯”ä¾‹å¯¹æ¯”")
        print("- ç»¼åˆåˆ†ææŠ¥å‘Š")
        sys.exit(0)
    
    main()


# =============================================================================
# ä¾¿æ·å‡½æ•°ï¼Œä¾›å…¶ä»–è„šæœ¬è°ƒç”¨
# =============================================================================

def quick_integrated_analysis(checkpoint_path, val_csv, data_root, save_dir=None, max_samples=100):
    """å¿«é€Ÿé›†æˆåˆ†ææ¥å£"""
    if save_dir is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        save_dir = f'./quick_integrated_analysis_{timestamp}'
    
    return analyze_single_image_integrated(
        checkpoint_path, val_csv, data_root, save_dir, max_samples
    )


def full_integrated_analysis(checkpoint_path, val_csv, data_root, save_dir=None, 
                            max_samples=500, layers=None, min_r2=0.5, selectivity_threshold=0.3):
    """å®Œæ•´é›†æˆåˆ†ææ¥å£"""
    if save_dir is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        save_dir = f'./full_integrated_analysis_{timestamp}'
    
    return analyze_single_image_integrated(
        checkpoint_path, val_csv, data_root, save_dir, max_samples, layers,
        min_r2, selectivity_threshold
    )


# =============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# =============================================================================

"""
ä½¿ç”¨ç¤ºä¾‹:

1. å‘½ä»¤è¡Œä½¿ç”¨:
   python integrated_single_image_analysis.py \\
       --checkpoint ./best_single_image_model.pth \\
       --val_csv ./val.csv \\
       --data_root ./data \\
       --mode full \\
       --max_samples 500

2. åœ¨Pythonè„šæœ¬ä¸­ä½¿ç”¨:
   from integrated_single_image_analysis import quick_integrated_analysis, full_integrated_analysis
   
   # å¿«é€Ÿåˆ†æ
   results = quick_integrated_analysis(
       checkpoint_path='./best_single_image_model.pth',
       val_csv='./val.csv', 
       data_root='./data'
   )
   
   # å®Œæ•´åˆ†æ
   results = full_integrated_analysis(
       checkpoint_path='./best_single_image_model.pth',
       val_csv='./val.csv',
       data_root='./data',
       max_samples=1000,
       layers=['visual_encoder', 'classifier'],
       min_r2=0.6,
       selectivity_threshold=0.4
   )

è¾“å‡ºå†…å®¹:
- layer_name_pca.png: PCAé™ç»´å¯è§†åŒ–
- layer_name_tsne.png: t-SNEé™ç»´å¯è§†åŒ–  
- layer_name_number_line_neurons.png: Number Lineç¥ç»å…ƒå¯è§†åŒ–
- layer_name_number_selective_neurons.png: Number Selectiveç¥ç»å…ƒå¯è§†åŒ–
- number_neurons_layer_comparison.png: è·¨å±‚æ•°å€¼ç¥ç»å…ƒæ¯”è¾ƒ
- integrated_analysis_report.json: è¯¦ç»†åˆ†ææŠ¥å‘Š(JSON)
- integrated_analysis_summary.txt: åˆ†ææ€»ç»“æŠ¥å‘Š(æ–‡æœ¬)
""" 