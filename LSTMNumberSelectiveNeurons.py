"""
LSTM Number Selective Neurons and Tuning Curve Analysis Tool
LSTMæ•°å€¼é€‰æ‹©æ€§ç¥ç»å…ƒå’Œè°ƒè°æ›²çº¿åˆ†æå·¥å…·
æ”¯æŒåŸå§‹Embodimentæ¨¡å‹å’Œæ‰€æœ‰Ablationæ¨¡å‹
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯ï¼Œé€‚åˆæœåŠ¡å™¨ç¯å¢ƒ
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from scipy.stats import pearsonr, entropy
from scipy.signal import find_peaks
from scipy.optimize import curve_fit
import os
import sys
import json
import argparse
import time
from collections import defaultdict
from datetime import datetime
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class LSTMFeatureExtractor:
    """LSTMç‰¹å¾æå–å™¨ - ä¸“é—¨æå–LSTMéšçŠ¶æ€"""
    
    def __init__(self, model, device='cuda'):
        self.model = model
        self.device = device
        self.model.eval()
        self.lstm_states_history = []
        self.model_info = self._detect_model_type()
        
        print(f"âœ… æ£€æµ‹åˆ°æ¨¡å‹ç±»å‹: {self.model_info['type']}")
        print(f"   LSTMå±‚: {self.model_info['has_lstm']}")
        
    def _detect_model_type(self):
        """æ£€æµ‹æ¨¡å‹ç±»å‹"""
        model_class_name = self.model.__class__.__name__
        has_lstm = hasattr(self.model, 'lstm')
        
        if hasattr(self.model, 'get_model_info'):
            info = self.model.get_model_info()
            model_type = info.get('model_type', model_class_name)
        else:
            model_type = 'EmbodiedCountingModel'
        
        return {'type': model_type, 'has_lstm': has_lstm}
    
    def _hook_lstm_states(self):
        """é’©å­å‡½æ•°æ¥æ•è·LSTMéšçŠ¶æ€"""
        def lstm_hook(module, input, output):
            # LSTMè¾“å‡ºæ ¼å¼: (output, (h_n, c_n))
            # output: [batch, seq_len, hidden_size]
            # h_n: [num_layers, batch, hidden_size]
            lstm_output, (h_n, c_n) = output
            
            # ä¿å­˜æ¯ä¸ªæ—¶é—´æ­¥çš„éšçŠ¶æ€
            batch_size, seq_len, hidden_size = lstm_output.shape
            
            # è½¬æ¢ä¸º [seq_len, batch, hidden_size] ç„¶åä¿å­˜æ¯ä¸ªæ—¶é—´æ­¥
            lstm_output_transposed = lstm_output.transpose(0, 1)  # [seq_len, batch, hidden_size]
            
            for t in range(seq_len):
                timestep_hidden = lstm_output_transposed[t].detach().cpu()  # [batch, hidden_size]
                self.lstm_states_history.append({
                    'timestep': t,
                    'hidden_states': timestep_hidden,
                    'batch_size': batch_size
                })
        
        # æ³¨å†Œé’©å­
        if hasattr(self.model, 'lstm'):
            handle = self.model.lstm.register_forward_hook(lstm_hook)
            return handle
        else:
            print("âŒ æ¨¡å‹æ²¡æœ‰LSTMå±‚")
            return None
    
    def extract_lstm_features(self, data_loader, max_samples=500):
        """æå–LSTMç‰¹å¾"""
        print("ğŸ§  å¼€å§‹æå–LSTMéšçŠ¶æ€ç‰¹å¾...")
        
        # æ³¨å†ŒLSTMé’©å­
        handle = self._hook_lstm_states()
        if not handle:
            return None
        
        all_labels = []
        all_sample_ids = []
        sample_count = 0
        
        try:
            with torch.no_grad():
                for batch in tqdm(data_loader, desc="æå–LSTMéšçŠ¶æ€"):
                    if sample_count >= max_samples:
                        break
                    
                    # æ¸…ç©ºå†å²è®°å½•
                    self.lstm_states_history = []
                    
                    # å‡†å¤‡æ•°æ®
                    sequence_data = {
                        'images': batch['sequence_data']['images'].to(self.device),
                        'joints': batch['sequence_data']['joints'].to(self.device),
                        'timestamps': batch['sequence_data']['timestamps'].to(self.device),
                        'labels': batch['sequence_data']['labels'].to(self.device)
                    }
                    
                    # è·å–æ‰¹æ¬¡ä¿¡æ¯
                    labels = batch['label'].cpu().numpy()
                    sample_ids = batch['sample_id']
                    
                    # è®¡ç®—å®é™…å¤„ç†çš„æ ·æœ¬æ•°
                    remaining_samples = max_samples - sample_count
                    actual_batch_size = min(len(labels), remaining_samples)
                    
                    # æˆªæ–­æ‰¹æ¬¡
                    if actual_batch_size < len(labels):
                        for key in sequence_data:
                            sequence_data[key] = sequence_data[key][:actual_batch_size]
                        labels = labels[:actual_batch_size]
                        sample_ids = sample_ids[:actual_batch_size]
                    
                    # å‰å‘ä¼ æ’­ - æ ¹æ®æ¨¡å‹ç±»å‹
                    if self.model_info['type'] in ['EmbodiedCountingOnly', 'VisualOnlyCountingModel']:
                        outputs = self.model(sequence_data=sequence_data)
                    else:
                        outputs = self.model(
                            sequence_data=sequence_data,
                            use_teacher_forcing=False
                        )
                    
                    # æ”¶é›†æ ‡ç­¾
                    all_labels.extend(labels)
                    all_sample_ids.extend(sample_ids)
                    
                    sample_count += actual_batch_size
                    
                    if sample_count >= max_samples:
                        break
            
            # å¤„ç†æ”¶é›†åˆ°çš„LSTMçŠ¶æ€
            lstm_data = self._process_lstm_states(all_labels, all_sample_ids)
            return lstm_data
            
        finally:
            # ç§»é™¤é’©å­
            if handle:
                handle.remove()
    
    def _process_lstm_states(self, all_labels, all_sample_ids):
        """å¤„ç†æ”¶é›†åˆ°çš„LSTMçŠ¶æ€"""
        print("ğŸ”„ å¤„ç†LSTMçŠ¶æ€æ•°æ®...")
        
        if not self.lstm_states_history:
            print("âŒ æ²¡æœ‰æ”¶é›†åˆ°LSTMçŠ¶æ€")
            return None
        
        # æŒ‰æ—¶é—´æ­¥ç»„ç»‡æ•°æ®
        timestep_data = defaultdict(list)
        
        current_sample_idx = 0
        
        for state_info in self.lstm_states_history:
            timestep = state_info['timestep']
            hidden_states = state_info['hidden_states']  # [batch, hidden_size]
            batch_size = state_info['batch_size']
            
            # ä¸ºå½“å‰æ‰¹æ¬¡çš„æ¯ä¸ªæ ·æœ¬åˆ†é…æ ‡ç­¾
            for b in range(batch_size):
                if current_sample_idx < len(all_labels):
                    sample_label = all_labels[current_sample_idx]
                    sample_id = all_sample_ids[current_sample_idx]
                    
                    timestep_data[timestep].append({
                        'sample_id': sample_id,
                        'label': sample_label,
                        'hidden_states': hidden_states[b].numpy(),
                        'sample_idx': current_sample_idx
                    })
                    
                    if timestep == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥å¢åŠ æ ·æœ¬ç´¢å¼•
                        current_sample_idx += 1
        
        # è½¬æ¢ä¸ºæœ€ç»ˆæ ¼å¼
        final_data = {}
        for timestep, data_list in timestep_data.items():
            if data_list:
                labels = np.array([d['label'] for d in data_list])
                hidden_states = np.stack([d['hidden_states'] for d in data_list])
                sample_ids = [d['sample_id'] for d in data_list]
                
                final_data[f'timestep_{timestep}'] = {
                    'labels': labels,
                    'hidden_states': hidden_states,  # [samples, hidden_size]
                    'sample_ids': sample_ids
                }
        
        print(f"âœ… LSTMç‰¹å¾æå–å®Œæˆ:")
        print(f"   æ—¶é—´æ­¥æ•°: {len(final_data)}")
        print(f"   æ ·æœ¬æ•°: {len(all_labels)}")
        if final_data:
            first_timestep = list(final_data.keys())[0]
            hidden_size = final_data[first_timestep]['hidden_states'].shape[1]
            print(f"   LSTMéšçŠ¶æ€ç»´åº¦: {hidden_size}")
        
        return final_data


class LSTMNumberAnalyzer:
    """LSTMæ•°å€¼ç¥ç»å…ƒåˆ†æå™¨"""
    
    def __init__(self, lstm_data):
        """
        Args:
            lstm_data: {timestep: {labels, hidden_states, sample_ids}}
        """
        self.lstm_data = lstm_data
        self.timesteps = sorted(lstm_data.keys())
        self.results = {}
        
        # è·å–åŸºæœ¬ä¿¡æ¯
        first_timestep = self.timesteps[0]
        self.hidden_size = lstm_data[first_timestep]['hidden_states'].shape[1]
        self.unique_numbers = np.unique(lstm_data[first_timestep]['labels'])
        
        print(f"ğŸ“Š LSTMæ•°å€¼åˆ†æå™¨åˆå§‹åŒ–:")
        print(f"   æ—¶é—´æ­¥æ•°: {len(self.timesteps)}")
        print(f"   LSTMéšçŠ¶æ€ç»´åº¦: {self.hidden_size}")
        print(f"   æ•°å€¼èŒƒå›´: {self.unique_numbers}")
    
    def find_number_line_neurons(self, timestep_key, min_r2=0.5, method='linear'):
        """å¯»æ‰¾å…·æœ‰number lineç‰¹æ€§çš„LSTMç¥ç»å…ƒ"""
        if timestep_key not in self.lstm_data:
            print(f"âŒ æ—¶é—´æ­¥ {timestep_key} ä¸å­˜åœ¨")
            return None
        
        data = self.lstm_data[timestep_key]
        hidden_states = data['hidden_states']  # [samples, hidden_size]
        labels = data['labels']
        
        if method == 'linear':
            target = labels
        elif method == 'log':
            target = np.log(labels)
        elif method == 'sqrt':
            target = np.sqrt(labels)
        else:
            raise ValueError(f"Unknown method: {method}")
        
        number_line_neurons = []
        
        print(f"ğŸ” åˆ†æ {timestep_key} çš„ {self.hidden_size} ä¸ªLSTMç¥ç»å…ƒ...")
        
        for neuron_idx in tqdm(range(self.hidden_size), desc="å¯»æ‰¾number lineç¥ç»å…ƒ"):
            neuron_response = hidden_states[:, neuron_idx]
            
            # çº¿æ€§å›å½’æ‹Ÿåˆ
            reg = LinearRegression()
            reg.fit(target.reshape(-1, 1), neuron_response)
            predicted = reg.predict(target.reshape(-1, 1))
            
            # è®¡ç®—æ‹Ÿåˆè´¨é‡
            r2 = r2_score(neuron_response, predicted)
            correlation, p_value = pearsonr(target, neuron_response)
            
            if r2 >= min_r2 and p_value < 0.05:
                number_line_neurons.append({
                    'neuron_idx': neuron_idx,
                    'r2_score': r2,
                    'correlation': correlation,
                    'p_value': p_value,
                    'slope': reg.coef_[0],
                    'intercept': reg.intercept_,
                    'response': neuron_response.copy(),
                    'target_values': target.copy(),
                    'labels': labels.copy()
                })
        
        # æŒ‰RÂ²åˆ†æ•°æ’åº
        number_line_neurons.sort(key=lambda x: x['r2_score'], reverse=True)
        
        result = {
            'timestep': timestep_key,
            'method': method,
            'total_neurons': self.hidden_size,
            'number_line_neurons': number_line_neurons,
            'proportion': len(number_line_neurons) / self.hidden_size
        }
        
        print(f"âœ… æ‰¾åˆ° {len(number_line_neurons)} ä¸ªnumber lineç¥ç»å…ƒ "
              f"({result['proportion']:.2%})")
        
        return result
    
    def find_number_selective_neurons(self, timestep_key, selectivity_threshold=0.3):
        """å¯»æ‰¾æ•°å€¼é€‰æ‹©æ€§LSTMç¥ç»å…ƒ"""
        if timestep_key not in self.lstm_data:
            print(f"âŒ æ—¶é—´æ­¥ {timestep_key} ä¸å­˜åœ¨")
            return None
        
        data = self.lstm_data[timestep_key]
        hidden_states = data['hidden_states']
        labels = data['labels']
        
        # è®¡ç®—æ¯ä¸ªç¥ç»å…ƒå¯¹æ¯ä¸ªæ•°å€¼çš„å¹³å‡å“åº”
        response_matrix = np.zeros((len(self.unique_numbers), self.hidden_size))
        response_std_matrix = np.zeros((len(self.unique_numbers), self.hidden_size))
        
        for i, num in enumerate(self.unique_numbers):
            mask = labels == num
            if np.sum(mask) > 0:
                response_matrix[i, :] = np.mean(hidden_states[mask, :], axis=0)
                response_std_matrix[i, :] = np.std(hidden_states[mask, :], axis=0)
        
        selective_neurons = []
        
        print(f"ğŸ” åˆ†æ {timestep_key} çš„æ•°å€¼é€‰æ‹©æ€§...")
        
        for neuron_idx in tqdm(range(self.hidden_size), desc="è®¡ç®—é€‰æ‹©æ€§"):
            responses = response_matrix[:, neuron_idx]
            response_stds = response_std_matrix[:, neuron_idx]
            
            # è®¡ç®—é€‰æ‹©æ€§æŒ‡æ•°
            max_response = np.max(responses)
            min_response = np.min(responses)
            mean_response = np.mean(responses)
            
            if max_response != min_response:
                selectivity_index = (max_response - min_response) / (max_response + min_response + 1e-8)
            else:
                selectivity_index = 0
            
            # è®¡ç®—ä¿¡å™ªæ¯”
            if mean_response != 0:
                signal_to_noise = (max_response - mean_response) / (np.mean(response_stds) + 1e-8)
            else:
                signal_to_noise = 0
            
            # æ‰¾åˆ°æœ€ä½³æ•°å€¼
            preferred_number = self.unique_numbers[np.argmax(responses)]
            preferred_idx = np.argmax(responses)
            
            # è®¡ç®—è°ƒè°æ›²çº¿ç‰¹æ€§
            tuning_properties = self._analyze_tuning_curve(responses, self.unique_numbers)
            
            # è®¡ç®—å“åº”çš„ç†µï¼ˆä½œä¸ºé€‰æ‹©æ€§çš„å¦ä¸€ç§åº¦é‡ï¼‰
            response_prob = responses / (np.sum(responses) + 1e-8)
            response_entropy = entropy(response_prob + 1e-8)
            
            if selectivity_index >= selectivity_threshold:
                selective_neurons.append({
                    'neuron_idx': neuron_idx,
                    'selectivity_index': selectivity_index,
                    'preferred_number': preferred_number,
                    'preferred_idx': preferred_idx,
                    'response_profile': responses.copy(),
                    'response_stds': response_stds.copy(),
                    'max_response': max_response,
                    'min_response': min_response,
                    'response_ratio': max_response / (min_response + 1e-8),
                    'signal_to_noise': signal_to_noise,
                    'response_entropy': response_entropy,
                    **tuning_properties
                })
        
        # æŒ‰é€‰æ‹©æ€§æŒ‡æ•°æ’åº
        selective_neurons.sort(key=lambda x: x['selectivity_index'], reverse=True)
        
        result = {
            'timestep': timestep_key,
            'total_neurons': self.hidden_size,
            'selective_neurons': selective_neurons,
            'proportion': len(selective_neurons) / self.hidden_size,
            'unique_numbers': self.unique_numbers,
            'response_matrix': response_matrix,
            'response_std_matrix': response_std_matrix
        }
        
        print(f"âœ… æ‰¾åˆ° {len(selective_neurons)} ä¸ªæ•°å€¼é€‰æ‹©æ€§ç¥ç»å…ƒ "
              f"({result['proportion']:.2%})")
        
        return result
    
    def _analyze_tuning_curve(self, responses, numbers):
        """åˆ†æè°ƒè°æ›²çº¿ç‰¹æ€§"""
        # æ ‡å‡†åŒ–å“åº”
        responses_norm = (responses - np.min(responses)) / (np.max(responses) - np.min(responses) + 1e-8)
        
        # è®¡ç®—è°ƒè°å®½åº¦ï¼ˆåŠé«˜å®½åº¦ï¼‰
        max_idx = np.argmax(responses_norm)
        half_max = responses_norm[max_idx] / 2
        
        # æ‰¾åˆ°åŠé«˜ç‚¹
        left_indices = np.where(responses_norm[:max_idx] <= half_max)[0]
        right_indices = np.where(responses_norm[max_idx:] <= half_max)[0]
        
        if len(left_indices) > 0 and len(right_indices) > 0:
            left_bound = left_indices[-1]
            right_bound = max_idx + right_indices[0]
            tuning_width = numbers[right_bound] - numbers[left_bound]
        else:
            tuning_width = len(numbers)
        
        # è®¡ç®—è°ƒè°æ›²çº¿çš„é”åº¦
        peak_sharpness = responses_norm[max_idx] / (np.mean(responses_norm) + 1e-8)
        
        # æ£€æµ‹æ˜¯å¦æœ‰å¤šä¸ªå³°
        peaks, _ = find_peaks(responses_norm, height=0.3)
        num_peaks = len(peaks)
        
        # è®¡ç®—è°ƒè°æ›²çº¿çš„åæ–œåº¦
        mean_pos = np.sum(numbers * responses_norm) / (np.sum(responses_norm) + 1e-8)
        preferred_pos = numbers[max_idx]
        skewness = mean_pos - preferred_pos
        
        return {
            'tuning_width': tuning_width,
            'peak_sharpness': peak_sharpness,
            'num_peaks': num_peaks,
            'skewness': skewness,
            'peak_position': preferred_pos
        }
    
    def analyze_temporal_dynamics(self, neuron_idx, analysis_type='selective'):
        """åˆ†æç‰¹å®šç¥ç»å…ƒåœ¨æ—¶é—´ç»´åº¦ä¸Šçš„åŠ¨æ€å˜åŒ–"""
        temporal_data = []
        
        for timestep_key in self.timesteps:
            data = self.lstm_data[timestep_key]
            hidden_states = data['hidden_states']
            labels = data['labels']
            
            if neuron_idx >= hidden_states.shape[1]:
                continue
            
            neuron_response = hidden_states[:, neuron_idx]
            
            if analysis_type == 'selective':
                # è®¡ç®—é€‰æ‹©æ€§
                response_by_number = []
                for num in self.unique_numbers:
                    mask = labels == num
                    if np.sum(mask) > 0:
                        response_by_number.append(np.mean(neuron_response[mask]))
                    else:
                        response_by_number.append(0)
                
                responses = np.array(response_by_number)
                max_resp = np.max(responses)
                min_resp = np.min(responses)
                selectivity = (max_resp - min_resp) / (max_resp + min_resp + 1e-8)
                preferred_number = self.unique_numbers[np.argmax(responses)]
                
                temporal_data.append({
                    'timestep': int(timestep_key.split('_')[1]),
                    'selectivity': selectivity,
                    'preferred_number': preferred_number,
                    'max_response': max_resp,
                    'response_profile': responses
                })
            
            elif analysis_type == 'number_line':
                # è®¡ç®—çº¿æ€§æ‹Ÿåˆè´¨é‡
                reg = LinearRegression()
                reg.fit(labels.reshape(-1, 1), neuron_response)
                predicted = reg.predict(labels.reshape(-1, 1))
                r2 = r2_score(neuron_response, predicted)
                correlation, _ = pearsonr(labels, neuron_response)
                
                temporal_data.append({
                    'timestep': int(timestep_key.split('_')[1]),
                    'r2_score': r2,
                    'correlation': correlation,
                    'slope': reg.coef_[0],
                    'intercept': reg.intercept_
                })
        
        return temporal_data
    
    def find_best_timesteps_for_analysis(self, analysis_type='selective', top_k=3):
        """æ‰¾åˆ°æœ€é€‚åˆåˆ†æçš„æ—¶é—´æ­¥"""
        timestep_scores = []
        
        for timestep_key in self.timesteps:
            if analysis_type == 'selective':
                result = self.find_number_selective_neurons(timestep_key, selectivity_threshold=0.1)
                if result:
                    score = result['proportion']
                    avg_selectivity = np.mean([n['selectivity_index'] for n in result['selective_neurons']]) if result['selective_neurons'] else 0
                    timestep_scores.append((timestep_key, score, avg_selectivity))
            
            elif analysis_type == 'number_line':
                result = self.find_number_line_neurons(timestep_key, min_r2=0.3)
                if result:
                    score = result['proportion']
                    avg_r2 = np.mean([n['r2_score'] for n in result['number_line_neurons']]) if result['number_line_neurons'] else 0
                    timestep_scores.append((timestep_key, score, avg_r2))
        
        # æŒ‰ç»¼åˆåˆ†æ•°æ’åº
        timestep_scores.sort(key=lambda x: x[1] * x[2], reverse=True)
        
        return timestep_scores[:top_k]


class LSTMVisualizationEngine:
    """LSTMå¯è§†åŒ–å¼•æ“"""
    
    def __init__(self, figsize=(15, 10)):
        self.figsize = figsize
    
    def plot_number_line_neurons(self, number_line_result, save_path=None, top_n=6):
        """å¯è§†åŒ–LSTM number lineç¥ç»å…ƒ"""
        neurons = number_line_result['number_line_neurons'][:top_n]
        timestep = number_line_result['timestep']
        
        if not neurons:
            print(f"âš ï¸ {timestep} æ²¡æœ‰æ‰¾åˆ°number lineç¥ç»å…ƒ")
            return
        
        n_cols = min(3, len(neurons))
        n_rows = (len(neurons) + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))
        if len(neurons) == 1:
            axes = [axes]
        elif n_rows == 1:
            axes = axes if n_cols > 1 else [axes]
        else:
            axes = axes.flatten()
        
        for i, neuron in enumerate(neurons):
            if i >= len(axes):
                break
            
            ax = axes[i]
            
            # è®¡ç®—æ¯ä¸ªæ•°å€¼çš„å¹³å‡å“åº”å’Œæ ‡å‡†å·®
            unique_numbers = np.unique(neuron['labels'])
            avg_responses = []
            std_responses = []
            
            for num in unique_numbers:
                mask = neuron['labels'] == num
                if np.sum(mask) > 0:
                    responses = neuron['response'][mask]
                    avg_responses.append(np.mean(responses))
                    std_responses.append(np.std(responses))
                else:
                    avg_responses.append(0)
                    std_responses.append(0)
            
            # ç»˜åˆ¶æ•°æ®ç‚¹å’Œè¯¯å·®æ¡
            ax.errorbar(unique_numbers, avg_responses, yerr=std_responses, 
                       marker='o', capsize=5, linewidth=2, markersize=8, 
                       color='blue', alpha=0.7, label='Data')
            
            # æ·»åŠ æ‹Ÿåˆçº¿
            target_values = neuron['target_values']
            if len(np.unique(target_values)) > 1:
                reg_line = neuron['slope'] * unique_numbers + neuron['intercept']
                ax.plot(unique_numbers, reg_line, '--', color='red', linewidth=2, 
                       label=f'Fit (slope={neuron["slope"]:.3f})')
            
            ax.set_title(f'LSTM Neuron {neuron["neuron_idx"]}\n'
                        f'RÂ² = {neuron["r2_score"]:.3f}, r = {neuron["correlation"]:.3f}')
            ax.set_xlabel('Number')
            ax.set_ylabel('LSTM Hidden State')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(neurons), len(axes)):
            axes[i].axis('off')
        
        fig.suptitle(f'LSTM Number Line Neurons - {timestep}', fontsize=16)
        plt.tight_layout()
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… ä¿å­˜Number Lineç¥ç»å…ƒå›¾: {os.path.basename(save_path) if save_path else 'displayed'}")
    
    def plot_number_selective_neurons(self, selective_result, save_path=None, top_n=6):
        """å¯è§†åŒ–LSTMæ•°å€¼é€‰æ‹©æ€§ç¥ç»å…ƒ"""
        neurons = selective_result['selective_neurons'][:top_n]
        timestep = selective_result['timestep']
        unique_numbers = selective_result['unique_numbers']
        
        if not neurons:
            print(f"âš ï¸ {timestep} æ²¡æœ‰æ‰¾åˆ°number selectiveç¥ç»å…ƒ")
            return
        
        n_cols = min(3, len(neurons))
        n_rows = (len(neurons) + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))
        if len(neurons) == 1:
            axes = [axes]
        elif n_rows == 1:
            axes = axes if n_cols > 1 else [axes]
        else:
            axes = axes.flatten()
        
        for i, neuron in enumerate(neurons):
            if i >= len(axes):
                break
            
            ax = axes[i]
            
            # è°ƒè°æ›²çº¿
            responses = neuron['response_profile']
            response_stds = neuron['response_stds']
            
            # ç»˜åˆ¶æŸ±çŠ¶å›¾å’Œè¯¯å·®æ¡
            bars = ax.bar(unique_numbers, responses, alpha=0.7, 
                         color='skyblue', edgecolor='navy', linewidth=1,
                         yerr=response_stds, capsize=3)
            
            # æ ‡è®°åå¥½æ•°å€¼
            preferred_idx = neuron['preferred_idx']
            bars[preferred_idx].set_color('red')
            bars[preferred_idx].set_alpha(0.9)
            
            # æ·»åŠ è°ƒè°æ›²çº¿ä¿¡æ¯
            info_text = f"Width: {neuron['tuning_width']:.1f}\n"
            info_text += f"Peaks: {neuron['num_peaks']}\n"
            info_text += f"SNR: {neuron['signal_to_noise']:.2f}"
            
            ax.text(0.02, 0.98, info_text, transform=ax.transAxes, 
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                   verticalalignment='top', fontsize=8)
            
            ax.set_title(f'LSTM Neuron {neuron["neuron_idx"]}\n'
                        f'Selectivity = {neuron["selectivity_index"]:.3f}\n'
                        f'Preferred: {neuron["preferred_number"]}')
            ax.set_xlabel('Number')
            ax.set_ylabel('Average LSTM Response')
            ax.grid(True, alpha=0.3)
            
            # è®¾ç½®xè½´
            ax.set_xticks(unique_numbers)
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(neurons), len(axes)):
            axes[i].axis('off')
        
        fig.suptitle(f'LSTM Number Selective Neurons - {timestep}', fontsize=16)
        plt.tight_layout()
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… ä¿å­˜Number Selectiveç¥ç»å…ƒå›¾: {os.path.basename(save_path) if save_path else 'displayed'}")
    
    def plot_temporal_dynamics(self, temporal_data, neuron_idx, analysis_type, save_path=None):
        """å¯è§†åŒ–ç¥ç»å…ƒçš„æ—¶é—´åŠ¨æ€"""
        if not temporal_data:
            print("âš ï¸ æ²¡æœ‰æ—¶é—´åŠ¨æ€æ•°æ®")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        timesteps = [d['timestep'] for d in temporal_data]
        
        if analysis_type == 'selective':
            # é€‰æ‹©æ€§éšæ—¶é—´å˜åŒ–
            selectivities = [d['selectivity'] for d in temporal_data]
            preferred_numbers = [d['preferred_number'] for d in temporal_data]
            max_responses = [d['max_response'] for d in temporal_data]
            
            # 1. é€‰æ‹©æ€§æŒ‡æ•°éšæ—¶é—´å˜åŒ–
            axes[0, 0].plot(timesteps, selectivities, 'o-', linewidth=2, markersize=6)
            axes[0, 0].set_title(f'Selectivity Over Time\nNeuron {neuron_idx}')
            axes[0, 0].set_xlabel('Timestep')
            axes[0, 0].set_ylabel('Selectivity Index')
            axes[0, 0].grid(True, alpha=0.3)
            
            # 2. åå¥½æ•°å€¼éšæ—¶é—´å˜åŒ–
            axes[0, 1].plot(timesteps, preferred_numbers, 'o-', linewidth=2, markersize=6, color='red')
            axes[0, 1].set_title('Preferred Number Over Time')
            axes[0, 1].set_xlabel('Timestep')
            axes[0, 1].set_ylabel('Preferred Number')
            axes[0, 1].grid(True, alpha=0.3)
            axes[0, 1].set_yticks(range(1, 11))
            
            # 3. æœ€å¤§å“åº”å¼ºåº¦éšæ—¶é—´å˜åŒ–
            axes[1, 0].plot(timesteps, max_responses, 'o-', linewidth=2, markersize=6, color='green')
            axes[1, 0].set_title('Maximum Response Over Time')
            axes[1, 0].set_xlabel('Timestep')
            axes[1, 0].set_ylabel('Max Response')
            axes[1, 0].grid(True, alpha=0.3)
            
            # 4. å“åº”è½®å»“çš„çƒ­åŠ›å›¾
            response_profiles = np.array([d['response_profile'] for d in temporal_data])
            unique_numbers = np.arange(1, 11)
            
            im = axes[1, 1].imshow(response_profiles.T, aspect='auto', cmap='viridis', 
                                  extent=[min(timesteps), max(timesteps), 
                                         min(unique_numbers), max(unique_numbers)])
            axes[1, 1].set_title('Response Profile Heatmap')
            axes[1, 1].set_xlabel('Timestep')
            axes[1, 1].set_ylabel('Number')
            axes[1, 1].set_yticks(unique_numbers)
            plt.colorbar(im, ax=axes[1, 1], label='Response')
            
        elif analysis_type == 'number_line':
            # Number lineç‰¹æ€§éšæ—¶é—´å˜åŒ–
            r2_scores = [d['r2_score'] for d in temporal_data]
            correlations = [d['correlation'] for d in temporal_data]
            slopes = [d['slope'] for d in temporal_data]
            intercepts = [d['intercept'] for d in temporal_data]
            
            # 1. RÂ²åˆ†æ•°éšæ—¶é—´å˜åŒ–
            axes[0, 0].plot(timesteps, r2_scores, 'o-', linewidth=2, markersize=6)
            axes[0, 0].set_title(f'RÂ² Score Over Time\nNeuron {neuron_idx}')
            axes[0, 0].set_xlabel('Timestep')
            axes[0, 0].set_ylabel('RÂ² Score')
            axes[0, 0].grid(True, alpha=0.3)
            axes[0, 0].set_ylim(0, 1)
            
            # 2. ç›¸å…³ç³»æ•°éšæ—¶é—´å˜åŒ–
            axes[0, 1].plot(timesteps, correlations, 'o-', linewidth=2, markersize=6, color='red')
            axes[0, 1].set_title('Correlation Over Time')
            axes[0, 1].set_xlabel('Timestep')
            axes[0, 1].set_ylabel('Correlation')
            axes[0, 1].grid(True, alpha=0.3)
            axes[0, 1].set_ylim(-1, 1)
            
            # 3. æ–œç‡éšæ—¶é—´å˜åŒ–
            axes[1, 0].plot(timesteps, slopes, 'o-', linewidth=2, markersize=6, color='green')
            axes[1, 0].set_title('Slope Over Time')
            axes[1, 0].set_xlabel('Timestep')
            axes[1, 0].set_ylabel('Slope')
            axes[1, 0].grid(True, alpha=0.3)
            
            # 4. æˆªè·éšæ—¶é—´å˜åŒ–
            axes[1, 1].plot(timesteps, intercepts, 'o-', linewidth=2, markersize=6, color='purple')
            axes[1, 1].set_title('Intercept Over Time')
            axes[1, 1].set_xlabel('Timestep')
            axes[1, 1].set_ylabel('Intercept')
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… ä¿å­˜æ—¶é—´åŠ¨æ€å›¾: {os.path.basename(save_path) if save_path else 'displayed'}")
    
    def plot_timestep_comparison(self, analyzer, analysis_type='selective', save_path=None):
        """å¯¹æ¯”ä¸åŒæ—¶é—´æ­¥çš„ç¥ç»å…ƒç‰¹æ€§"""
        timestep_data = []
        
        for timestep_key in analyzer.timesteps:
            if analysis_type == 'selective':
                result = analyzer.find_number_selective_neurons(timestep_key, selectivity_threshold=0.1)
                if result:
                    proportion = result['proportion']
                    avg_selectivity = np.mean([n['selectivity_index'] for n in result['selective_neurons']]) if result['selective_neurons'] else 0
                    max_selectivity = max([n['selectivity_index'] for n in result['selective_neurons']]) if result['selective_neurons'] else 0
                    
                    timestep_data.append({
                        'timestep': int(timestep_key.split('_')[1]),
                        'proportion': proportion,
                        'avg_selectivity': avg_selectivity,
                        'max_selectivity': max_selectivity
                    })
            
            elif analysis_type == 'number_line':
                result = analyzer.find_number_line_neurons(timestep_key, min_r2=0.3)
                if result:
                    proportion = result['proportion']
                    avg_r2 = np.mean([n['r2_score'] for n in result['number_line_neurons']]) if result['number_line_neurons'] else 0
                    max_r2 = max([n['r2_score'] for n in result['number_line_neurons']]) if result['number_line_neurons'] else 0
                    
                    timestep_data.append({
                        'timestep': int(timestep_key.split('_')[1]),
                        'proportion': proportion,
                        'avg_r2': avg_r2,
                        'max_r2': max_r2
                    })
        
        if not timestep_data:
            print("âš ï¸ æ²¡æœ‰æ—¶é—´æ­¥æ•°æ®")
            return
        
        timesteps = [d['timestep'] for d in timestep_data]
        proportions = [d['proportion'] for d in timestep_data]
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. ç¥ç»å…ƒæ¯”ä¾‹éšæ—¶é—´å˜åŒ–
        axes[0, 0].plot(timesteps, proportions, 'o-', linewidth=2, markersize=8, color='blue')
        axes[0, 0].set_title(f'{analysis_type.title()} Neuron Proportion Over Time')
        axes[0, 0].set_xlabel('Timestep')
        axes[0, 0].set_ylabel('Proportion of Neurons')
        axes[0, 0].grid(True, alpha=0.3)
        axes[0, 0].set_ylim(0, max(proportions) * 1.1 if proportions else 0.1)
        
        if analysis_type == 'selective':
            avg_selectivities = [d['avg_selectivity'] for d in timestep_data]
            max_selectivities = [d['max_selectivity'] for d in timestep_data]
            
            # 2. å¹³å‡é€‰æ‹©æ€§
            axes[0, 1].plot(timesteps, avg_selectivities, 'o-', linewidth=2, markersize=8, color='red')
            axes[0, 1].set_title('Average Selectivity Over Time')
            axes[0, 1].set_xlabel('Timestep')
            axes[0, 1].set_ylabel('Average Selectivity')
            axes[0, 1].grid(True, alpha=0.3)
            
            # 3. æœ€å¤§é€‰æ‹©æ€§
            axes[1, 0].plot(timesteps, max_selectivities, 'o-', linewidth=2, markersize=8, color='green')
            axes[1, 0].set_title('Maximum Selectivity Over Time')
            axes[1, 0].set_xlabel('Timestep')
            axes[1, 0].set_ylabel('Maximum Selectivity')
            axes[1, 0].grid(True, alpha=0.3)
            
            # 4. ç»¼åˆåˆ†æ
            combined_scores = [p * a for p, a in zip(proportions, avg_selectivities)]
            axes[1, 1].plot(timesteps, combined_scores, 'o-', linewidth=2, markersize=8, color='purple')
            axes[1, 1].set_title('Combined Score (Proportion Ã— Avg Selectivity)')
            axes[1, 1].set_xlabel('Timestep')
            axes[1, 1].set_ylabel('Combined Score')
            axes[1, 1].grid(True, alpha=0.3)
            
        elif analysis_type == 'number_line':
            avg_r2s = [d['avg_r2'] for d in timestep_data]
            max_r2s = [d['max_r2'] for d in timestep_data]
            
            # 2. å¹³å‡RÂ²
            axes[0, 1].plot(timesteps, avg_r2s, 'o-', linewidth=2, markersize=8, color='red')
            axes[0, 1].set_title('Average RÂ² Over Time')
            axes[0, 1].set_xlabel('Timestep')
            axes[0, 1].set_ylabel('Average RÂ²')
            axes[0, 1].grid(True, alpha=0.3)
            axes[0, 1].set_ylim(0, 1)
            
            # 3. æœ€å¤§RÂ²
            axes[1, 0].plot(timesteps, max_r2s, 'o-', linewidth=2, markersize=8, color='green')
            axes[1, 0].set_title('Maximum RÂ² Over Time')
            axes[1, 0].set_xlabel('Timestep')
            axes[1, 0].set_ylabel('Maximum RÂ²')
            axes[1, 0].grid(True, alpha=0.3)
            axes[1, 0].set_ylim(0, 1)
            
            # 4. ç»¼åˆåˆ†æ
            combined_scores = [p * r for p, r in zip(proportions, avg_r2s)]
            axes[1, 1].plot(timesteps, combined_scores, 'o-', linewidth=2, markersize=8, color='purple')
            axes[1, 1].set_title('Combined Score (Proportion Ã— Avg RÂ²)')
            axes[1, 1].set_xlabel('Timestep')
            axes[1, 1].set_ylabel('Combined Score')
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… ä¿å­˜æ—¶é—´æ­¥å¯¹æ¯”å›¾: {os.path.basename(save_path) if save_path else 'displayed'}")


def load_model_and_data(checkpoint_path, val_csv, data_root, batch_size=8):
    """é€šç”¨æ¨¡å‹å’Œæ•°æ®åŠ è½½å‡½æ•°"""
    print("ğŸ“¥ åŠ è½½æ¨¡å‹å’Œæ•°æ®...")
    
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    config = checkpoint['config']
    
    # ç¡®å®šå›¾åƒæ¨¡å¼
    image_mode = config.get('image_mode', 'rgb')
    
    # æ£€æŸ¥æ¨¡å‹ç±»å‹
    model_type = checkpoint.get('model_type', 'embodied')
    
    if model_type in ['counting_only', 'visual_only']:
        # Ablationæ¨¡å‹
        from Model_embodiment_ablation import create_ablation_model
        model = create_ablation_model(model_type, config)
        print(f"âœ… åŠ è½½æ¶ˆèå®éªŒæ¨¡å‹: {model_type}")
    else:
        # åŸå§‹Embodimentæ¨¡å‹
        from Model_embodiment import EmbodiedCountingModel
        input_channels = 3 if image_mode == 'rgb' else 1
        model_config = config['model_config'].copy()
        model_config['input_channels'] = input_channels
        model = EmbodiedCountingModel(**model_config)
        print("âœ… åŠ è½½åŸå§‹å…·èº«è®¡æ•°æ¨¡å‹")
    
    model.load_state_dict(checkpoint['model_state_dict'])
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()
    
    print(f"   å›¾åƒæ¨¡å¼: {image_mode}, è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from DataLoader_embodiment import get_ball_counting_data_loaders
    
    _, val_loader, _ = get_ball_counting_data_loaders(
        train_csv_path=config['train_csv'],
        val_csv_path=val_csv,
        data_root=data_root,
        batch_size=batch_size,
        sequence_length=config['sequence_length'],
        normalize=config['normalize'],
        num_workers=2,
        image_mode=image_mode
    )
    
    print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆï¼ŒéªŒè¯é›†å¤§å°: {len(val_loader.dataset)}")
    
    return model, val_loader, device, config


def analyze_lstm_number_neurons(checkpoint_path, val_csv, data_root, 
                               save_dir='./lstm_number_analysis', 
                               max_samples=500, 
                               min_r2=0.5, selectivity_threshold=0.3,
                               analyze_temporal=True):
    """LSTMæ•°å€¼ç¥ç»å…ƒåˆ†æä¸»å‡½æ•°"""
    
    print("ğŸ§  å¼€å§‹LSTMæ•°å€¼ç¥ç»å…ƒåˆ†æ...")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    
    try:
        # 1. åŠ è½½æ¨¡å‹å’Œæ•°æ®
        model, val_loader, device, config = load_model_and_data(
            checkpoint_path, val_csv, data_root
        )
        
        # 2. åˆ›å»ºLSTMç‰¹å¾æå–å™¨
        extractor = LSTMFeatureExtractor(model, device)
        
        if not extractor.model_info['has_lstm']:
            print("âŒ æ¨¡å‹æ²¡æœ‰LSTMå±‚ï¼Œæ— æ³•åˆ†æ")
            return None
        
        # 3. æå–LSTMç‰¹å¾
        lstm_data = extractor.extract_lstm_features(val_loader, max_samples)
        
        if not lstm_data:
            print("âŒ LSTMç‰¹å¾æå–å¤±è´¥")
            return None
        
        # 4. åˆ›å»ºåˆ†æå™¨
        analyzer = LSTMNumberAnalyzer(lstm_data)
        
        # 5. åˆ›å»ºå¯è§†åŒ–å¼•æ“
        visualizer = LSTMVisualizationEngine()
        
        # 6. æ‰¾åˆ°æœ€ä½³åˆ†ææ—¶é—´æ­¥
        print("ğŸ” å¯»æ‰¾æœ€ä½³åˆ†ææ—¶é—´æ­¥...")
        best_timesteps_selective = analyzer.find_best_timesteps_for_analysis('selective', top_k=3)
        best_timesteps_number_line = analyzer.find_best_timesteps_for_analysis('number_line', top_k=3)
        
        print(f"âœ… æœ€ä½³é€‰æ‹©æ€§æ—¶é—´æ­¥: {[t[0] for t in best_timesteps_selective]}")
        print(f"âœ… æœ€ä½³Number Lineæ—¶é—´æ­¥: {[t[0] for t in best_timesteps_number_line]}")
        
        analysis_results = {}
        
        # 7. åˆ†æå…³é”®æ—¶é—´æ­¥
        key_timesteps = set([t[0] for t in best_timesteps_selective] + 
                           [t[0] for t in best_timesteps_number_line])
        
        for timestep_key in sorted(key_timesteps):
            print(f"\nğŸ“Š åˆ†ææ—¶é—´æ­¥: {timestep_key}")
            
            timestep_results = {}
            
            # Number Lineåˆ†æ
            print("ğŸ” Number Lineç¥ç»å…ƒåˆ†æ...")
            number_line_result = analyzer.find_number_line_neurons(
                timestep_key, min_r2=min_r2, method='linear'
            )
            
            if number_line_result:
                timestep_results['number_line'] = number_line_result
                
                # å¯è§†åŒ–
                visualizer.plot_number_line_neurons(
                    number_line_result,
                    save_path=os.path.join(save_dir, f'{timestep_key}_number_line_neurons.png')
                )
            
            # Number Selectiveåˆ†æ
            print("ğŸ” Number Selectiveç¥ç»å…ƒåˆ†æ...")
            selective_result = analyzer.find_number_selective_neurons(
                timestep_key, selectivity_threshold=selectivity_threshold
            )
            
            if selective_result:
                timestep_results['selective'] = selective_result
                
                # å¯è§†åŒ–
                visualizer.plot_number_selective_neurons(
                    selective_result,
                    save_path=os.path.join(save_dir, f'{timestep_key}_number_selective_neurons.png')
                )
            
            analysis_results[timestep_key] = timestep_results
        
        # 8. æ—¶é—´æ­¥å¯¹æ¯”åˆ†æ
        print("\nğŸ“ˆ ç”Ÿæˆæ—¶é—´æ­¥å¯¹æ¯”åˆ†æ...")
        visualizer.plot_timestep_comparison(
            analyzer, 'selective',
            save_path=os.path.join(save_dir, 'timestep_comparison_selective.png')
        )
        
        visualizer.plot_timestep_comparison(
            analyzer, 'number_line',
            save_path=os.path.join(save_dir, 'timestep_comparison_number_line.png')
        )
        
        # 9. æ—¶é—´åŠ¨æ€åˆ†æï¼ˆå¯é€‰ï¼‰
        if analyze_temporal:
            print("\nâ±ï¸ åˆ†æé€‰å®šç¥ç»å…ƒçš„æ—¶é—´åŠ¨æ€...")
            
            # é€‰æ‹©å‡ ä¸ªæœ‰ä»£è¡¨æ€§çš„ç¥ç»å…ƒè¿›è¡Œæ—¶é—´åŠ¨æ€åˆ†æ
            for timestep_key in list(key_timesteps)[:2]:  # åªåˆ†æå‰ä¸¤ä¸ªæ—¶é—´æ­¥
                if timestep_key in analysis_results:
                    results = analysis_results[timestep_key]
                    
                    # é€‰æ‹©æ€§ç¥ç»å…ƒæ—¶é—´åŠ¨æ€
                    if 'selective' in results and results['selective']['selective_neurons']:
                        best_selective_neuron = results['selective']['selective_neurons'][0]
                        neuron_idx = best_selective_neuron['neuron_idx']
                        
                        temporal_data = analyzer.analyze_temporal_dynamics(neuron_idx, 'selective')
                        if temporal_data:
                            visualizer.plot_temporal_dynamics(
                                temporal_data, neuron_idx, 'selective',
                                save_path=os.path.join(save_dir, f'temporal_dynamics_selective_neuron_{neuron_idx}.png')
                            )
                    
                    # Number lineç¥ç»å…ƒæ—¶é—´åŠ¨æ€
                    if 'number_line' in results and results['number_line']['number_line_neurons']:
                        best_nl_neuron = results['number_line']['number_line_neurons'][0]
                        neuron_idx = best_nl_neuron['neuron_idx']
                        
                        temporal_data = analyzer.analyze_temporal_dynamics(neuron_idx, 'number_line')
                        if temporal_data:
                            visualizer.plot_temporal_dynamics(
                                temporal_data, neuron_idx, 'number_line',
                                save_path=os.path.join(save_dir, f'temporal_dynamics_number_line_neuron_{neuron_idx}.png')
                            )
        
        # 10. ç”Ÿæˆåˆ†ææŠ¥å‘Š
        print("ğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        generate_lstm_analysis_report(analysis_results, analyzer, config, save_dir)
        
        print(f"ğŸ‰ LSTMæ•°å€¼ç¥ç»å…ƒåˆ†æå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {save_dir}")
        
        return {
            'lstm_data': lstm_data,
            'analysis_results': analysis_results,
            'analyzer': analyzer,
            'config': config
        }
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def generate_lstm_analysis_report(analysis_results, analyzer, config, save_dir):
    """ç”ŸæˆLSTMåˆ†ææŠ¥å‘Š"""
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_timesteps = len(analyzer.timesteps)
    analyzed_timesteps = len(analysis_results)
    hidden_size = analyzer.hidden_size
    unique_numbers = analyzer.unique_numbers
    
    # æ”¶é›†ç»Ÿè®¡æ•°æ®
    timestep_stats = {}
    overall_stats = {
        'number_line_neurons': [],
        'selective_neurons': [],
        'total_number_line': 0,
        'total_selective': 0
    }
    
    for timestep_key, results in analysis_results.items():
        timestep_stat = {'timestep': timestep_key}
        
        if 'number_line' in results:
            nl_result = results['number_line']
            timestep_stat['number_line'] = {
                'count': len(nl_result['number_line_neurons']),
                'proportion': nl_result['proportion'],
                'best_r2': max([n['r2_score'] for n in nl_result['number_line_neurons']], default=0),
                'avg_r2': np.mean([n['r2_score'] for n in nl_result['number_line_neurons']]) if nl_result['number_line_neurons'] else 0
            }
            overall_stats['total_number_line'] += len(nl_result['number_line_neurons'])
            overall_stats['number_line_neurons'].extend([n['r2_score'] for n in nl_result['number_line_neurons']])
        
        if 'selective' in results:
            sel_result = results['selective']
            timestep_stat['selective'] = {
                'count': len(sel_result['selective_neurons']),
                'proportion': sel_result['proportion'],
                'best_selectivity': max([n['selectivity_index'] for n in sel_result['selective_neurons']], default=0),
                'avg_selectivity': np.mean([n['selectivity_index'] for n in sel_result['selective_neurons']]) if sel_result['selective_neurons'] else 0
            }
            overall_stats['total_selective'] += len(sel_result['selective_neurons'])
            overall_stats['selective_neurons'].extend([n['selectivity_index'] for n in sel_result['selective_neurons']])
        
        timestep_stats[timestep_key] = timestep_stat
    
    # è®¡ç®—æ•´ä½“ç»Ÿè®¡
    if overall_stats['number_line_neurons']:
        overall_stats['avg_r2_all'] = np.mean(overall_stats['number_line_neurons'])
        overall_stats['max_r2_all'] = max(overall_stats['number_line_neurons'])
    else:
        overall_stats['avg_r2_all'] = 0
        overall_stats['max_r2_all'] = 0
    
    if overall_stats['selective_neurons']:
        overall_stats['avg_selectivity_all'] = np.mean(overall_stats['selective_neurons'])
        overall_stats['max_selectivity_all'] = max(overall_stats['selective_neurons'])
    else:
        overall_stats['avg_selectivity_all'] = 0
        overall_stats['max_selectivity_all'] = 0
    
    # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
    report = {
        'analysis_type': 'LSTM Number Neurons Analysis',
        'timestamp': pd.Timestamp.now().isoformat(),
        'model_config': {
            'model_type': config.get('model_type', 'unknown'),
            'image_mode': config.get('image_mode', 'rgb'),
            'sequence_length': config.get('sequence_length', 'unknown'),
            'lstm_hidden_size': hidden_size
        },
        'analysis_summary': {
            'total_timesteps': total_timesteps,
            'analyzed_timesteps': analyzed_timesteps,
            'lstm_hidden_size': hidden_size,
            'number_range': f"{min(unique_numbers)}-{max(unique_numbers)}",
            'total_number_line_neurons': overall_stats['total_number_line'],
            'total_selective_neurons': overall_stats['total_selective'],
            'avg_r2_all_timesteps': overall_stats['avg_r2_all'],
            'max_r2_all_timesteps': overall_stats['max_r2_all'],
            'avg_selectivity_all_timesteps': overall_stats['avg_selectivity_all'],
            'max_selectivity_all_timesteps': overall_stats['max_selectivity_all']
        },
        'timestep_details': timestep_stats
    }
    
    # ä¿å­˜JSONæŠ¥å‘Š
    try:
        with open(os.path.join(save_dir, 'lstm_analysis_report.json'), 'w') as f:
            json.dump(report, f, indent=2)
        print(f"âœ… JSONæŠ¥å‘Šå·²ä¿å­˜")
    except Exception as e:
        print(f"âš ï¸ JSONæŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
    
    # ç”Ÿæˆå¯è¯»æŠ¥å‘Š
    try:
        with open(os.path.join(save_dir, 'lstm_analysis_summary.txt'), 'w', encoding='utf-8') as f:
            f.write("=== LSTMæ•°å€¼ç¥ç»å…ƒåˆ†ææŠ¥å‘Š ===\n\n")
            f.write(f"åˆ†ææ—¶é—´: {report['timestamp']}\n")
            f.write(f"æ¨¡å‹ç±»å‹: {report['model_config']['model_type']}\n")
            f.write(f"LSTMéšçŠ¶æ€ç»´åº¦: {hidden_size}\n")
            f.write(f"æ•°å€¼èŒƒå›´: {report['analysis_summary']['number_range']}\n")
            f.write(f"æ€»æ—¶é—´æ­¥æ•°: {total_timesteps}\n")
            f.write(f"åˆ†ææ—¶é—´æ­¥æ•°: {analyzed_timesteps}\n\n")
            
            f.write("=== æ•´ä½“ç»Ÿè®¡ ===\n")
            f.write(f"æ€»Number Lineç¥ç»å…ƒ: {overall_stats['total_number_line']}\n")
            f.write(f"æ€»Number Selectiveç¥ç»å…ƒ: {overall_stats['total_selective']}\n")
            f.write(f"å¹³å‡RÂ²åˆ†æ•°: {overall_stats['avg_r2_all']:.3f}\n")
            f.write(f"æœ€å¤§RÂ²åˆ†æ•°: {overall_stats['max_r2_all']:.3f}\n")
            f.write(f"å¹³å‡é€‰æ‹©æ€§æŒ‡æ•°: {overall_stats['avg_selectivity_all']:.3f}\n")
            f.write(f"æœ€å¤§é€‰æ‹©æ€§æŒ‡æ•°: {overall_stats['max_selectivity_all']:.3f}\n\n")
            
            f.write("=== å„æ—¶é—´æ­¥è¯¦æƒ… ===\n")
            for timestep_key, stats in timestep_stats.items():
                f.write(f"\n{timestep_key}:\n")
                
                if 'number_line' in stats:
                    nl = stats['number_line']
                    f.write(f"  Number Lineç¥ç»å…ƒ:\n")
                    f.write(f"    æ•°é‡: {nl['count']}\n")
                    f.write(f"    æ¯”ä¾‹: {nl['proportion']:.2%}\n")
                    f.write(f"    æœ€ä½³RÂ²: {nl['best_r2']:.3f}\n")
                    f.write(f"    å¹³å‡RÂ²: {nl['avg_r2']:.3f}\n")
                
                if 'selective' in stats:
                    sel = stats['selective']
                    f.write(f"  Number Selectiveç¥ç»å…ƒ:\n")
                    f.write(f"    æ•°é‡: {sel['count']}\n")
                    f.write(f"    æ¯”ä¾‹: {sel['proportion']:.2%}\n")
                    f.write(f"    æœ€ä½³é€‰æ‹©æ€§: {sel['best_selectivity']:.3f}\n")
                    f.write(f"    å¹³å‡é€‰æ‹©æ€§: {sel['avg_selectivity']:.3f}\n")
            
            f.write("\n=== åˆ†æç»“è®º ===\n")
            if overall_stats['total_number_line'] > 0:
                f.write("â€¢ å‘ç°äº†Number Lineç¥ç»å…ƒï¼Œè¡¨æ˜LSTMå­¦ä¹ äº†æ•°å€¼çš„çº¿æ€§è¡¨å¾\n")
            else:
                f.write("â€¢ æœªå‘ç°Number Lineç¥ç»å…ƒï¼ŒLSTMå¯èƒ½ä½¿ç”¨å…¶ä»–æ–¹å¼ç¼–ç æ•°å€¼\n")
            
            if overall_stats['total_selective'] > 0:
                f.write("â€¢ å‘ç°äº†Number Selectiveç¥ç»å…ƒï¼Œè¡¨æ˜LSTMå¯¹ç‰¹å®šæ•°å€¼æœ‰ä¸“é—¨åŒ–å“åº”\n")
            else:
                f.write("â€¢ æœªå‘ç°Number Selectiveç¥ç»å…ƒï¼ŒLSTMå¯èƒ½ä½¿ç”¨åˆ†å¸ƒå¼æ•°å€¼è¡¨å¾\n")
        
        print(f"âœ… å¯è¯»æŠ¥å‘Šå·²ä¿å­˜")
    except Exception as e:
        print(f"âš ï¸ å¯è¯»æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='LSTMæ•°å€¼é€‰æ‹©æ€§ç¥ç»å…ƒå’Œè°ƒè°æ›²çº¿åˆ†æå·¥å…·')
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('--checkpoint', type=str, required=True,
                       help='æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--val_csv', type=str,
                        default='scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_val.csv',
                       help='éªŒè¯é›†CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--data_root', type=str, 
                        default='/mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/Ball_counting_CNN/ball_data_collection',
                       help='æ•°æ®æ ¹ç›®å½•')
    
    # å¯é€‰å‚æ•°
    parser.add_argument('--save_dir', type=str, default='./lstm_number_analysis',
                       help='ç»“æœä¿å­˜ç›®å½• (é»˜è®¤: ./lstm_number_analysis)')
    parser.add_argument('--max_samples', type=int, default=1000,
                       help='æœ€å¤§åˆ†ææ ·æœ¬æ•° (é»˜è®¤: 500)')
    parser.add_argument('--min_r2', type=float, default=0.3,
                       help='Number Lineç¥ç»å…ƒæœ€å°RÂ²é˜ˆå€¼ (é»˜è®¤: 0.5)')
    parser.add_argument('--selectivity_threshold', type=float, default=0.1,
                       help='é€‰æ‹©æ€§ç¥ç»å…ƒé˜ˆå€¼ (é»˜è®¤: 0.3)')
    parser.add_argument('--batch_size', type=int, default=16,
                       help='æ‰¹æ¬¡å¤§å° (é»˜è®¤: 8)')
    parser.add_argument('--device', type=str, default='cuda',
                       help='è®¾å¤‡ (é»˜è®¤: cuda)')
    parser.add_argument('--no_temporal', action='store_true',
                       help='è·³è¿‡æ—¶é—´åŠ¨æ€åˆ†æ')
    
    return parser.parse_args()


def print_usage_info():
    """æ‰“å°ä½¿ç”¨ä¿¡æ¯"""
    print("ğŸ§  LSTMæ•°å€¼é€‰æ‹©æ€§ç¥ç»å…ƒå’Œè°ƒè°æ›²çº¿åˆ†æå·¥å…·")
    print("="*60)
    print("æ­¤å·¥å…·åˆ†æLSTMä¸­çš„æ•°å€¼ç¼–ç ç¥ç»å…ƒï¼ŒåŒ…æ‹¬:")
    print("  â€¢ Number Lineç¥ç»å…ƒ: å¯¹æ•°å€¼æœ‰çº¿æ€§å“åº”çš„ç¥ç»å…ƒ")
    print("  â€¢ Number Selectiveç¥ç»å…ƒ: å¯¹ç‰¹å®šæ•°å€¼é«˜åº¦é€‰æ‹©æ€§çš„ç¥ç»å…ƒ")
    print("  â€¢ è°ƒè°æ›²çº¿åˆ†æ: ç¥ç»å…ƒçš„æ•°å€¼åå¥½å’Œè°ƒè°ç‰¹æ€§")
    print("  â€¢ æ—¶é—´åŠ¨æ€: ç¥ç»å…ƒç‰¹æ€§åœ¨åºåˆ—ä¸­çš„å˜åŒ–")
    print()
    print("æ”¯æŒçš„æ¨¡å‹ç±»å‹:")
    print("  â€¢ åŸå§‹å…·èº«è®¡æ•°æ¨¡å‹ (EmbodiedCountingModel)")
    print("  â€¢ æ¶ˆèå®éªŒæ¨¡å‹ (counting_only, visual_only)")
    print()
    print("ä½¿ç”¨æ–¹æ³•:")
    print("python lstm_number_analysis.py --checkpoint MODEL.pth --val_csv VAL.csv --data_root DATA_DIR")
    print()
    print("ç¤ºä¾‹:")
    print("python lstm_number_analysis.py \\")
    print("    --checkpoint ./best_model.pth \\")
    print("    --val_csv ./validation_dataset.csv \\")
    print("    --data_root ./ball_data_collection \\")
    print("    --save_dir ./lstm_analysis_results \\")
    print("    --max_samples 1000 \\")
    print("    --min_r2 0.6 \\")
    print("    --selectivity_threshold 0.4")
    print()
    print("å¯é€‰å‚æ•°è¯´æ˜:")
    print("  --save_dir: ç»“æœä¿å­˜ç›®å½•")
    print("  --max_samples: åˆ†æçš„æœ€å¤§æ ·æœ¬æ•° (è¶Šå¤šè¶Šå‡†ç¡®ä½†è¶Šæ…¢)")
    print("  --min_r2: Number Lineç¥ç»å…ƒçš„æœ€å°RÂ²é˜ˆå€¼ (è¶Šé«˜è¶Šä¸¥æ ¼)")
    print("  --selectivity_threshold: é€‰æ‹©æ€§ç¥ç»å…ƒé˜ˆå€¼ (è¶Šé«˜è¶Šä¸¥æ ¼)")
    print("  --batch_size: æ•°æ®åŠ è½½æ‰¹æ¬¡å¤§å°")
    print("  --device: è®¡ç®—è®¾å¤‡ (cuda/cpu)")
    print("  --no_temporal: è·³è¿‡æ—¶é—´åŠ¨æ€åˆ†æ (åŠ å¿«é€Ÿåº¦)")
    print()
    print("è¾“å‡ºæ–‡ä»¶:")
    print("  â€¢ timestep_X_number_line_neurons.png: Number Lineç¥ç»å…ƒå¯è§†åŒ–")
    print("  â€¢ timestep_X_number_selective_neurons.png: é€‰æ‹©æ€§ç¥ç»å…ƒå¯è§†åŒ–")
    print("  â€¢ timestep_comparison_*.png: æ—¶é—´æ­¥å¯¹æ¯”")
    print("  â€¢ temporal_dynamics_*.png: æ—¶é—´åŠ¨æ€åˆ†æ")
    print("  â€¢ lstm_analysis_report.json: è¯¦ç»†åˆ†ææŠ¥å‘Š")
    print("  â€¢ lstm_analysis_summary.txt: å¯è¯»åˆ†ææ€»ç»“")
    print()
    print("ğŸ’¡ å»ºè®®:")
    print("  â€¢ é¦–æ¬¡è¿è¡Œå¯ä»¥ç”¨è¾ƒå°‘æ ·æœ¬æ•° (å¦‚200) å¿«é€Ÿæµ‹è¯•")
    print("  â€¢ å¯¹äºå‘è¡¨è®ºæ–‡çš„åˆ†æï¼Œå»ºè®®ä½¿ç”¨1000+æ ·æœ¬")
    print("  â€¢ å¦‚æœå‘ç°å¾ˆå°‘ç¥ç»å…ƒï¼Œå¯ä»¥é™ä½é˜ˆå€¼å‚æ•°")
    print("  â€¢ ä½¿ç”¨GPUå¯ä»¥æ˜¾è‘—åŠ å¿«åˆ†æé€Ÿåº¦")


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) == 1:
        print_usage_info()
        return
    
    # è§£æå‚æ•°
    args = parse_arguments()
    
    print("ğŸ§  LSTMæ•°å€¼é€‰æ‹©æ€§ç¥ç»å…ƒå’Œè°ƒè°æ›²çº¿åˆ†æ")
    print("="*50)
    print(f"æ¨¡å‹æ£€æŸ¥ç‚¹: {args.checkpoint}")
    print(f"éªŒè¯æ•°æ®: {args.val_csv}")
    print(f"æ•°æ®æ ¹ç›®å½•: {args.data_root}")
    print(f"ä¿å­˜ç›®å½•: {args.save_dir}")
    print(f"æœ€å¤§æ ·æœ¬æ•°: {args.max_samples}")
    print(f"Number Line RÂ²é˜ˆå€¼: {args.min_r2}")
    print(f"é€‰æ‹©æ€§é˜ˆå€¼: {args.selectivity_threshold}")
    print(f"è®¾å¤‡: {args.device}")
    print(f"æ—¶é—´åŠ¨æ€åˆ†æ: {not args.no_temporal}")
    print("="*50)
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.checkpoint):
        print(f"âŒ æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {args.checkpoint}")
        return
    
    if not os.path.exists(args.val_csv):
        print(f"âŒ éªŒè¯CSVæ–‡ä»¶ä¸å­˜åœ¨: {args.val_csv}")
        return
    
    if not os.path.exists(args.data_root):
        print(f"âŒ æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {args.data_root}")
        return
    
    # è¿è¡Œåˆ†æ
    try:
        start_time = time.time()
        
        results = analyze_lstm_number_neurons(
            checkpoint_path=args.checkpoint,
            val_csv=args.val_csv,
            data_root=args.data_root,
            save_dir=args.save_dir,
            max_samples=args.max_samples,
            min_r2=args.min_r2,
            selectivity_threshold=args.selectivity_threshold,
            analyze_temporal=not args.no_temporal
        )
        
        end_time = time.time()
        
        if results:
            print(f"\nğŸ‰ åˆ†ææˆåŠŸå®Œæˆ!")
            print(f"â±ï¸ æ€»è€—æ—¶: {end_time - start_time:.1f} ç§’")
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {args.save_dir}")
            
            # æ‰“å°å…³é”®ç»“æœæ‘˜è¦
            analysis_results = results['analysis_results']
            if analysis_results:
                print(f"\nğŸ“Š å…³é”®å‘ç°:")
                
                total_nl_neurons = sum(
                    len(res.get('number_line', {}).get('number_line_neurons', []))
                    for res in analysis_results.values()
                )
                
                total_sel_neurons = sum(
                    len(res.get('selective', {}).get('selective_neurons', []))
                    for res in analysis_results.values()
                )
                
                print(f"  â€¢ å‘ç° {total_nl_neurons} ä¸ªNumber Lineç¥ç»å…ƒ")
                print(f"  â€¢ å‘ç° {total_sel_neurons} ä¸ªNumber Selectiveç¥ç»å…ƒ")
                print(f"  â€¢ åˆ†æäº† {len(analysis_results)} ä¸ªå…³é”®æ—¶é—´æ­¥")
                
                # æœ€ä½³æ—¶é—´æ­¥
                best_timestep = max(analysis_results.keys()) if analysis_results else None
                if best_timestep and 'selective' in analysis_results[best_timestep]:
                    sel_result = analysis_results[best_timestep]['selective']
                    best_proportion = sel_result['proportion']
                    print(f"  â€¢ æœ€ä½³æ—¶é—´æ­¥ {best_timestep}: {best_proportion:.1%} çš„ç¥ç»å…ƒæœ‰é€‰æ‹©æ€§")
            
            print(f"\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
            generated_files = []
            for root, dirs, files in os.walk(args.save_dir):
                for file in files:
                    if file.endswith(('.png', '.json', '.txt')):
                        rel_path = os.path.relpath(os.path.join(root, file), args.save_dir)
                        generated_files.append(rel_path)
            
            for file in sorted(generated_files):
                print(f"  â€¢ {file}")
            
        else:
            print(f"\nâŒ åˆ†æå¤±è´¥")
            
    except KeyboardInterrupt:
        print(f"\nâ¸ï¸ åˆ†æè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def quick_test():
    """å¿«é€Ÿæµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª è¿è¡Œå¿«é€Ÿæµ‹è¯•...")
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ ä¸€äº›å¿«é€Ÿæµ‹è¯•ä»£ç 
    # æ¯”å¦‚æµ‹è¯•æ¨¡å‹åŠ è½½ã€æ•°æ®å¤„ç†ç­‰åŸºæœ¬åŠŸèƒ½
    
    print("âœ… å¿«é€Ÿæµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()