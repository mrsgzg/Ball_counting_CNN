"""
AlexNetå…·èº«æ¨¡å‹å®Œæ•´è®­ç»ƒè„šæœ¬ - ä¿®å¤ç‰ˆ
ä¿æŒä¸çº¯è§†è§‰è®­ç»ƒç‰ˆæœ¬ä¸€è‡´çš„ç»“æ„ï¼Œä¿®å¤TensorBoardæ˜¾ç¤ºå¼‚å¸¸é—®é¢˜
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
import numpy as np
import pandas as pd
import os
import time
import csv
from datetime import datetime
from sklearn.metrics import confusion_matrix
from tqdm import tqdm
import argparse
import json
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®matplotlibä¸ºéäº¤äº’å¼åç«¯
plt.switch_backend('Agg')

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å‹å’Œæ•°æ®åŠ è½½å™¨
from Model_alexnet_embodiment import create_model
from DataLoader_embodiment import get_ball_counting_data_loaders


class EmbodiedTrainer:
    """å…·èº«æ¨¡å‹è®­ç»ƒå™¨ - ä¿®å¤ç‰ˆï¼Œä¸çº¯è§†è§‰è®­ç»ƒä¿æŒä¸€è‡´çš„ç»“æ„"""
    
    def __init__(self, model, train_loader, val_loader, config, device, log_dir, checkpoint_dir):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.config = config
        self.device = device
        self.checkpoint_dir = checkpoint_dir
        
        # åˆ›å»ºcheckpointç›®å½•
        os.makedirs(self.checkpoint_dir, exist_ok=True)
        
        # TensorBoardè®°å½•å™¨
        self.writer = SummaryWriter(log_dir)
        
        # ä¼˜åŒ–å™¨ - ä¸çº¯è§†è§‰æ¨¡å‹ä¿æŒä¸€è‡´
        self.optimizer = optim.Adam(
            model.parameters(),
            lr=config['learning_rate'],
            betas=config.get('adam_betas', (0.9, 0.999)),
            weight_decay=config.get('weight_decay', 1e-5)
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = self._create_scheduler()
        
        # æ¢¯åº¦è£å‰ªé˜ˆå€¼
        self.grad_clip_norm = config.get('grad_clip_norm', 1.0)
        
        # æŸå¤±æƒé‡
        self.embodiment_loss_weight = config.get('embodiment_loss_weight', 0.3)
        self.attention_loss_weight = config.get('attention_loss_weight', 0.1)
        
        # è®­ç»ƒçŠ¶æ€è®°å½•
        self.best_val_accuracy = 0.0
        self.best_val_loss = float('inf')
        self.training_history = []
        
        # è®°å½•é…ç½®åˆ°TensorBoard
        config_text = f"Model: {config['model_type']}\n"
        config_text += f"Learning Rate: {config['learning_rate']}\n"
        config_text += f"Batch Size: {config['batch_size']}\n"
        config_text += f"Embodiment Loss Weight: {self.embodiment_loss_weight}\n"
        config_text += f"Image Mode: {config.get('image_mode', 'rgb')}\n"
        self.writer.add_text('Config', config_text, 0)
        
    def _create_scheduler(self):
        """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨ - ä¸çº¯è§†è§‰æ¨¡å‹ä¿æŒä¸€è‡´"""
        scheduler_type = self.config.get('scheduler_type', 'none')
        
        if scheduler_type == 'cosine':
            return optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer, T_max=self.config.get('total_epochs', 1000)
            )
        elif scheduler_type == 'plateau':
            return optim.lr_scheduler.ReduceLROnPlateau(
                self.optimizer, mode='min', factor=0.5,
                patience=self.config.get('scheduler_patience', 5)
            )
        else:
            return None
    
    def compute_loss(self, outputs, targets):
        """è®¡ç®—æŸå¤± - ä¿®å¤ç»´åº¦é—®é¢˜"""
        losses = {}
        
        # 1. è®¡æ•°åˆ†ç±»æŸå¤±
        count_logits = outputs['counts']  # [batch, seq_len, 11]
        target_counts = targets['labels'].long()  # [batch, seq_len]
        
        # å±•å¹³ç”¨äºè®¡ç®—æŸå¤±
        batch_size, seq_len = count_logits.shape[:2]
        count_loss = F.cross_entropy(
            count_logits.view(-1, 11),
            target_counts.view(-1),
            ignore_index=-1
        )
        losses['count_loss'] = count_loss
        
        # 2. åŠ¨ä½œå›å½’æŸå¤±ï¼ˆé¢„æµ‹ä¸‹ä¸€å¸§çš„å…³èŠ‚ä½ç½®ï¼‰
        if outputs['joints'].shape[1] > 1:
            pred_joints = outputs['joints'][:, :-1]  # [batch, seq_len-1, 7]
            target_joints = targets['joints'][:, 1:]  # [batch, seq_len-1, 7]
            motion_loss = F.mse_loss(pred_joints, target_joints)
        else:
            motion_loss = torch.tensor(0.0, device=self.device)
        losses['motion_loss'] = motion_loss
        
        # 3. æ³¨æ„åŠ›æ­£åˆ™åŒ–æŸå¤±ï¼ˆå¯é€‰ï¼‰
        if 'attention_weights' in outputs:
            attention_weights = outputs['attention_weights']  # [batch, seq_len, H, W]
            batch_size, seq_len, H, W = attention_weights.shape
            attention_flat = attention_weights.view(batch_size * seq_len, -1)
            # è®¡ç®—ç†µä½œä¸ºæ­£åˆ™åŒ–
            attention_entropy = -(attention_flat * torch.log(attention_flat + 1e-8)).sum(dim=1).mean()
            losses['attention_loss'] = -attention_entropy  # è´Ÿç†µï¼Œé¼“åŠ±é›†ä¸­æ³¨æ„åŠ›
        else:
            losses['attention_loss'] = torch.tensor(0.0, device=self.device)
        
        # æ€»æŸå¤±
        total_loss = (count_loss + 
                     self.embodiment_loss_weight * motion_loss +
                     self.attention_loss_weight * losses['attention_loss'])
        losses['total_loss'] = total_loss
        
        return losses
    
    def compute_metrics(self, outputs, targets):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡ - ä¿®å¤å‡†ç¡®ç‡è®¡ç®—"""
        metrics = {}
        
        # è®¡æ•°åˆ†ç±»æŒ‡æ ‡
        count_logits = outputs['counts']  # [batch, seq_len, 11]
        pred_labels = torch.argmax(count_logits, dim=-1)  # [batch, seq_len]
        target_counts = targets['labels'].long()  # [batch, seq_len]
        
        # 1. åºåˆ—å‡†ç¡®ç‡ï¼ˆæ‰€æœ‰æ—¶é—´æ­¥çš„å¹³å‡ï¼‰
        valid_mask = target_counts >= 0
        if valid_mask.sum() > 0:
            metrics['count_accuracy'] = (pred_labels[valid_mask] == target_counts[valid_mask]).float().mean().item()
        else:
            metrics['count_accuracy'] = 0.0
        
        # 2. æœ€ç»ˆè®¡æ•°å‡†ç¡®ç‡ï¼ˆåºåˆ—æœ€åä¸€ä¸ªæ—¶é—´æ­¥ï¼‰
        final_pred = pred_labels[:, -1]
        final_target = target_counts[:, -1]
        metrics['final_count_accuracy'] = (final_pred == final_target).float().mean().item()
        
        # 3. çœŸå®æœ€ç»ˆè®¡æ•°å‡†ç¡®ç‡ï¼ˆè€ƒè™‘å®é™…åºåˆ—é•¿åº¦ï¼‰
        batch_size = pred_labels.shape[0]
        true_final_correct = 0
        
        for i in range(batch_size):
            # æ‰¾åˆ°çœŸå®çš„æœ€ç»ˆä½ç½®ï¼ˆæœ€å¤§æ ‡ç­¾å€¼çš„ä½ç½®ï¼‰
            max_label = target_counts[i].max()
            final_positions = (target_counts[i] == max_label).nonzero(as_tuple=True)[0]
            if len(final_positions) > 0:
                true_final_pos = final_positions[0].item()
                if pred_labels[i, true_final_pos] == target_counts[i, true_final_pos]:
                    true_final_correct += 1
        
        metrics['true_final_count_accuracy'] = true_final_correct / batch_size
        
        # 4. åŠ¨ä½œæŒ‡æ ‡
        if outputs['joints'].shape[1] > 1:
            pred_joints = outputs['joints'][:, :-1]
            target_joints = targets['joints'][:, 1:]
            metrics['joint_mse'] = F.mse_loss(pred_joints, target_joints).item()
            metrics['joint_mae'] = F.l1_loss(pred_joints, target_joints).item()
        else:
            metrics['joint_mse'] = 0.0
            metrics['joint_mae'] = 0.0
        
        return metrics
    
    def compute_per_digit_accuracy(self, all_preds, all_labels):
        """è®¡ç®—æ¯ä¸ªæ•°å­—çš„å‡†ç¡®ç‡"""
        per_digit_acc = {}
        
        # å±•å¹³é¢„æµ‹å’Œæ ‡ç­¾
        all_preds_flat = all_preds.view(-1)
        all_labels_flat = all_labels.view(-1)
        
        # è¿‡æ»¤æœ‰æ•ˆæ ‡ç­¾
        valid_mask = all_labels_flat >= 0
        all_preds_flat = all_preds_flat[valid_mask]
        all_labels_flat = all_labels_flat[valid_mask]
        
        for digit in range(11):  # 0-10çš„çƒæ•°
            mask = all_labels_flat == digit
            if mask.sum() > 0:
                digit_acc = (all_preds_flat[mask] == all_labels_flat[mask]).float().mean().item()
                per_digit_acc[f'digit_{digit}_accuracy'] = digit_acc
            else:
                per_digit_acc[f'digit_{digit}_accuracy'] = 0.0
        
        return per_digit_acc
    
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        total_count = 0
        epoch_metrics = defaultdict(float)
        
        # æ”¶é›†æ‰€æœ‰é¢„æµ‹ç”¨äºè®¡ç®—per-digit accuracy
        all_preds = []
        all_labels = []
        
        # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡
        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch}', leave=False)
        
        for batch_idx, batch in enumerate(pbar):
            # æ•°æ®å‡†å¤‡
            sequence_data = {
                'images': batch['sequence_data']['images'].to(self.device),
                'joints': batch['sequence_data']['joints'].to(self.device),
                'timestamps': batch['sequence_data']['timestamps'].to(self.device),
                'labels': batch['sequence_data']['labels'].to(self.device)
            }
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(
                sequence_data=sequence_data,
                use_teacher_forcing=True,
                return_attention=True  # è·å–æ³¨æ„åŠ›æƒé‡ç”¨äºå¯è§†åŒ–
            )
            
            # è®¡ç®—æŸå¤±
            targets = {
                'labels': sequence_data['labels'],
                'joints': sequence_data['joints']
            }
            losses = self.compute_loss(outputs, targets)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            losses['total_loss'].backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip_norm)
            
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += losses['total_loss'].item()
            total_count += 1
            
            # è®¡ç®—æŒ‡æ ‡
            with torch.no_grad():
                batch_metrics = self.compute_metrics(outputs, targets)
                for key, value in batch_metrics.items():
                    epoch_metrics[key] += value
                
                # æ”¶é›†é¢„æµ‹
                count_logits = outputs['counts']
                pred_labels = torch.argmax(count_logits, dim=-1)
                all_preds.append(pred_labels.cpu())
                all_labels.append(sequence_data['labels'].cpu())
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': losses['total_loss'].item(), 
                'acc': batch_metrics['count_accuracy']
            })
            
            # è®°å½•batchçº§åˆ«çš„æŸå¤±åˆ°TensorBoard
            global_step = epoch * len(self.train_loader) + batch_idx
            self.writer.add_scalar('Batch/Train_Loss', losses['total_loss'].item(), global_step)
            self.writer.add_scalar('Batch/Count_Loss', losses['count_loss'].item(), global_step)
            self.writer.add_scalar('Batch/Motion_Loss', losses['motion_loss'].item(), global_step)
        
        # è®¡ç®—epochçº§åˆ«çš„æŒ‡æ ‡
        avg_loss = total_loss / total_count
        avg_metrics = {key: value / total_count for key, value in epoch_metrics.items()}
        
        # åˆå¹¶æ‰€æœ‰é¢„æµ‹
        all_preds = torch.cat(all_preds, dim=0)
        all_labels = torch.cat(all_labels, dim=0)
        
        # è®¡ç®—per-digit accuracy
        per_digit_metrics = self.compute_per_digit_accuracy(all_preds, all_labels)
        avg_metrics.update(per_digit_metrics)
        
        # è®°å½•åˆ°TensorBoard
        self.writer.add_scalar('Epoch/Train_Loss', avg_loss, epoch)
        self.writer.add_scalar('Epoch/Train_Count_Accuracy', avg_metrics['count_accuracy'], epoch)
        self.writer.add_scalar('Epoch/Train_Final_Accuracy', avg_metrics['final_count_accuracy'], epoch)
        
        # è®°å½•MotionæŒ‡æ ‡
        self.writer.add_scalar('Epoch/Train_Joint_MSE', avg_metrics['joint_mse'], epoch)
        self.writer.add_scalar('Epoch/Train_Joint_MAE', avg_metrics['joint_mae'], epoch)
        
        for key, value in per_digit_metrics.items():
            self.writer.add_scalar(f'Train/{key}', value, epoch)
        
        return avg_loss, avg_metrics
    
    @torch.no_grad()
    def validate(self, epoch):
        """éªŒè¯ - åŒ…å«æ¯ä¸ªæ•°å­—çš„å‡†ç¡®ç‡å’Œæ··æ·†çŸ©é˜µ"""
        self.model.eval()
        total_loss = 0
        total_metrics = defaultdict(float)
        total_count = 0
        
        # æ”¶é›†æ‰€æœ‰é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
        all_preds = []
        all_labels = []
        all_final_preds = []
        all_final_labels = []
        
        for batch in self.val_loader:
            # æ•°æ®å‡†å¤‡
            sequence_data = {
                'images': batch['sequence_data']['images'].to(self.device),
                'joints': batch['sequence_data']['joints'].to(self.device),
                'timestamps': batch['sequence_data']['timestamps'].to(self.device),
                'labels': batch['sequence_data']['labels'].to(self.device)
            }
            
            # å‰å‘ä¼ æ’­ï¼ˆä¸ä½¿ç”¨teacher forcingï¼‰
            outputs = self.model(
                sequence_data=sequence_data,
                use_teacher_forcing=False,
                return_attention=True
            )
            
            # è®¡ç®—æŸå¤±
            targets = {
                'labels': sequence_data['labels'],
                'joints': sequence_data['joints']
            }
            losses = self.compute_loss(outputs, targets)
            total_loss += losses['total_loss'].item()
            
            # è®¡ç®—æŒ‡æ ‡
            metrics = self.compute_metrics(outputs, targets)
            for key, value in metrics.items():
                total_metrics[key] += value
            
            # æ”¶é›†é¢„æµ‹
            count_logits = outputs['counts']
            pred_labels = torch.argmax(count_logits, dim=-1)
            all_preds.append(pred_labels.cpu())
            all_labels.append(sequence_data['labels'].cpu())
            
            # æ”¶é›†æœ€ç»ˆé¢„æµ‹ï¼ˆç”¨äºæ··æ·†çŸ©é˜µï¼‰
            all_final_preds.append(pred_labels[:, -1].cpu())
            all_final_labels.append(sequence_data['labels'][:, -1].cpu())
            
            total_count += 1
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_loss = total_loss / total_count
        avg_metrics = {key: value / total_count for key, value in total_metrics.items()}
        
        # åˆå¹¶æ‰€æœ‰é¢„æµ‹
        all_preds = torch.cat(all_preds, dim=0)
        all_labels = torch.cat(all_labels, dim=0)
        all_final_preds = torch.cat(all_final_preds, dim=0)
        all_final_labels = torch.cat(all_final_labels, dim=0)
        
        # è®¡ç®—per-digit accuracy
        per_digit_metrics = self.compute_per_digit_accuracy(all_preds, all_labels)
        avg_metrics.update(per_digit_metrics)
        
        # è®¡ç®—æ··æ·†çŸ©é˜µï¼ˆåŸºäºæœ€ç»ˆé¢„æµ‹ï¼‰
        cm = confusion_matrix(all_final_labels.numpy(), all_final_preds.numpy(), labels=list(range(11)))
        
        # ç»˜åˆ¶å¹¶ä¿å­˜æ··æ·†çŸ©é˜µ
        plt.figure(figsize=(12, 10))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=range(11), yticklabels=range(11))
        plt.title(f'Confusion Matrix - Epoch {epoch}')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        
        # ä¿å­˜å›¾åƒåˆ°TensorBoard
        self.writer.add_figure('Confusion_Matrix', plt.gcf(), epoch)
        plt.close()
        
        # è®°å½•åˆ°TensorBoard
        self.writer.add_scalar('Epoch/Val_Loss', avg_loss, epoch)
        self.writer.add_scalar('Epoch/Val_Count_Accuracy', avg_metrics['count_accuracy'], epoch)
        self.writer.add_scalar('Epoch/Val_Final_Accuracy', avg_metrics['final_count_accuracy'], epoch)
        self.writer.add_scalar('Epoch/Val_True_Final_Accuracy', avg_metrics['true_final_count_accuracy'], epoch)
        
        # è®°å½•MotionæŒ‡æ ‡
        self.writer.add_scalar('Epoch/Val_Joint_MSE', avg_metrics['joint_mse'], epoch)
        self.writer.add_scalar('Epoch/Val_Joint_MAE', avg_metrics['joint_mae'], epoch)
        
        for key, value in per_digit_metrics.items():
            self.writer.add_scalar(f'Val/{key}', value, epoch)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
        is_best = avg_metrics['true_final_count_accuracy'] > self.best_val_accuracy
        if is_best:
            self.best_val_accuracy = avg_metrics['true_final_count_accuracy']
            self.best_val_loss = avg_loss
        
        return avg_loss, avg_metrics, is_best
    
    def save_checkpoint(self, epoch, val_loss, val_metrics, is_best=False):
        """ä¿å­˜æ¨¡å‹checkpoint"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'val_loss': val_loss,
            'val_metrics': val_metrics,
            'best_val_accuracy': self.best_val_accuracy,
            'config': self.config,
            'model_info': self.model.get_model_info()
        }
        
        # ä¿å­˜æœ€æ–°çš„checkpoint
        latest_path = os.path.join(self.checkpoint_dir, 'latest_checkpoint.pth')
        torch.save(checkpoint, latest_path)
        
        # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œé¢å¤–ä¿å­˜
        if is_best:
            best_path = os.path.join(self.checkpoint_dir, 'best_model.pth')
            torch.save(checkpoint, best_path)
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡: {val_metrics['true_final_count_accuracy']:.4f})")
        
        # å®šæœŸä¿å­˜checkpoint
        if epoch % self.config.get('save_every', 100) == 0:
            epoch_path = os.path.join(self.checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')
            torch.save(checkpoint, epoch_path)
    
    def train(self, num_epochs):
        """å®Œæ•´çš„è®­ç»ƒæµç¨‹"""
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ - {self.config['model_type']} å…·èº«æ¨¡å‹")
        print(f"è®¾å¤‡: {self.device}")
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(self.train_loader.dataset)}")
        print(f"éªŒè¯æ ·æœ¬æ•°: {len(self.val_loader.dataset)}")
        
        start_time = time.time()
        
        # ğŸ’¾ ä¿å­˜åˆå§‹æ¨¡å‹ï¼ˆepoch 0ï¼‰
        if self.config.get('save_checkpoints', True):
            print("\nğŸ’¾ ä¿å­˜åˆå§‹æ¨¡å‹ (epoch 0)...")
            
            # å…ˆè¿›è¡Œä¸€æ¬¡éªŒè¯ï¼Œè·å–åˆå§‹æ€§èƒ½
            print("ğŸ“Š è¯„ä¼°åˆå§‹æ¨¡å‹æ€§èƒ½...")
            initial_val_loss, initial_val_metrics, _ = self.validate(0)
            
            # ä¿å­˜åˆå§‹checkpoint
            self.save_checkpoint(
                epoch=0, 
                val_loss=initial_val_loss, 
                val_metrics=initial_val_metrics, 
                is_best=False
            )
            
            # é¢å¤–ä¿å­˜ä¸º checkpoint_epoch_0.pth
            checkpoint = {
                'epoch': 0,
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'val_loss': initial_val_loss,
                'val_metrics': initial_val_metrics,
                'best_val_accuracy': 0.0,
                'config': self.config,
                'model_info': self.model.get_model_info()
            }
            epoch0_path = os.path.join(self.checkpoint_dir, 'checkpoint_epoch_0.pth')
            torch.save(checkpoint, epoch0_path)
            
            print(f"âœ… åˆå§‹æ¨¡å‹å·²ä¿å­˜åˆ°: checkpoint_epoch_0.pth")
            print(f"   åˆå§‹éªŒè¯æŸå¤±: {initial_val_loss:.4f}")
            print(f"   åˆå§‹éªŒè¯å‡†ç¡®ç‡: {initial_val_metrics['count_accuracy']:.4f}")
            print(f"   åˆå§‹æœ€ç»ˆå‡†ç¡®ç‡: {initial_val_metrics['true_final_count_accuracy']:.4f}")
            
            # è®°å½•åˆå§‹æ€§èƒ½åˆ°è®­ç»ƒå†å²
            initial_history = {
                'epoch': 0,
                'train_loss': float('inf'),
                'train_count_acc': 0.0,
                'train_final_acc': 0.0,
                'val_loss': initial_val_loss,
                'val_count_acc': initial_val_metrics['count_accuracy'],
                'val_final_acc': initial_val_metrics['final_count_accuracy'],
                'val_true_final_acc': initial_val_metrics['true_final_count_accuracy'],
                'joint_mse': initial_val_metrics['joint_mse'],
                'joint_mae': initial_val_metrics['joint_mae'],
                'learning_rate': self.config['learning_rate'],
                'epoch_time': 0.0,
                **{k: v for k, v in initial_val_metrics.items() if k.startswith('digit_')}
            }
            self.training_history.append(initial_history)
        
        for epoch in range(1, num_epochs + 1):
            epoch_start_time = time.time()
            
            # è®­ç»ƒ
            train_loss, train_metrics = self.train_epoch(epoch)
            
            # éªŒè¯ï¼ˆæ¯ä¸ªepochéƒ½éªŒè¯ï¼Œä¸çº¯è§†è§‰ä¿æŒä¸€è‡´ï¼‰
            val_loss, val_metrics, is_best = self.validate(epoch)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            if self.scheduler:
                if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                    self.scheduler.step(val_loss)
                else:
                    self.scheduler.step()
            
            # è·å–å½“å‰å­¦ä¹ ç‡
            current_lr = self.optimizer.param_groups[0]['lr']
            self.writer.add_scalar('Learning_Rate', current_lr, epoch)
            
            # è®°å½•epochæ—¶é—´
            epoch_time = time.time() - epoch_start_time
            
            # ä¿å­˜è®­ç»ƒå†å²
            history_entry = {
                'epoch': epoch,
                'train_loss': train_loss,
                'train_count_acc': train_metrics['count_accuracy'],
                'train_final_acc': train_metrics['final_count_accuracy'],
                'val_loss': val_loss,
                'val_count_acc': val_metrics['count_accuracy'],
                'val_final_acc': val_metrics['final_count_accuracy'],
                'val_true_final_acc': val_metrics['true_final_count_accuracy'],
                'joint_mse': val_metrics['joint_mse'],
                'joint_mae': val_metrics['joint_mae'],
                'learning_rate': current_lr,
                'epoch_time': epoch_time,
                **{f'train_{k}': v for k, v in train_metrics.items() if k.startswith('digit_')},
                **{f'val_{k}': v for k, v in val_metrics.items() if k.startswith('digit_')}
            }
            self.training_history.append(history_entry)
            
            # ä¿å­˜checkpoint
            if self.config.get('save_checkpoints', True):
                self.save_checkpoint(epoch, val_loss, val_metrics, is_best)
            
            # æ‰“å°è¿›åº¦
            if epoch % self.config.get('print_every', 10) == 0:
                elapsed_time = time.time() - start_time
                avg_epoch_time = elapsed_time / epoch
                remaining_epochs = num_epochs - epoch
                eta = avg_epoch_time * remaining_epochs
                
                print(f"\nEpoch [{epoch}/{num_epochs}] "
                      f"Train Loss: {train_loss:.4f}, Train Acc: {train_metrics['count_accuracy']:.4f} | "
                      f"Val Loss: {val_loss:.4f}, Val Acc: {val_metrics['count_accuracy']:.4f} | "
                      f"Final Acc: {val_metrics['true_final_count_accuracy']:.4f} | "
                      f"LR: {current_lr:.6f} | "
                      f"Time: {epoch_time:.1f}s | ETA: {eta/60:.1f}min")
                
                # æ‰“å°éƒ¨åˆ†per-digitå‡†ç¡®ç‡
                print("Per-digit Val Accuracy:", end=" ")
                for digit in [0, 1, 5, 10]:  # æ‰“å°å‡ ä¸ªå…³é”®æ•°å­—
                    key = f'digit_{digit}_accuracy'
                    if key in val_metrics:
                        print(f"[{digit}]: {val_metrics[key]:.3f}", end=" ")
                print()
        
        # è®­ç»ƒå®Œæˆ
        total_time = time.time() - start_time
        print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"æ€»è€—æ—¶: {total_time/3600:.2f} å°æ—¶")
        print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_val_accuracy:.4f}")
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_df = pd.DataFrame(self.training_history)
        history_path = os.path.join(self.checkpoint_dir, 'training_history.csv')
        history_df.to_csv(history_path, index=False)
        print(f"è®­ç»ƒå†å²å·²ä¿å­˜: {history_path}")
        
        # å…³é—­TensorBoard writer
        self.writer.close()
        
        return self.training_history


def run_single_experiment(model_type, seed, data_config, save_dir, total_epochs, config_overrides=None):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(seed)
    np.random.seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    model_name = f"{model_type}_seed_{seed}"
    experiment_dir = os.path.join(save_dir, model_name)
    log_dir = os.path.join(experiment_dir, 'tensorboard_logs')
    checkpoint_dir = os.path.join(experiment_dir, 'checkpoints')
    
    os.makedirs(experiment_dir, exist_ok=True)
    os.makedirs(log_dir, exist_ok=True)
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    # é…ç½®
    config = {
        'model_type': model_type,
        'seed': seed,
        'total_epochs': total_epochs,
        'batch_size': 16,
        'sequence_length': 11,
        'learning_rate': 1e-4,
        'image_mode': 'rgb',
        'num_workers': 4,
        'save_checkpoints': True,
        'save_every': 10,
        'print_every': 10,
        'model_config': {
            'cnn_layers': 3,
            'cnn_channels': [64, 128, 256],
            'lstm_layers': 2,
            'lstm_hidden_size': 512,
            'feature_dim': 256,
            'joint_dim': 7,
            'dropout': 0.1,
            'use_fovea_bias': True
        },
        # ä¸çº¯è§†è§‰ä¿æŒä¸€è‡´çš„è®­ç»ƒå‚æ•°
        'adam_betas': (0.9, 0.999),
        'weight_decay': 1e-5,
        'grad_clip_norm': 1.0,
        'scheduler_type': 'cosine',
        'normalize': True,
        'embodiment_loss_weight': 0.3,
        'attention_loss_weight': 0.1
    }
    
    # åº”ç”¨é…ç½®è¦†ç›–
    if config_overrides:
        config.update(config_overrides)
    
    # ä¿å­˜é…ç½®
    config_path = os.path.join(experiment_dir, 'config.json')
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=4)
    
    print(f"\n{'='*60}")
    print(f"å®éªŒ: {model_name}")
    print(f"ä¿å­˜ç›®å½•: {experiment_dir}")
    print(f"{'='*60}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader, normalizer = get_ball_counting_data_loaders(
        train_csv_path=data_config['train_csv'],
        val_csv_path=data_config['val_csv'],
        data_root=data_config['data_root'],
        batch_size=config['batch_size'],
        sequence_length=config['sequence_length'],
        normalize=config['normalize'],
        num_workers=config['num_workers'],
        image_mode=config['image_mode']
    )
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model(config, model_type=model_type)
    model = model.to(device)
    
    # ç»Ÿè®¡å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = EmbodiedTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        config=config,
        device=device,
        log_dir=log_dir,
        checkpoint_dir=checkpoint_dir
    )
    
    # å¼€å§‹è®­ç»ƒ
    start_time = time.time()
    history = trainer.train(num_epochs=config['total_epochs'])
    training_time = time.time() - start_time
    
    # è¿”å›å®éªŒç»“æœ
    final_metrics = history[-1] if history else {}
    result = {
        'model_type': model_type,
        'seed': seed,
        'best_val_accuracy': trainer.best_val_accuracy,
        'best_val_loss': trainer.best_val_loss,
        'final_val_accuracy': final_metrics.get('val_count_acc', 0.0),
        'final_val_final_accuracy': final_metrics.get('val_final_acc', 0.0),
        'final_val_true_final_accuracy': final_metrics.get('val_true_final_acc', 0.0),
        'final_joint_mse': final_metrics.get('joint_mse', 0.0),
        'final_joint_mae': final_metrics.get('joint_mae', 0.0),
        'total_epochs': config['total_epochs'],
        'training_time_hours': training_time / 3600,
        'total_parameters': total_params,
        'trainable_parameters': trainable_params,
        'experiment_dir': experiment_dir
    }
    
    return result


from collections import defaultdict


def main():
    parser = argparse.ArgumentParser(description='AlexNetå…·èº«æ¨¡å‹è®­ç»ƒ - ä¿®å¤ç‰ˆ')
    
    # æ•°æ®è·¯å¾„
    parser.add_argument('--data_root', type=str, 
                       default='/mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/Ball_counting_CNN/ball_data_collection')
    parser.add_argument('--train_csv', type=str,
                       default='scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_train.csv')
    parser.add_argument('--val_csv', type=str,
                       default='scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_val.csv')
    
    # å®éªŒå‚æ•°
    parser.add_argument('--total_epochs', type=int, default=1000,
                       help='è®­ç»ƒæ€»epochæ•°')
    parser.add_argument('--model_types', nargs='+', 
                       default=['baseline', 'alexnet_no_pretrain', 'alexnet_pretrain'],
                       help='è¦æµ‹è¯•çš„æ¨¡å‹ç±»å‹')
    parser.add_argument('--seeds', nargs='+', type=int,
                       default=[2048, 4096, 9999],  # é»˜è®¤3ä¸ªç§å­
                       help='éšæœºç§å­åˆ—è¡¨')
    
    # ç»“æœä¿å­˜
    parser.add_argument('--save_dir', type=str, default='./embodied_experiments_fixed',
                       help='ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--experiment_name', type=str, default=None,
                       help='å®éªŒåç§°ï¼Œç”¨äºå­ç›®å½•')
    
    args = parser.parse_args()
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    experiment_name = args.experiment_name or f'alexnet_embodied_comparison_{timestamp}'
    save_dir = os.path.join(args.save_dir, experiment_name)
    os.makedirs(save_dir, exist_ok=True)
    
    # æ•°æ®é…ç½®
    data_config = {
        'data_root': args.data_root,
        'train_csv': args.train_csv,
        'val_csv': args.val_csv
    }
    
    # è®°å½•æ‰€æœ‰å®éªŒç»“æœ
    all_results = []
    results_file = os.path.join(save_dir, 'experiment_results.csv')
    
    print(f"ğŸš€ å¼€å§‹AlexNetå…·èº«æ¨¡å‹å¯¹æ¯”å®éªŒ")
    print(f"æ¨¡å‹ç±»å‹: {args.model_types}")
    print(f"éšæœºç§å­: {args.seeds}")
    print(f"æ€»å®éªŒæ•°: {len(args.model_types) * len(args.seeds)}")
    print(f"æ¯ä¸ªå®éªŒè®­ç»ƒepochs: {args.total_epochs}")
    print(f"ç»“æœä¿å­˜: {save_dir}")
    
    # è¿è¡Œæ‰€æœ‰å®éªŒ
    total_experiments = len(args.model_types) * len(args.seeds)
    current_exp = 0
    start_time = time.time()
    
    for model_type in args.model_types:
        for seed in args.seeds:
            current_exp += 1
            
            # æ˜¾ç¤ºè¿›åº¦
            elapsed_time = time.time() - start_time
            avg_time_per_exp = elapsed_time / current_exp if current_exp > 0 else 0
            remaining_time = avg_time_per_exp * (total_experiments - current_exp)
            
            print(f"\nğŸ“Š è¿›åº¦: {current_exp}/{total_experiments}")
            print(f"â±ï¸  å·²ç”¨æ—¶: {elapsed_time/3600:.1f}h, é¢„è®¡å‰©ä½™: {remaining_time/3600:.1f}h")
            
            # è¿è¡Œå®éªŒ
            result = run_single_experiment(
                model_type=model_type,
                seed=seed,
                data_config=data_config,
                save_dir=save_dir,
                total_epochs=args.total_epochs
            )
            all_results.append(result)
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            results_df = pd.DataFrame(all_results)
            results_df.to_csv(results_file, index=False)
            print(f"ğŸ’¾ ä¿å­˜ä¸­é—´ç»“æœ: {results_file}")
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    print(f"\nğŸ“Š ç”Ÿæˆå®éªŒæŠ¥å‘Š...")
    results_df = pd.DataFrame(all_results)
    
    # è®¡ç®—ç»Ÿè®¡æ‘˜è¦
    summary = results_df.groupby('model_type').agg({
        'best_val_accuracy': ['mean', 'std', 'max'],
        'final_val_true_final_accuracy': ['mean', 'std'],
        'final_joint_mse': ['mean', 'std'],
        'training_time_hours': ['mean', 'sum']
    }).round(4)
    
    # ä¿å­˜æ‘˜è¦
    summary_file = os.path.join(save_dir, 'summary_stats.csv')
    summary.to_csv(summary_file)
    
    # æ‰“å°æ‘˜è¦
    print("\nğŸ“ˆ å®éªŒç»“æœæ‘˜è¦:")
    print("="*80)
    print(summary)
    print("="*80)
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    report_content = f"""# AlexNetå…·èº«æ¨¡å‹å®éªŒæŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## å®éªŒæ¦‚è¿°

- **ä»»åŠ¡**: å…·èº«çƒæ•°è®¡æ•°ï¼ˆå¤šæ¨¡æ€åºåˆ—é¢„æµ‹ï¼‰
- **æ¨¡å‹å¯¹æ¯”**: Baseline vs AlexNet (æ— é¢„è®­ç»ƒ) vs AlexNet (é¢„è®­ç»ƒ)
- **è®­ç»ƒepochs**: {args.total_epochs}
- **éšæœºç§å­**: {args.seeds}
- **åºåˆ—é•¿åº¦**: 11å¸§

## å®éªŒç»“æœ

### å‡†ç¡®ç‡å¯¹æ¯”

| æ¨¡å‹ç±»å‹ | æœ€ä½³éªŒè¯å‡†ç¡®ç‡ (meanÂ±std) | æœ€ç»ˆå‡†ç¡®ç‡ (meanÂ±std) | å…³èŠ‚MSE (meanÂ±std) |
|---------|--------------------------|---------------------|-------------------|
"""
    
    for model_type in args.model_types:
        model_results = results_df[results_df['model_type'] == model_type]
        if len(model_results) > 0:
            best_mean = model_results['best_val_accuracy'].mean()
            best_std = model_results['best_val_accuracy'].std()
            final_mean = model_results['final_val_true_final_accuracy'].mean()
            final_std = model_results['final_val_true_final_accuracy'].std()
            joint_mean = model_results['final_joint_mse'].mean()
            joint_std = model_results['final_joint_mse'].std()
            
            type_names = {
                'baseline': 'Baseline CNN',
                'alexnet_pretrain': 'é¢„è®­ç»ƒAlexNet',
                'alexnet_no_pretrain': 'æ— é¢„è®­ç»ƒAlexNet'
            }
            display_name = type_names.get(model_type, model_type)
            
            report_content += f"| {display_name} | {best_mean:.4f}Â±{best_std:.4f} | "
            report_content += f"{final_mean:.4f}Â±{final_std:.4f} | {joint_mean:.4f}Â±{joint_std:.4f} |\n"
    
    report_content += f"""

### è®­ç»ƒæ•ˆç‡

| æ¨¡å‹ç±»å‹ | å¹³å‡è®­ç»ƒæ—¶é—´ (å°æ—¶) | å‚æ•°é‡ |
|---------|------------------|--------|
"""
    
    for model_type in args.model_types:
        model_results = results_df[results_df['model_type'] == model_type]
        if len(model_results) > 0:
            avg_time = model_results['training_time_hours'].mean()
            params = model_results['total_parameters'].iloc[0]
            
            type_names = {
                'baseline': 'Baseline CNN',
                'alexnet_pretrain': 'é¢„è®­ç»ƒAlexNet',
                'alexnet_no_pretrain': 'æ— é¢„è®­ç»ƒAlexNet'
            }
            display_name = type_names.get(model_type, model_type)
            
            report_content += f"| {display_name} | {avg_time:.2f} | {params:,} |\n"
    
    report_content += f"""

## æ–‡ä»¶è¯´æ˜

- è¯¦ç»†ç»“æœ: `experiment_results.csv`
- ç»Ÿè®¡æ‘˜è¦: `summary_stats.csv`
- TensorBoardæ—¥å¿—: å„æ¨¡å‹çš„ `tensorboard_logs/` ç›®å½•
- æ¨¡å‹checkpoints: å„æ¨¡å‹çš„ `checkpoints/` ç›®å½•
- è®­ç»ƒå†å²: å„æ¨¡å‹çš„ `training_history.csv`

## æŸ¥çœ‹TensorBoard

```bash
tensorboard --logdir {save_dir}
```

## ä¸çº¯è§†è§‰æ¨¡å‹å¯¹æ¯”

æ­¤å…·èº«æ¨¡å‹å®éªŒå¯ä¸çº¯è§†è§‰æ¨¡å‹å®éªŒç»“æœè¿›è¡Œå¯¹æ¯”ï¼Œä»¥è¯„ä¼°å…·èº«ä¿¡æ¯ï¼ˆå…³èŠ‚ä½ç½®ï¼‰å¯¹è®¡æ•°ä»»åŠ¡çš„è´¡çŒ®ã€‚
"""
    
    report_file = os.path.join(save_dir, 'experiment_report.md')
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    total_time = time.time() - start_time
    print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆ!")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time/3600:.1f} å°æ—¶")
    print(f"ğŸ“Š è¯¦ç»†ç»“æœ: {results_file}")
    print(f"ğŸ“ˆ ç»Ÿè®¡æ‘˜è¦: {summary_file}")
    print(f"ğŸ“‹ å®éªŒæŠ¥å‘Š: {report_file}")
    print(f"ğŸ’¾ æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {save_dir}")


if __name__ == "__main__":
    main()