"""
åŠ¨æ€å…·èº«è®¡æ•°æ¨¡å‹å¯è§†åŒ–å·¥å…·
å¯è§†åŒ–æ¯ä¸ªæ ·æœ¬æ¯ä¸€å¸§çš„:
1. Attentionçƒ­åŠ›å›¾
2. Softmaxè¾“å‡ºåˆ†å¸ƒ
3. LSTMéšçŠ¶æ€å˜åŒ–
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib.animation import FuncAnimation
import seaborn as sns
import os
import json
import argparse
from datetime import datetime
from tqdm import tqdm
import pandas as pd
from PIL import Image
import cv2

# è®¾ç½®matplotlibåç«¯
import matplotlib
matplotlib.use('Agg')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class DynamicModelVisualizer:
    """åŠ¨æ€æ¨¡å‹å¯è§†åŒ–å™¨"""
    
    def __init__(self, model, device='cuda'):
        self.model = model
        self.device = device
        self.model.eval()
        
        # å­˜å‚¨ä¸­é—´ç»“æœ
        self.attention_weights_history = []
        self.lstm_states_history = []
        self.softmax_outputs_history = []
        
    def visualize_sample_sequence(self, sample_data, sample_id, save_dir):
        """å¯è§†åŒ–å•ä¸ªæ ·æœ¬çš„å®Œæ•´åºåˆ—"""
        
        # åˆ›å»ºæ ·æœ¬ä¿å­˜ç›®å½•
        sample_dir = os.path.join(save_dir, f'sample_{sample_id}')
        os.makedirs(sample_dir, exist_ok=True)
        
        # å‡†å¤‡æ•°æ®
        sequence_data = {
            'images': sample_data['sequence_data']['images'].unsqueeze(0).to(self.device),
            'joints': sample_data['sequence_data']['joints'].unsqueeze(0).to(self.device),
            'timestamps': sample_data['sequence_data']['timestamps'].unsqueeze(0).to(self.device),
            'labels': sample_data['sequence_data']['labels'].unsqueeze(0).to(self.device)
        }
        
        seq_len = sequence_data['images'].shape[1]
        true_label = sample_data['label'].item()
        
        print(f"\nå¤„ç†æ ·æœ¬ {sample_id} (çœŸå®æ ‡ç­¾: {true_label}, åºåˆ—é•¿åº¦: {seq_len})")
        
        # æ¸…ç©ºå†å²è®°å½•
        self.model.lstm_hidden_states = []
        self.model.attention_weights_history = []
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            outputs = self.model(
                sequence_data=sequence_data,
                use_teacher_forcing=False,
                return_attention=True
            )
        
        # æå–ç»“æœ
        count_logits = outputs['counts'][0]  # [seq_len, 11]
        softmax_probs = F.softmax(count_logits, dim=-1)  # [seq_len, 11]
        predictions = torch.argmax(count_logits, dim=-1)  # [seq_len]
        
        # è·å–attentionæƒé‡å’ŒLSTMçŠ¶æ€
        attention_weights = self.model.attention_weights_history  # list of [1, H*W]
        lstm_states = self.model.lstm_hidden_states  # list of [lstm_hidden_size]
        
        # 1. åˆ›å»ºç»¼åˆå¯è§†åŒ–å›¾ï¼ˆæ¯ä¸€å¸§ï¼‰
        for t in range(seq_len):
            fig = plt.figure(figsize=(20, 12))
            
            # 1.1 åŸå§‹å›¾åƒ
            ax1 = plt.subplot(2, 3, 1)
            img = sequence_data['images'][0, t].cpu()
            
            # å¤„ç†ä¸åŒé€šé“æ•°çš„å›¾åƒ
            if img.shape[0] == 1:  # ç°åº¦å›¾
                img = img.squeeze(0)
                ax1.imshow(img, cmap='gray')
            else:  # RGB
                img = img.permute(1, 2, 0)
                # åå½’ä¸€åŒ–
                mean = torch.tensor([0.485, 0.456, 0.406])
                std = torch.tensor([0.229, 0.224, 0.225])
                img = img * std + mean
                img = torch.clamp(img, 0, 1)
                ax1.imshow(img)
            
            ax1.set_title(f'Frame {t+1}/{seq_len}')
            ax1.axis('off')
            
            # 1.2 Attentionçƒ­åŠ›å›¾
            ax2 = plt.subplot(2, 3, 2)
            if t < len(attention_weights):
                att_weights = attention_weights[t].cpu().numpy().squeeze()
                #att_weights = att_weights.mean(axis=0)  # å˜æˆ (784,)
                #print(f"Frame {t}: Attention weights shape: {att_weights.shape}")
                # å°è¯•é‡å¡‘ä¸º2Dï¼ˆå‡è®¾æ˜¯æ­£æ–¹å½¢ï¼‰
                spatial_size = len(att_weights)
                #print(f"Spatial size: {spatial_size}")
                grid_size = int(np.sqrt(spatial_size))
                #print(f"Grid size: {grid_size}")
                if grid_size * grid_size == spatial_size:
                    att_map = att_weights.reshape(grid_size, grid_size)
                    
                    # ä¸Šé‡‡æ ·åˆ°åŸå§‹å›¾åƒå¤§å°
                    att_map_resized = cv2.resize(att_map, (224, 224))
                    
                    # å åŠ æ˜¾ç¤º
                    if img.dim() == 2:  # ç°åº¦å›¾
                        ax2.imshow(img, cmap='gray', alpha=0.5)
                    else:  # RGB
                        ax2.imshow(img, alpha=0.5)
                    
                    im = ax2.imshow(att_map_resized, cmap='viridis', alpha=0.5)
                    plt.colorbar(im, ax=ax2, fraction=0.046)
                else:
                    # å¦‚æœä¸èƒ½é‡å¡‘ï¼Œæ˜¾ç¤º1D attention
                    ax2.bar(range(len(att_weights)), att_weights)
                    ax2.set_xlabel('Spatial Position')
                    ax2.set_ylabel('Attention Weight')
                
                ax2.set_title(f'Attention Map (t={t+1})')
            else:
                ax2.text(0.5, 0.5, 'No attention data', ha='center', va='center')
                ax2.set_title(f'Attention Map (t={t+1})')
            
            # 1.3 Softmaxè¾“å‡ºåˆ†å¸ƒ
            ax3 = plt.subplot(2, 3, 3)
            probs_t = softmax_probs[t].cpu().numpy()
            pred_t = predictions[t].item()
            
            bars = ax3.bar(range(11), probs_t, color='skyblue', alpha=0.7)
            bars[pred_t].set_color('red')  # é«˜äº®é¢„æµ‹ç±»åˆ«
            
            # æ·»åŠ æ¦‚ç‡å€¼æ ‡ç­¾
            for i, prob in enumerate(probs_t):
                if prob > 0.01:  # åªæ˜¾ç¤ºå¤§äº1%çš„æ¦‚ç‡
                    ax3.text(i, prob + 0.01, f'{prob:.2f}', ha='center', fontsize=8)
            
            ax3.set_xlabel('Count Class')
            ax3.set_ylabel('Probability')
            ax3.set_title(f'Softmax Output (Pred: {pred_t})')
            ax3.set_xticks(range(11))
            ax3.set_ylim(0, 1.1)
            ax3.grid(True, alpha=0.3)
            
            # 1.4 Softmaxåˆ†å¸ƒæ—¶åºå˜åŒ–
            ax4 = plt.subplot(2, 3, 4)
            
            # ç»˜åˆ¶å‰t+1å¸§çš„softmaxå˜åŒ–
            for class_idx in range(11):
                probs_history = softmax_probs[:t+1, class_idx].cpu().numpy()
                if np.max(probs_history) > 0.1:  # åªæ˜¾ç¤ºé‡è¦çš„ç±»åˆ«
                    ax4.plot(range(t+1), probs_history, label=f'Class {class_idx}', 
                            linewidth=2 if class_idx == pred_t else 1,
                            alpha=1.0 if class_idx == pred_t else 0.5)
            
            ax4.set_xlabel('Frame')
            ax4.set_ylabel('Probability')
            ax4.set_title('Softmax Evolution')
            ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax4.grid(True, alpha=0.3)
            ax4.set_xlim(-0.5, seq_len-0.5)
            
            # 1.5 LSTMéšçŠ¶æ€å˜åŒ–
            ax5 = plt.subplot(2, 3, 5)
            
            if t < len(lstm_states):
                print(f"Frame {t}: LSTM states length: {len(lstm_states)}")
                print(f"Frame {t}: LSTM states shape: {lstm_states[t].shape}")
                # æ˜¾ç¤ºLSTMçŠ¶æ€çš„PCAæŠ•å½±ï¼ˆ2Dï¼‰
                states_so_far = torch.stack(lstm_states[:t+1]).cpu().numpy()
                states_so_far = states_so_far.squeeze(1)  # [t+1, lstm_hidden_size]
                print(f"Frame {t}: LSTM states shape: {states_so_far.shape}")
                if states_so_far.shape[0] > 2:
                    # ä½¿ç”¨PCAé™ç»´åˆ°2D
                    from sklearn.decomposition import PCA
                    pca = PCA(n_components=2)
                    states_2d = pca.fit_transform(states_so_far)
                    
                    # ç»˜åˆ¶è½¨è¿¹
                    ax5.plot(states_2d[:, 0], states_2d[:, 1], 'b-', alpha=0.5)
                    ax5.scatter(states_2d[:, 0], states_2d[:, 1], 
                              c=range(t+1), cmap='viridis', s=50)
                    ax5.scatter(states_2d[-1, 0], states_2d[-1, 1], 
                              color='red', s=100, marker='*', label='Current')
                    
                    ax5.set_xlabel('PC1')
                    ax5.set_ylabel('PC2')
                    ax5.set_title(f'LSTM State Trajectory (PCA)')
                    ax5.legend()
                else:
                    # å¦‚æœç»´åº¦å·²ç»å¾ˆä½ï¼Œç›´æ¥æ˜¾ç¤º
                    ax5.plot(states_so_far[:, 0], 'b-', label='Dim 0')
                    if states_so_far.shape[1] > 1:
                        ax5.plot(states_so_far[:, 1], 'r-', label='Dim 1')
                    ax5.set_xlabel('Frame')
                    ax5.set_ylabel('State Value')
                    ax5.set_title('LSTM State Evolution')
                    ax5.legend()
            
            ax5.grid(True, alpha=0.3)
            
            # 1.6 é¢„æµ‹åºåˆ—å’Œä¿¡æ¯
            ax6 = plt.subplot(2, 3, 6)
            
            # æ˜¾ç¤ºé¢„æµ‹åºåˆ—
            pred_seq = predictions[:t+1].cpu().numpy()
            true_seq = sequence_data['labels'][0, :t+1].cpu().numpy()
            
            ax6.plot(range(t+1), pred_seq, 'ro-', label='Predictions', markersize=8)
            ax6.plot(range(t+1), true_seq, 'bs--', label='True Labels', markersize=6)
            
            ax6.set_xlabel('Frame')
            ax6.set_ylabel('Count')
            ax6.set_title('Prediction Sequence')
            ax6.legend()
            ax6.grid(True, alpha=0.3)
            ax6.set_ylim(-0.5, 10.5)
            ax6.set_yticks(range(11))
            
            # æ·»åŠ æ–‡æœ¬ä¿¡æ¯
            info_text = f"Sample ID: {sample_id}\n"
            info_text += f"True Label: {true_label}\n"
            info_text += f"Current Pred: {pred_t}\n"
            info_text += f"Final Pred: {predictions[-1].item()}\n"
            info_text += f"Confidence: {probs_t[pred_t]:.3f}"
            
            ax6.text(0.02, 0.98, info_text, transform=ax6.transAxes,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="wheat", alpha=0.5),
                    verticalalignment='top', fontsize=10)
            
            plt.tight_layout()
            
            # ä¿å­˜å½“å‰å¸§
            frame_path = os.path.join(sample_dir, f'frame_{t:03d}.png')
            plt.savefig(frame_path, dpi=150, bbox_inches='tight')
            plt.close()
        
        # 2. ç”Ÿæˆæ±‡æ€»å›¾
        self._generate_summary_plot(
            softmax_probs, predictions, lstm_states, attention_weights,
            sequence_data, true_label, sample_id, sample_dir
        )
        
        # 3. ä¿å­˜æ•°å€¼æ•°æ®
        self._save_numerical_data(
            softmax_probs, predictions, lstm_states, attention_weights,
            true_label, sample_id, sample_dir
        )
        
        print(f"âœ… æ ·æœ¬ {sample_id} å¯è§†åŒ–å®Œæˆ")
        
    def _generate_summary_plot(self, softmax_probs, predictions, lstm_states, 
                              attention_weights, sequence_data, true_label, 
                              sample_id, sample_dir):
        """ç”Ÿæˆæ±‡æ€»å¯è§†åŒ–å›¾"""
        
        fig = plt.figure(figsize=(20, 10))
        
        # 1. Softmaxçƒ­åŠ›å›¾
        ax1 = plt.subplot(2, 2, 1)
        sns.heatmap(softmax_probs.cpu().numpy().T, 
                   cmap='YlOrRd', cbar=True, 
                   xticklabels=range(len(softmax_probs)),
                   yticklabels=range(11))
        ax1.set_xlabel('Frame')
        ax1.set_ylabel('Count Class')
        ax1.set_title('Softmax Probability Heatmap')
        
        # 2. é¢„æµ‹å‡†ç¡®åº¦æ—¶åºå›¾
        ax2 = plt.subplot(2, 2, 2)
        pred_np = predictions.cpu().numpy()
        true_np = sequence_data['labels'][0].cpu().numpy()
        correct = pred_np == true_np
        
        ax2.plot(range(len(pred_np)), pred_np, 'ro-', label='Predictions')
        ax2.plot(range(len(true_np)), true_np, 'bs--', label='True Labels')
        
        # æ ‡è®°æ­£ç¡®å’Œé”™è¯¯çš„é¢„æµ‹
        for i, is_correct in enumerate(correct):
            color = 'green' if is_correct else 'red'
            ax2.axvspan(i-0.3, i+0.3, alpha=0.2, color=color)
        
        ax2.set_xlabel('Frame')
        ax2.set_ylabel('Count')
        ax2.set_title('Prediction vs Ground Truth')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. LSTMçŠ¶æ€çƒ­åŠ›å›¾ï¼ˆæ˜¾ç¤ºéƒ¨åˆ†ç»´åº¦ï¼‰
        ax3 = plt.subplot(2, 2, 3)
        if lstm_states:
            lstm_array = torch.stack(lstm_states).cpu().numpy()
            #print(f"LSTM states shape: {lstm_array.shape}")
            # åªæ˜¾ç¤ºå‰50ä¸ªç»´åº¦
            n_dims_to_show = min(50, lstm_array.shape[1])
            sns.heatmap(lstm_array[:, :n_dims_to_show].T.squeeze(1),
                       cmap='coolwarm', center=0,
                       xticklabels=range(len(lstm_states)),
                       yticklabels=False)
            ax3.set_xlabel('Frame')
            ax3.set_ylabel(f'LSTM Hidden Dims (first {n_dims_to_show})')
            ax3.set_title('LSTM Hidden State Evolution')
        
        # 4. ç½®ä¿¡åº¦å˜åŒ–
        ax4 = plt.subplot(2, 2, 4)
        
        # æœ€é«˜æ¦‚ç‡å€¼ï¼ˆç½®ä¿¡åº¦ï¼‰
        max_probs = torch.max(softmax_probs, dim=1)[0].cpu().numpy()
        
        # æ­£ç¡®é¢„æµ‹çš„ç½®ä¿¡åº¦
        correct_class_probs = []
        for t in range(len(predictions)):
            true_class = int(true_np[t])  # ç¡®ä¿ç´¢å¼•ä¸ºæ•´æ•°
            #print(f"Frame {t}: True class {true_class}, Predicted {predictions[t].item()}")
            prob = softmax_probs[t, true_class].item()
            correct_class_probs.append(prob)
        
        ax4.plot(range(len(max_probs)), max_probs, 'b-', label='Max Confidence', linewidth=2)
        ax4.plot(range(len(correct_class_probs)), correct_class_probs, 'g--', 
                label='True Class Prob', linewidth=2)
        
        ax4.fill_between(range(len(max_probs)), 0, max_probs, alpha=0.3)
        ax4.set_xlabel('Frame')
        ax4.set_ylabel('Probability')
        ax4.set_title('Model Confidence Over Time')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        ax4.set_ylim(0, 1.1)
        
        # æ·»åŠ æ€»ä½“ä¿¡æ¯
        fig.suptitle(f'Sample {sample_id} Summary - True Label: {true_label}, '
                    f'Final Prediction: {predictions[-1].item()}', fontsize=16)
        
        plt.tight_layout()
        
        # ä¿å­˜æ±‡æ€»å›¾
        summary_path = os.path.join(sample_dir, 'summary.png')
        plt.savefig(summary_path, dpi=200, bbox_inches='tight')
        plt.close()
        
    def _save_numerical_data(self, softmax_probs, predictions, lstm_states, 
                           attention_weights, true_label, sample_id, sample_dir):
        """ä¿å­˜æ•°å€¼æ•°æ®ä¸ºJSONæ ¼å¼"""
        
        data = {
            'sample_id': sample_id,
            'true_label': int(true_label),
            'predictions': predictions.cpu().tolist(),
            'softmax_probs': softmax_probs.cpu().tolist(),
            'final_prediction': int(predictions[-1].item()),
            'sequence_length': len(predictions),
            'accuracy': float((predictions.cpu().numpy() == true_label).mean())
        }
        
        # ä¿å­˜LSTMçŠ¶æ€ç»Ÿè®¡ä¿¡æ¯
        if lstm_states:
            lstm_array = torch.stack(lstm_states).cpu().numpy()
            data['lstm_stats'] = {
                'mean': float(lstm_array.mean()),
                'std': float(lstm_array.std()),
                'shape': list(lstm_array.shape)
            }
        
        # ä¿å­˜attentionç»Ÿè®¡ä¿¡æ¯
        if attention_weights:
            att_array = torch.cat(attention_weights).cpu().numpy()
            data['attention_stats'] = {
                'mean': float(att_array.mean()),
                'std': float(att_array.std()),
                'max': float(att_array.max()),
                'min': float(att_array.min())
            }
        
        # ä¿å­˜JSONæ–‡ä»¶
        json_path = os.path.join(sample_dir, 'data.json')
        with open(json_path, 'w') as f:
            json.dump(data, f, indent=2)


def load_model_and_data(checkpoint_path, val_csv, data_root, device='cuda'):
    """åŠ è½½æ¨¡å‹å’Œæ•°æ®"""
    print("ğŸ“¥ åŠ è½½æ¨¡å‹å’Œæ•°æ®...")
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    config = checkpoint['config']
    
    # å¯¼å…¥å¿…è¦çš„æ¨¡å—
    from Model_embodiment import EmbodiedCountingModel
    from DataLoader_embodiment import BallCountingDataset
    
    # ç¡®å®šå›¾åƒæ¨¡å¼
    image_mode = config.get('image_mode', 'rgb')
    input_channels = 3 if image_mode == 'rgb' else 1
    
    # é‡å»ºæ¨¡å‹
    model_config = config['model_config'].copy()
    model_config['input_channels'] = input_channels
    model = EmbodiedCountingModel(**model_config)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    device = torch.device(device if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (å›¾åƒæ¨¡å¼: {image_mode}, è®¾å¤‡: {device})")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = BallCountingDataset(
        csv_path=val_csv,
        data_root=data_root,
        sequence_length=config['sequence_length'],
        normalize=config['normalize'],
        image_mode=image_mode,
        normalize_images=True
    )
    
    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œæ ·æœ¬æ•°: {len(dataset)}")
    
    return model, dataset, device, config


def main():
    parser = argparse.ArgumentParser(description='åŠ¨æ€å…·èº«è®¡æ•°æ¨¡å‹å¯è§†åŒ–')
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('--checkpoint', type=str, required=True,
                       help='æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--val_csv', type=str, default='scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_val_single_per_label_v1.csv',
                       help='éªŒè¯é›†CSVæ–‡ä»¶è·¯å¾„ï¼ˆå»ºè®®ä½¿ç”¨å°å­é›†ï¼‰')
    parser.add_argument('--data_root', type=str, default='/mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/Ball_counting_CNN/ball_data_collection',
                       help='æ•°æ®æ ¹ç›®å½•')
    
    # å¯é€‰å‚æ•°
    parser.add_argument('--save_dir', type=str, default='./dynamic_visualizations',
                       help='ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--device', type=str, default='cuda',
                       help='è®¾å¤‡ (cuda/cpu)')
    parser.add_argument('--sample_indices', type=int, nargs='+', default=None,
                       help='è¦å¯è§†åŒ–çš„æ ·æœ¬ç´¢å¼•ï¼ˆé»˜è®¤å…¨éƒ¨ï¼‰')
    parser.add_argument('--max_samples', type=int, default=10,
                       help='æœ€å¤§å¯è§†åŒ–æ ·æœ¬æ•°')
    
    args = parser.parse_args()
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_dir = os.path.join(args.save_dir, f'viz_{timestamp}')
    os.makedirs(save_dir, exist_ok=True)
    
    print("ğŸ¬ åŠ¨æ€å…·èº«è®¡æ•°æ¨¡å‹å¯è§†åŒ–å·¥å…·")
    print("="*50)
    print(f"æ£€æŸ¥ç‚¹: {args.checkpoint}")
    print(f"æ•°æ®é›†: {args.val_csv}")
    print(f"ä¿å­˜ç›®å½•: {save_dir}")
    print("="*50)
    
    try:
        # åŠ è½½æ¨¡å‹å’Œæ•°æ®
        model, dataset, device, config = load_model_and_data(
            args.checkpoint, args.val_csv, args.data_root, args.device
        )
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = DynamicModelVisualizer(model, device)
        
        # ç¡®å®šè¦å¯è§†åŒ–çš„æ ·æœ¬
        if args.sample_indices is not None:
            sample_indices = args.sample_indices
        else:
            sample_indices = list(range(min(len(dataset), args.max_samples)))
        
        print(f"\nå‡†å¤‡å¯è§†åŒ– {len(sample_indices)} ä¸ªæ ·æœ¬: {sample_indices}")
        
        # å¯è§†åŒ–æ¯ä¸ªæ ·æœ¬
        for idx in sample_indices:
            if idx >= len(dataset):
                print(f"âš ï¸ æ ·æœ¬ç´¢å¼• {idx} è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡")
                continue
            
            sample_data = dataset[idx]
            visualizer.visualize_sample_sequence(sample_data, idx, save_dir)
        
        # ç”Ÿæˆç´¢å¼•é¡µé¢
        generate_index_html(sample_indices, save_dir)
        
        print(f"\nğŸ‰ å¯è§†åŒ–å®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {save_dir}")
        print(f"ğŸŒ æ‰“å¼€ {os.path.join(save_dir, 'index.html')} æŸ¥çœ‹ç»“æœ")
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def generate_index_html(sample_indices, save_dir):
    """ç”ŸæˆHTMLç´¢å¼•é¡µé¢"""
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>Dynamic Model Visualization</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                margin: 20px;
                background-color: #f5f5f5;
            }
            h1 {
                color: #333;
                text-align: center;
            }
            .sample-grid {
                display: grid;
                grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
                gap: 20px;
                margin-top: 30px;
            }
            .sample-card {
                background: white;
                border-radius: 8px;
                padding: 15px;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                text-align: center;
            }
            .sample-card img {
                max-width: 100%;
                border-radius: 4px;
            }
            .sample-card h3 {
                margin: 10px 0;
                color: #555;
            }
            .sample-card a {
                display: inline-block;
                margin: 5px;
                padding: 8px 15px;
                background-color: #4CAF50;
                color: white;
                text-decoration: none;
                border-radius: 4px;
            }
            .sample-card a:hover {
                background-color: #45a049;
            }
        </style>
    </head>
    <body>
        <h1>Dynamic Embodied Counting Model Visualization</h1>
        <div class="sample-grid">
    """
    
    for idx in sample_indices:
        sample_dir = f'sample_{idx}'
        summary_path = f'{sample_dir}/summary.png'
        
        html_content += f"""
            <div class="sample-card">
                <h3>Sample {idx}</h3>
                <img src="{summary_path}" alt="Sample {idx} Summary">
                <br>
                <a href="{sample_dir}/" target="_blank">View Frames</a>
                <a href="{sample_dir}/data.json" target="_blank">View Data</a>
            </div>
        """
    
    html_content += """
        </div>
    </body>
    </html>
    """
    
    index_path = os.path.join(save_dir, 'index.html')
    with open(index_path, 'w') as f:
        f.write(html_content)
    
    print(f"âœ… ç´¢å¼•é¡µé¢å·²ç”Ÿæˆ: {index_path}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) == 1:
        print("ğŸ¬ åŠ¨æ€å…·èº«è®¡æ•°æ¨¡å‹å¯è§†åŒ–å·¥å…·")
        print("="*50)
        print("æ­¤å·¥å…·å¯è§†åŒ–æ¨¡å‹å¯¹æ¯ä¸ªæ ·æœ¬åºåˆ—çš„åŠ¨æ€å¤„ç†è¿‡ç¨‹")
        print("\nåŠŸèƒ½åŒ…æ‹¬:")
        print("  â€¢ æ¯ä¸€å¸§çš„attentionçƒ­åŠ›å›¾")
        print("  â€¢ Softmaxè¾“å‡ºåˆ†å¸ƒçš„åŠ¨æ€å˜åŒ–")
        print("  â€¢ LSTMéšçŠ¶æ€çš„æ¼”åŒ–è½¨è¿¹")
        print("  â€¢ é¢„æµ‹åºåˆ—ä¸çœŸå®æ ‡ç­¾çš„å¯¹æ¯”")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("python dynamic_viz.py --checkpoint MODEL.pth --val_csv VAL.csv --data_root DATA_DIR")
        print("\nç¤ºä¾‹:")
        print("python dynamic_viz.py \\")
        print("    --checkpoint ./best_model.pth \\")
        print("    --val_csv ./small_val_subset.csv \\")
        print("    --data_root ./data \\")
        print("    --max_samples 5")
        print("\nå¯é€‰å‚æ•°:")
        print("  --save_dir DIR          ä¿å­˜ç›®å½• (é»˜è®¤: ./dynamic_visualizations)")
        print("  --device DEVICE         è®¾å¤‡ (é»˜è®¤: cuda)")
        print("  --sample_indices 0 1 2  æŒ‡å®šæ ·æœ¬ç´¢å¼•")
        print("  --max_samples N         æœ€å¤§æ ·æœ¬æ•° (é»˜è®¤: 10)")
        print("\nğŸ’¡ å»ºè®®:")
        print("  â€¢ å‡†å¤‡ä¸€ä¸ªå°çš„éªŒè¯å­é›†ï¼ˆ10-20ä¸ªæ ·æœ¬ï¼‰")
        print("  â€¢ æ¯ä¸ªæ ·æœ¬ä¼šç”Ÿæˆåºåˆ—é•¿åº¦ä¸ªå›¾ç‰‡ï¼Œæ³¨æ„å­˜å‚¨ç©ºé—´")
        print("  â€¢ ç”Ÿæˆçš„index.htmlå¯ä»¥æ–¹ä¾¿åœ°æµè§ˆæ‰€æœ‰ç»“æœ")
        sys.exit(0)
    
    main()