"""
é€šç”¨æ¨¡å‹ç‰¹å¾åˆ†æå·¥å…·
æ”¯æŒåŸå§‹Embodimentæ¨¡å‹å’Œæ‰€æœ‰Ablationæ¨¡å‹
ä¸“æ³¨äºé™ç»´å¯è§†åŒ–ï¼šPCAå’Œt-SNEçš„2D/3Då±•ç¤º
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib
matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯ï¼Œé€‚åˆæœåŠ¡å™¨ç¯å¢ƒ
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import os
import sys
import argparse
import time
from collections import defaultdict
from datetime import datetime
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class UniversalFeatureExtractor:
    """é€šç”¨ç‰¹å¾æå–å™¨ - æ”¯æŒæ‰€æœ‰æ¨¡å‹ç±»å‹"""
    
    def __init__(self, model, device='cuda'):
        self.model = model
        self.device = device
        self.model.eval()
        self.features = {}
        self.hooks = []
        
        # æ£€æµ‹æ¨¡å‹ç±»å‹
        self.model_info = self._detect_model_type()
        print(f"âœ… æ£€æµ‹åˆ°æ¨¡å‹ç±»å‹: {self.model_info['type']}")
        print(f"   æ”¯æŒçš„ç»„ä»¶: {', '.join(self.model_info['available_components'])}")
        
    def _detect_model_type(self):
        """æ£€æµ‹æ¨¡å‹ç±»å‹å’Œå¯ç”¨ç»„ä»¶"""
        model_class_name = self.model.__class__.__name__
        
        # æ£€æŸ¥æ¨¡å‹ç±»å‹
        if hasattr(self.model, 'get_model_info'):
            # æ–°çš„ablationæ¨¡å‹
            info = self.model.get_model_info()
            model_type = info.get('model_type', model_class_name)
        else:
            # åŸå§‹Embodimentæ¨¡å‹
            model_type = 'EmbodiedCountingModel'
        
        # æ£€æµ‹å¯ç”¨ç»„ä»¶
        available_components = []
        
        # é€šç”¨ç»„ä»¶ï¼ˆæ‰€æœ‰æ¨¡å‹éƒ½æœ‰ï¼‰
        if hasattr(self.model, 'counting_decoder'):
            available_components.append('counting_decoder')
        if hasattr(self.model, 'lstm'):
            available_components.append('lstm')
        if hasattr(self.model, 'visual_encoder'):
            available_components.append('visual_encoder')
        
        # ç‰¹å®šç»„ä»¶
        if hasattr(self.model, 'embodiment_encoder'):
            available_components.append('embodiment_encoder')
        if hasattr(self.model, 'fusion'):
            available_components.append('fusion')
        if hasattr(self.model, 'motion_decoder'):
            available_components.append('motion_decoder')
        
        return {
            'type': model_type,
            'available_components': available_components
        }
    
    def get_recommended_components(self):
        """è·å–æ¨èåˆ†æçš„ç»„ä»¶"""
        all_components = self.model_info['available_components']
        
        # æŒ‰é‡è¦æ€§æ’åº
        priority_order = [
            'fusion',              # å¤šæ¨¡æ€èåˆï¼ˆæœ€é‡è¦ï¼‰
            'lstm',                # æ—¶åºå¤„ç†
            'counting_decoder',    # è®¡æ•°è§£ç 
            'visual_encoder',      # è§†è§‰ç¼–ç 
            'embodiment_encoder',  # å…·èº«ç¼–ç 
            'motion_decoder'       # åŠ¨ä½œè§£ç 
        ]
        
        recommended = []
        for component in priority_order:
            if component in all_components:
                recommended.append(component)
        
        return recommended
        
    def register_hooks(self, components_to_extract=None):
        """æ³¨å†Œé’©å­å‡½æ•°æ¥æå–ç»„ä»¶ç‰¹å¾"""
        if components_to_extract is None:
            components_to_extract = self.get_recommended_components()
        
        def get_activation(name):
            def hook(model, input, output):
                if isinstance(output, tuple):
                    self.features[name] = output[0].detach().cpu()
                else:
                    self.features[name] = output.detach().cpu()
            return hook
        
        successful_hooks = []
        failed_hooks = []
        
        for component_name in components_to_extract:
            try:
                # ç›´æ¥è·å–ç»„ä»¶æ¨¡å—
                if hasattr(self.model, component_name):
                    module = getattr(self.model, component_name)
                    handle = module.register_forward_hook(get_activation(component_name))
                    self.hooks.append(handle)
                    successful_hooks.append(component_name)
                    print(f"âœ… æˆåŠŸæ³¨å†Œé’©å­: {component_name}")
                else:
                    failed_hooks.append(component_name)
                    print(f"âŒ ç»„ä»¶ä¸å­˜åœ¨: {component_name}")
                
            except Exception as e:
                failed_hooks.append(component_name)
                print(f"âŒ æ³¨å†Œé’©å­å¤±è´¥: {component_name} - {e}")
        
        print(f"\né’©å­æ³¨å†Œç»“æœ: æˆåŠŸ {len(successful_hooks)}, å¤±è´¥ {len(failed_hooks)}")
        return successful_hooks
    
    def remove_hooks(self):
        """ç§»é™¤æ‰€æœ‰é’©å­"""
        for handle in self.hooks:
            handle.remove()
        self.hooks = []
        
    def _process_feature_tensor(self, feature_tensor):
        """å¤„ç†ä¸åŒå½¢çŠ¶çš„ç‰¹å¾å¼ é‡"""
        if len(feature_tensor.shape) == 3:  # [batch, seq, dim]
            # å–æœ€åä¸€ä¸ªæ—¶åˆ»çš„ç‰¹å¾
            return feature_tensor[:, -1, :].cpu().numpy()
        elif len(feature_tensor.shape) == 4:  # [batch, seq, h, w] or [batch, channel, h, w]
            # å…¨å±€å¹³å‡æ± åŒ–
            pooled = feature_tensor.mean(dim=(-2, -1))
            if len(pooled.shape) == 3:  # å¦‚æœè¿˜æœ‰seqç»´åº¦
                pooled = pooled[:, -1, :]
            return pooled.cpu().numpy()
        elif len(feature_tensor.shape) == 2:  # [batch, dim]
            return feature_tensor.cpu().numpy()
        else:
            # å…¶ä»–æƒ…å†µï¼Œå±•å¹³
            return feature_tensor.view(feature_tensor.shape[0], -1).cpu().numpy()
    
    def extract_features(self, data_loader, max_samples=500):
        """æå–ç‰¹å¾ - é€šç”¨äºæ‰€æœ‰æ¨¡å‹ç±»å‹"""
        all_features = defaultdict(list)
        all_labels = []
        all_sample_ids = []
        
        sample_count = 0
        
        with torch.no_grad():
            for batch in tqdm(data_loader, desc="æå–ç‰¹å¾"):
                if sample_count >= max_samples:
                    break
                
                # é€‚é…æ–°çš„æ•°æ®æ ¼å¼
                sequence_data = {
                    'images': batch['sequence_data']['images'].to(self.device),
                    'joints': batch['sequence_data']['joints'].to(self.device),
                    'timestamps': batch['sequence_data']['timestamps'].to(self.device),
                    'labels': batch['sequence_data']['labels'].to(self.device)
                }
                
                # è·å–æ‰¹æ¬¡ä¿¡æ¯
                labels = batch['label'].cpu().numpy()
                sample_ids = batch['sample_id']
                
                # è®¡ç®—å®é™…å¤„ç†çš„æ ·æœ¬æ•°
                remaining_samples = max_samples - sample_count
                actual_batch_size = min(len(labels), remaining_samples)
                
                # æˆªæ–­æ‰¹æ¬¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if actual_batch_size < len(labels):
                    for key in sequence_data:
                        sequence_data[key] = sequence_data[key][:actual_batch_size]
                    labels = labels[:actual_batch_size]
                    sample_ids = sample_ids[:actual_batch_size]
                
                # æ¸…ç©ºç‰¹å¾å­—å…¸
                self.features = {}
                
                # å‰å‘ä¼ æ’­ - æ ¹æ®æ¨¡å‹ç±»å‹è°ƒç”¨
                if self.model_info['type'] in ['EmbodiedCountingOnly', 'VisualOnlyCountingModel']:
                    # Ablationæ¨¡å‹
                    outputs = self.model(sequence_data=sequence_data)
                else:
                    # åŸå§‹Embodimentæ¨¡å‹
                    outputs = self.model(
                        sequence_data=sequence_data,
                        use_teacher_forcing=False
                    )
                
                # æ”¶é›†æ ‡ç­¾å’ŒID
                all_labels.extend(labels)
                all_sample_ids.extend(sample_ids)
                
                # æ”¶é›†ä¸­é—´å±‚ç‰¹å¾
                for component_name, feature_tensor in self.features.items():
                    processed_features = self._process_feature_tensor(feature_tensor)
                    all_features[component_name].append(processed_features)
                
                sample_count += actual_batch_size
                
                if sample_count >= max_samples:
                    break
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        final_features = {}
        for component_name, feature_list in all_features.items():
            if feature_list:
                final_features[component_name] = np.vstack(feature_list)
        
        result = {
            'features': final_features,
            'labels': np.array(all_labels),
            'sample_ids': all_sample_ids,
            'model_type': self.model_info['type']
        }
        
        print(f"\nç‰¹å¾æå–å®Œæˆ:")
        print(f"  å®é™…æ ·æœ¬æ•°: {len(result['labels'])}")
        print(f"  æ ‡ç­¾èŒƒå›´: {result['labels'].min()} - {result['labels'].max()}")
        print(f"  æå–çš„ç»„ä»¶: {list(final_features.keys())}")
        for name, features in final_features.items():
            print(f"    {name}: {features.shape}")
        
        return result


class VisualizationEngine:
    """å¯è§†åŒ–å¼•æ“ - ä¸“æ³¨äºé™ç»´å¯è§†åŒ–"""
    
    def __init__(self, figsize_2d=(12, 8), figsize_3d=(10, 8)):
        self.figsize_2d = figsize_2d
        self.figsize_3d = figsize_3d
        
    def reduce_dimensions(self, features, method='tsne', n_components=2):
        """é™ç»´"""
        print(f"  æ‰§è¡Œ{method.upper()} {n_components}Dé™ç»´...")
        
        if method == 'tsne':
            perplexity = min(30, len(features)//4, 50)
            reducer = TSNE(n_components=n_components, random_state=42, 
                          perplexity=perplexity, max_iter=1000)
        elif method == 'pca':
            reducer = PCA(n_components=n_components, random_state=42)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é™ç»´æ–¹æ³•: {method}")
        
        reduced_features = reducer.fit_transform(features)
        
        # è¿”å›é™ç»´ç»“æœå’Œè§£é‡Šæ–¹å·®æ¯”ä¾‹ï¼ˆå¦‚æœæ˜¯PCAï¼‰
        info = {'method': method, 'n_components': n_components}
        if method == 'pca':
            info['explained_variance_ratio'] = reducer.explained_variance_ratio_
            info['total_variance'] = reducer.explained_variance_ratio_.sum()
        
        return reduced_features, info
    
    def plot_2d_scatter(self, features_2d, labels, title, info, save_path):
        """ç»˜åˆ¶2Dæ•£ç‚¹å›¾"""
        plt.figure(figsize=self.figsize_2d)
        
        unique_labels = np.unique(labels)
        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
        
        for i, label in enumerate(unique_labels):
            mask = labels == label
            plt.scatter(features_2d[mask, 0], features_2d[mask, 1], 
                       c=[colors[i]], label=f'Count {label}', alpha=0.7, s=50)
        
        plt.title(title, fontsize=14, pad=20)
        plt.xlabel(f'Component 1', fontsize=12)
        plt.ylabel(f'Component 2', fontsize=12)
        
        # æ·»åŠ æ–¹å·®è§£é‡Šæ¯”ä¾‹ï¼ˆå¦‚æœæ˜¯PCAï¼‰
        if 'explained_variance_ratio' in info:
            plt.xlabel(f'PC1 ({info["explained_variance_ratio"][0]:.1%})', fontsize=12)
            plt.ylabel(f'PC2 ({info["explained_variance_ratio"][1]:.1%})', fontsize=12)
            plt.text(0.02, 0.98, f'Total Variance: {info["total_variance"]:.1%}', 
                    transform=plt.gca().transAxes, fontsize=10,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"    âœ… ä¿å­˜2Då›¾: {os.path.basename(save_path)}")
    
    def plot_3d_scatter(self, features_3d, labels, title, info, save_path):
        """ç»˜åˆ¶3Dæ•£ç‚¹å›¾"""
        from mpl_toolkits.mplot3d import Axes3D
        
        fig = plt.figure(figsize=self.figsize_3d)
        ax = fig.add_subplot(111, projection='3d')
        
        unique_labels = np.unique(labels)
        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
        
        for i, label in enumerate(unique_labels):
            mask = labels == label
            ax.scatter(features_3d[mask, 0], features_3d[mask, 1], features_3d[mask, 2],
                      c=[colors[i]], label=f'Count {label}', alpha=0.7, s=50)
        
        ax.set_title(title, fontsize=14, pad=20)
        
        # è®¾ç½®åæ ‡è½´æ ‡ç­¾
        if 'explained_variance_ratio' in info:
            ax.set_xlabel(f'PC1 ({info["explained_variance_ratio"][0]:.1%})')
            ax.set_ylabel(f'PC2 ({info["explained_variance_ratio"][1]:.1%})')
            ax.set_zlabel(f'PC3 ({info["explained_variance_ratio"][2]:.1%})')
            
            # æ·»åŠ æ€»æ–¹å·®è§£é‡Š
            ax.text2D(0.02, 0.98, f'Total Variance: {info["total_variance"]:.1%}', 
                     transform=ax.transAxes, fontsize=10,
                     bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        else:
            ax.set_xlabel('Component 1')
            ax.set_ylabel('Component 2')
            ax.set_zlabel('Component 3')
        
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # è®¾ç½®è§†è§’
        ax.view_init(elev=20, azim=45)
        
        plt.tight_layout()
        
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"    âœ… ä¿å­˜3Då›¾: {os.path.basename(save_path)}")
    
    def create_component_visualizations(self, features_dict, labels, model_type, save_dir):
        """ä¸ºæ¯ä¸ªç»„ä»¶åˆ›å»ºå¯è§†åŒ–"""
        print(f"\nğŸ¨ åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
        
        for component_name, features in features_dict.items():
            print(f"\nğŸ“Š å¤„ç†ç»„ä»¶: {component_name}")
            print(f"   ç‰¹å¾å½¢çŠ¶: {features.shape}")
            
            component_dir = os.path.join(save_dir, component_name)
            
            # PCA 2D
            features_2d, info_2d = self.reduce_dimensions(features, 'pca', 2)
            title_2d = f'{model_type} - {component_name} (PCA 2D)'
            save_path_2d = os.path.join(component_dir, f'{component_name}_pca_2d.png')
            self.plot_2d_scatter(features_2d, labels, title_2d, info_2d, save_path_2d)
            
            # PCA 3D
            if features.shape[1] >= 3:  # ç¡®ä¿ç‰¹å¾ç»´åº¦è¶³å¤Ÿ
                features_3d, info_3d = self.reduce_dimensions(features, 'pca', 3)
                title_3d = f'{model_type} - {component_name} (PCA 3D)'
                save_path_3d = os.path.join(component_dir, f'{component_name}_pca_3d.png')
                self.plot_3d_scatter(features_3d, labels, title_3d, info_3d, save_path_3d)
            
            # t-SNE 2D
            if len(features) > 50:  # t-SNEéœ€è¦è¶³å¤Ÿçš„æ ·æœ¬
                features_2d_tsne, info_2d_tsne = self.reduce_dimensions(features, 'tsne', 2)
                title_2d_tsne = f'{model_type} - {component_name} (t-SNE 2D)'
                save_path_2d_tsne = os.path.join(component_dir, f'{component_name}_tsne_2d.png')
                self.plot_2d_scatter(features_2d_tsne, labels, title_2d_tsne, info_2d_tsne, save_path_2d_tsne)
                
                # t-SNE 3D
                if features.shape[1] >= 3:
                    features_3d_tsne, info_3d_tsne = self.reduce_dimensions(features, 'tsne', 3)
                    title_3d_tsne = f'{model_type} - {component_name} (t-SNE 3D)'
                    save_path_3d_tsne = os.path.join(component_dir, f'{component_name}_tsne_3d.png')
                    self.plot_3d_scatter(features_3d_tsne, labels, title_3d_tsne, info_3d_tsne, save_path_3d_tsne)
            else:
                print(f"    âš ï¸ æ ·æœ¬æ•°ä¸è¶³ï¼Œè·³è¿‡t-SNEåˆ†æ")


def load_model_and_data(checkpoint_path, val_csv, data_root, batch_size=8):
    """é€šç”¨æ¨¡å‹å’Œæ•°æ®åŠ è½½å‡½æ•°"""
    print("ğŸ“¥ åŠ è½½æ¨¡å‹å’Œæ•°æ®...")
    
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    config = checkpoint['config']
    
    # ç¡®å®šå›¾åƒæ¨¡å¼
    image_mode = config.get('image_mode', 'rgb')
    
    # æ£€æŸ¥æ¨¡å‹ç±»å‹
    model_type = checkpoint.get('model_type', 'embodied')
    
    if model_type in ['counting_only', 'visual_only']:
        # Ablationæ¨¡å‹
        from Model_embodiment_ablation import create_ablation_model
        model = create_ablation_model(model_type, config)
        print(f"âœ… åŠ è½½æ¶ˆèå®éªŒæ¨¡å‹: {model_type}")
    else:
        # åŸå§‹Embodimentæ¨¡å‹
        from Model_embodiment import EmbodiedCountingModel
        input_channels = 3 if image_mode == 'rgb' else 1
        model_config = config['model_config'].copy()
        model_config['input_channels'] = input_channels
        model = EmbodiedCountingModel(**model_config)
        print("âœ… åŠ è½½åŸå§‹å…·èº«è®¡æ•°æ¨¡å‹")
    
    model.load_state_dict(checkpoint['model_state_dict'])
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()
    
    print(f"   å›¾åƒæ¨¡å¼: {image_mode}, è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from DataLoader_embodiment import get_ball_counting_data_loaders
    
    _, val_loader, _ = get_ball_counting_data_loaders(
        train_csv_path=config['train_csv'],
        val_csv_path=val_csv,
        data_root=data_root,
        batch_size=batch_size,
        sequence_length=config['sequence_length'],
        normalize=config['normalize'],
        num_workers=2,
        image_mode=image_mode
    )
    
    print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆï¼ŒéªŒè¯é›†å¤§å°: {len(val_loader.dataset)}")
    
    return model, val_loader, device, config


def analyze_model(checkpoint_path, val_csv, data_root, save_dir, 
                 max_samples=500, components=None):
    """ä¸»åˆ†æå‡½æ•°"""
    
    print("ğŸ”¬ å¼€å§‹æ¨¡å‹ç‰¹å¾åˆ†æ...")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    
    try:
        # 1. åŠ è½½æ¨¡å‹å’Œæ•°æ®
        model, val_loader, device, config = load_model_and_data(
            checkpoint_path, val_csv, data_root
        )
        
        # 2. åˆ›å»ºç‰¹å¾æå–å™¨
        extractor = UniversalFeatureExtractor(model, device)
        
        # 3. ç¡®å®šè¦åˆ†æçš„ç»„ä»¶
        if components is None:
            components = extractor.get_recommended_components()
        
        print(f"ğŸ“‹ å‡†å¤‡åˆ†æçš„ç»„ä»¶: {components}")
        
        # 4. æ³¨å†Œé’©å­å¹¶æå–ç‰¹å¾
        successful_components = extractor.register_hooks(components)
        
        if not successful_components:
            print("âŒ æ²¡æœ‰æˆåŠŸæ³¨å†Œä»»ä½•é’©å­ï¼")
            return None
        
        try:
            # 5. æå–ç‰¹å¾
            print("ğŸ¯ æå–ç»„ä»¶ç‰¹å¾...")
            data = extractor.extract_features(val_loader, max_samples)
            
            features = data['features']
            labels = data['labels']
            model_type = data['model_type']
            
            if not features:
                print("âŒ æ²¡æœ‰æå–åˆ°ä»»ä½•ç‰¹å¾ï¼")
                return None
            
            # 6. åˆ›å»ºå¯è§†åŒ–
            visualizer = VisualizationEngine()
            visualizer.create_component_visualizations(
                features, labels, model_type, save_dir
            )
            
            print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {save_dir}")
            print(f"ğŸ“Š ç”Ÿæˆçš„å¯è§†åŒ–:")
            for component in features.keys():
                print(f"   â€¢ {component}: PCA/t-SNE 2D/3D")
            
            return {
                'features': features,
                'labels': labels,
                'model_type': model_type,
                'components_analyzed': list(features.keys())
            }
            
        finally:
            extractor.remove_hooks()
            
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def inspect_model(checkpoint_path):
    """æ£€æŸ¥æ¨¡å‹ç»“æ„å’Œå¯ç”¨ç»„ä»¶"""
    print("ğŸ” æ£€æŸ¥æ¨¡å‹ç»“æ„...")
    
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        config = checkpoint['config']
        model_type = checkpoint.get('model_type', 'embodied')
        
        # åŠ è½½æ¨¡å‹
        if model_type in ['counting_only', 'visual_only']:
            from Model_embodiment_ablation import create_ablation_model
            model = create_ablation_model(model_type, config)
        else:
            from Model_embodiment import EmbodiedCountingModel
            image_mode = config.get('image_mode', 'rgb')
            input_channels = 3 if image_mode == 'rgb' else 1
            model_config = config['model_config'].copy()
            model_config['input_channels'] = input_channels
            model = EmbodiedCountingModel(**model_config)
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        
        # åˆ›å»ºç‰¹å¾æå–å™¨æ¥æ£€æŸ¥ç»„ä»¶
        extractor = UniversalFeatureExtractor(model, device)
        recommended = extractor.get_recommended_components()
        
        print(f"\nğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
        print(f"   ç±»å‹: {extractor.model_info['type']}")
        print(f"   å¯ç”¨ç»„ä»¶: {extractor.model_info['available_components']}")
        print(f"   æ¨èåˆ†æ: {recommended}")
        
        return recommended
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ£€æŸ¥å¤±è´¥: {e}")
        return None


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    parser = argparse.ArgumentParser(description='é€šç”¨æ¨¡å‹ç‰¹å¾åˆ†æå·¥å…·')
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('--checkpoint', type=str, required=True,
                       help='æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--val_csv', type=str, 
                       default='scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_val.csv',
                       help='éªŒè¯é›†CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--data_root', type=str, 
                       default='/mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/Ball_counting_CNN/ball_data_collection',
                       help='æ•°æ®æ ¹ç›®å½•')
    
    # åˆ†æé€‰é¡¹
    parser.add_argument('--mode', type=str, default='analyze',
                       choices=['inspect', 'analyze'],
                       help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--save_dir', type=str, default=None,
                       help='ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--max_samples', type=int, default=1000,
                       help='æœ€å¤§åˆ†ææ ·æœ¬æ•°')
    parser.add_argument('--components', nargs='+', default=None,
                       help='æŒ‡å®šè¦åˆ†æçš„ç»„ä»¶åç§°')
    
    # å…¶ä»–é€‰é¡¹
    parser.add_argument('--batch_size', type=int, default=16,
                       help='æ•°æ®åŠ è½½æ‰¹æ¬¡å¤§å°')
    
    args = parser.parse_args()
    
    # è®¾ç½®é»˜è®¤ä¿å­˜ç›®å½•
    if args.save_dir is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        model_name = os.path.basename(args.checkpoint).replace('.pth', '')
        args.save_dir = f'./analysis_{model_name}_{timestamp}'
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.checkpoint):
        print(f"âŒ æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {args.checkpoint}")
        return
    
    print("ğŸ”¬ é€šç”¨æ¨¡å‹ç‰¹å¾åˆ†æå·¥å…·")
    print("="*50)
    print(f"æ¨¡å¼: {args.mode}")
    print(f"æ£€æŸ¥ç‚¹: {args.checkpoint}")
    if args.mode == 'analyze':
        print(f"éªŒè¯é›†: {args.val_csv}")
        print(f"æ•°æ®æ ¹ç›®å½•: {args.data_root}")
        print(f"ä¿å­˜ç›®å½•: {args.save_dir}")
        print(f"æœ€å¤§æ ·æœ¬æ•°: {args.max_samples}")
    print("="*50)
    
    start_time = time.time()
    
    try:
        if args.mode == 'inspect':
            recommended = inspect_model(args.checkpoint)
            if recommended:
                print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
                print(f"python {sys.argv[0]} \\")
                print(f"    --checkpoint {args.checkpoint} \\")
                print(f"    --mode analyze \\")
                print(f"    --components {' '.join(recommended[:3])}")  # åªæ˜¾ç¤ºå‰3ä¸ª
        
        elif args.mode == 'analyze':
            # æ£€æŸ¥å…¶ä»–å¿…éœ€æ–‡ä»¶
            for path, name in [(args.val_csv, 'éªŒè¯CSVæ–‡ä»¶'), 
                              (args.data_root, 'æ•°æ®æ ¹ç›®å½•')]:
                if not os.path.exists(path):
                    print(f"âŒ {name}ä¸å­˜åœ¨: {path}")
                    return
            
            results = analyze_model(
                args.checkpoint, args.val_csv, args.data_root, 
                args.save_dir, args.max_samples, args.components
            )
        
        elapsed_time = time.time() - start_time
        print(f"\nğŸ‰ å®Œæˆï¼")
        print(f"â±ï¸ æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­åˆ†æ")
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œæ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    if len(sys.argv) == 1:
        print("ğŸ”¬ é€šç”¨æ¨¡å‹ç‰¹å¾åˆ†æå·¥å…·")
        print("="*50)
        print("æ”¯æŒæ‰€æœ‰æ¨¡å‹ç±»å‹çš„ç‰¹å¾é™ç»´å¯è§†åŒ–")
        print("  â€¢ åŸå§‹Embodimentæ¨¡å‹")
        print("  â€¢ Counting-Onlyæ¶ˆèæ¨¡å‹")
        print("  â€¢ Visual-Onlyæ¶ˆèæ¨¡å‹")
        print()
        print("åŠŸèƒ½ç‰¹è‰²:")
        print("  â€¢ è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹å’Œå¯ç”¨ç»„ä»¶")
        print("  â€¢ PCAå’Œt-SNEé™ç»´å¯è§†åŒ–")
        print("  â€¢ 2Då’Œ3Då¯è§†åŒ–")
        print("  â€¢ æŒ‰ç»„ä»¶åˆ†ç±»å±•ç¤º")
        print()
        print("ä½¿ç”¨æ–¹æ³•:")
        print("1. æ£€æŸ¥æ¨¡å‹ç»“æ„:")
        print("   python Universal_Model_Analysis.py --checkpoint MODEL.pth --mode inspect")
        print()
        print("2. å®Œæ•´åˆ†æ:")
        print("   python Universal_Model_Analysis.py \\")
        print("       --checkpoint MODEL.pth \\")
        print("       --val_csv VAL.csv \\")
        print("       --data_root DATA_DIR \\")
        print("       --mode analyze")
        print()
        print("ç¤ºä¾‹:")
        print("# åˆ†æåŸå§‹Embodimentæ¨¡å‹")
        print("python Universal_Model_Analysis.py \\")
        print("    --checkpoint ./best_embodied_model.pth \\")
        print("    --val_csv ./val_subset.csv \\")
        print("    --data_root ./data \\")
        print("    --mode analyze \\")
        print("    --max_samples 300")
        print()
        print("# åˆ†æCounting-Onlyæ¶ˆèæ¨¡å‹")
        print("python Universal_Model_Analysis.py \\")
        print("    --checkpoint ./best_counting_only_model.pth \\")
        print("    --val_csv ./val_subset.csv \\")
        print("    --data_root ./data \\")
        print("    --mode analyze")
        print()
        print("# åˆ†æç‰¹å®šç»„ä»¶")
        print("python Universal_Model_Analysis.py \\")
        print("    --checkpoint ./model.pth \\")
        print("    --val_csv ./val.csv \\")
        print("    --data_root ./data \\")
        print("    --mode analyze \\")
        print("    --components fusion lstm counting_decoder")
        print()
        print("å¯é€‰å‚æ•°:")
        print("  --save_dir DIR          ä¿å­˜ç›®å½•")
        print("  --max_samples N         æœ€å¤§æ ·æœ¬æ•° (é»˜è®¤500)")
        print("  --components LIST       æŒ‡å®šç»„ä»¶ (é»˜è®¤è‡ªåŠ¨é€‰æ‹©)")
        print("  --batch_size N          æ‰¹æ¬¡å¤§å° (é»˜è®¤8)")
        print()
        print("ğŸ’¡ æ¨èå·¥ä½œæµ:")
        print("1. å…ˆè¿è¡Œ --mode inspect æŸ¥çœ‹æ¨¡å‹ç»“æ„")
        print("2. å†è¿è¡Œ --mode analyze è¿›è¡Œå®Œæ•´åˆ†æ")
        print("3. æ¯ä¸ªç»„ä»¶ä¼šç”Ÿæˆ4å¼ å›¾: PCA-2D, PCA-3D, t-SNE-2D, t-SNE-3D")
        sys.exit(0)
    
    main()


# =============================================================================
# ä¾¿æ·å‡½æ•°ï¼Œä¾›å…¶ä»–è„šæœ¬è°ƒç”¨
# =============================================================================

def quick_analyze(checkpoint_path, val_csv, data_root, save_dir=None, max_samples=200):
    """å¿«é€Ÿåˆ†ææ¥å£"""
    if save_dir is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        model_name = os.path.basename(checkpoint_path).replace('.pth', '')
        save_dir = f'./quick_analysis_{model_name}_{timestamp}'
    
    return analyze_model(checkpoint_path, val_csv, data_root, save_dir, max_samples)


def compare_models(checkpoint_paths, val_csv, data_root, base_save_dir='./model_comparison'):
    """å¯¹æ¯”å¤šä¸ªæ¨¡å‹çš„ç»„ä»¶ç‰¹å¾"""
    print("ğŸ”„ å¼€å§‹å¤šæ¨¡å‹å¯¹æ¯”åˆ†æ...")
    
    results = {}
    
    for i, checkpoint_path in enumerate(checkpoint_paths):
        print(f"\n{'='*60}")
        print(f"åˆ†ææ¨¡å‹ {i+1}/{len(checkpoint_paths)}: {checkpoint_path}")
        print(f"{'='*60}")
        
        model_name = os.path.basename(checkpoint_path).replace('.pth', '')
        save_dir = os.path.join(base_save_dir, f'model_{i+1}_{model_name}')
        
        try:
            result = analyze_model(checkpoint_path, val_csv, data_root, save_dir, max_samples=300)
            results[model_name] = result
            print(f"âœ… æ¨¡å‹ {model_name} åˆ†æå®Œæˆ")
        except Exception as e:
            print(f"âŒ æ¨¡å‹ {model_name} åˆ†æå¤±è´¥: {e}")
            results[model_name] = None
    
    # ç”Ÿæˆå¯¹æ¯”æ€»ç»“
    print(f"\nğŸ“Š å¤šæ¨¡å‹å¯¹æ¯”æ€»ç»“:")
    print("-" * 60)
    for model_name, result in results.items():
        if result:
            print(f"{model_name}:")
            print(f"  æ¨¡å‹ç±»å‹: {result['model_type']}")
            print(f"  åˆ†æç»„ä»¶: {', '.join(result['components_analyzed'])}")
            print(f"  æ ·æœ¬æ•°: {len(result['labels'])}")
        else:
            print(f"{model_name}: åˆ†æå¤±è´¥")
    
    print(f"\nğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {base_save_dir}")
    
    return results


def analyze_specific_components(checkpoint_path, val_csv, data_root, 
                               components, save_dir=None, max_samples=500):
    """åˆ†æç‰¹å®šç»„ä»¶"""
    if save_dir is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        model_name = os.path.basename(checkpoint_path).replace('.pth', '')
        components_str = '_'.join(components)
        save_dir = f'./component_analysis_{model_name}_{components_str}_{timestamp}'
    
    return analyze_model(checkpoint_path, val_csv, data_root, save_dir, max_samples, components)


# =============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# =============================================================================

"""
ä½¿ç”¨ç¤ºä¾‹:

1. å‘½ä»¤è¡Œä½¿ç”¨:
   # æ£€æŸ¥æ¨¡å‹
   python Universal_Model_Analysis.py --checkpoint model.pth --mode inspect
   
   # å®Œæ•´åˆ†æ
   python Universal_Model_Analysis.py \\
       --checkpoint model.pth \\
       --val_csv val.csv \\
       --data_root ./data \\
       --mode analyze \\
       --max_samples 500

2. åœ¨Pythonè„šæœ¬ä¸­ä½¿ç”¨:
   from Universal_Model_Analysis import quick_analyze, compare_models
   
   # å¿«é€Ÿåˆ†æå•ä¸ªæ¨¡å‹
   result = quick_analyze(
       checkpoint_path='./best_model.pth',
       val_csv='./val.csv', 
       data_root='./data',
       max_samples=300
   )
   
   # å¯¹æ¯”å¤šä¸ªæ¨¡å‹
   model_paths = [
       './embodied_model.pth',
       './counting_only_model.pth',
       './visual_only_model.pth'
   ]
   
   comparison_results = compare_models(
       checkpoint_paths=model_paths,
       val_csv='./val.csv',
       data_root='./data'
   )

3. åˆ†æç‰¹å®šç»„ä»¶:
   from Universal_Model_Analysis import analyze_specific_components
   
   result = analyze_specific_components(
       checkpoint_path='./model.pth',
       val_csv='./val.csv',
       data_root='./data',
       components=['fusion', 'lstm'],
       max_samples=400
   )

è¾“å‡ºç»“æ„:
analysis_results/
â”œâ”€â”€ fusion/
â”‚   â”œâ”€â”€ fusion_pca_2d.png      # PCA 2Då¯è§†åŒ–
â”‚   â”œâ”€â”€ fusion_pca_3d.png      # PCA 3Då¯è§†åŒ–
â”‚   â”œâ”€â”€ fusion_tsne_2d.png     # t-SNE 2Då¯è§†åŒ–
â”‚   â””â”€â”€ fusion_tsne_3d.png     # t-SNE 3Då¯è§†åŒ–
â”œâ”€â”€ lstm/
â”‚   â”œâ”€â”€ lstm_pca_2d.png
â”‚   â”œâ”€â”€ lstm_pca_3d.png
â”‚   â”œâ”€â”€ lstm_tsne_2d.png
â”‚   â””â”€â”€ lstm_tsne_3d.png
â””â”€â”€ counting_decoder/
    â”œâ”€â”€ counting_decoder_pca_2d.png
    â”œâ”€â”€ counting_decoder_pca_3d.png
    â”œâ”€â”€ counting_decoder_tsne_2d.png
    â””â”€â”€ counting_decoder_tsne_3d.png
"""
print("åˆ†æå®Œæˆ")