"""
é€šç”¨åŠ¨æ€æ¨¡å‹å¯è§†åŒ–å·¥å…· - å¢å¼ºç‰ˆ
æ”¯æŒåŸå§‹Embodimentæ¨¡å‹å’ŒAblationæ¨¡å‹çš„å¯è§†åŒ–
æ–°å¢åŠŸèƒ½ï¼šjointPCAåˆ†æå’Œç¯å½¢åŠ¨åŠ›å­¦æ£€æµ‹
å¯è§†åŒ–æ¯ä¸ªæ ·æœ¬æ¯ä¸€å¸§çš„:
1. Attentionçƒ­åŠ›å›¾ (å¦‚æœæ¨¡å‹æ”¯æŒ)
2. Softmaxè¾“å‡ºåˆ†å¸ƒ
3. LSTMéšçŠ¶æ€å˜åŒ– (2D + 3D PCA)
4. è·¨æ ·æœ¬jointPCAåˆ†æï¼ˆæ–°å¢ï¼‰
5. ç¯å½¢attractoræ£€æµ‹ï¼ˆæ–°å¢ï¼‰
"""

import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import json
import argparse
from datetime import datetime
from PIL import Image
import cv2

# å¯¼å…¥ç¯å½¢åŠ¨åŠ›å­¦åˆ†ææ¨¡å—
from circular_dynamics_analysis import CircularDynamicsAnalyzer, analyze_rotation_in_trajectories

# è®¾ç½®matplotlibåç«¯
import matplotlib
matplotlib.use('Agg')

# è®¾ç½®å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class UniversalModelVisualizer:
    """é€šç”¨æ¨¡å‹å¯è§†åŒ–å™¨ - æ”¯æŒæ‰€æœ‰æ¨¡å‹ç±»å‹"""
    
    def __init__(self, model, device='cuda'):
        self.model = model
        self.device = device
        self.model.eval()
        
        # æ£€æµ‹æ¨¡å‹ç±»å‹å’Œèƒ½åŠ›
        self.model_info = self._detect_model_capabilities()
        print(f"âœ… æ£€æµ‹åˆ°æ¨¡å‹ç±»å‹: {self.model_info['model_type']}")
        print(f"   æ”¯æŒçš„åŠŸèƒ½: {', '.join(self.model_info['capabilities'])}")
        
        # æ–°å¢ï¼šç”¨äºæ”¶é›†è·¨æ ·æœ¬çš„LSTMè½¨è¿¹
        self.collected_lstm_trajectories = {}
        
    def _detect_model_capabilities(self):
        """æ£€æµ‹æ¨¡å‹ç±»å‹å’Œæ”¯æŒçš„åŠŸèƒ½"""
        model_info = {
            'model_type': 'unknown',
            'capabilities': [],
            'has_attention': False,
            'has_embodiment': False,
            'has_motion_decoder': False
        }
        
        # æ£€æŸ¥æ¨¡å‹ç±»å‹
        model_class_name = self.model.__class__.__name__
        
        if hasattr(self.model, 'get_model_info'):
            # æ–°çš„ablationæ¨¡å‹æœ‰get_model_infoæ–¹æ³•
            info = self.model.get_model_info()
            model_info.update(info)
            model_info['model_type'] = info.get('model_type', model_class_name)
            model_info['has_embodiment'] = info.get('has_embodiment', False)
            model_info['has_motion_decoder'] = info.get('has_motion_decoder', False)
        else:
            # åŸå§‹Embodimentæ¨¡å‹
            model_info['model_type'] = 'EmbodiedCountingModel'
            model_info['has_embodiment'] = True
            model_info['has_motion_decoder'] = True
        
        # æ£€æŸ¥æ˜¯å¦æœ‰attentionæœºåˆ¶
        if hasattr(self.model, 'fusion') or hasattr(self.model, 'attention_weights_history'):
            model_info['has_attention'] = True
        
        # ç¡®å®šæ”¯æŒçš„åŠŸèƒ½
        capabilities = ['counting', 'lstm_states']
        if model_info['has_attention']:
            capabilities.append('attention')
        if model_info['has_embodiment']:
            capabilities.append('embodiment')
        if model_info['has_motion_decoder']:
            capabilities.append('motion_prediction')
            
        model_info['capabilities'] = capabilities
        
        return model_info
    
    def _prepare_model_for_visualization(self):
        """ä¸ºå¯è§†åŒ–å‡†å¤‡æ¨¡å‹"""
        # æ¸…ç©ºå†å²è®°å½•
        if hasattr(self.model, 'lstm_hidden_states'):
            self.model.lstm_hidden_states = []
        if hasattr(self.model, 'attention_weights_history'):
            self.model.attention_weights_history = []
    
    def _get_model_outputs(self, sequence_data):
        """è·å–æ¨¡å‹è¾“å‡º"""
        self._prepare_model_for_visualization()
        
        with torch.no_grad():
            # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒç”¨forward
            if self.model_info['has_attention']:
                outputs = self.model(
                    sequence_data=sequence_data,
                    use_teacher_forcing=False,
                    return_attention=True
                )
            else:
                outputs = self.model(
                    sequence_data=sequence_data,
                    use_teacher_forcing=False
                )
        
        return outputs
    
    def _extract_visualization_data(self, outputs):
        """æå–å¯è§†åŒ–æ•°æ®"""
        viz_data = {}
        
        # è®¡æ•°ç›¸å…³æ•°æ®
        count_logits = outputs['counts'][0]  # [seq_len, 11]
        
        viz_data['softmax_probs'] = F.softmax(count_logits, dim=-1)  # [seq_len, 11]
        viz_data['predictions'] = torch.argmax(count_logits, dim=-1)  # [seq_len]
        
        # LSTMçŠ¶æ€
        if hasattr(self.model, 'lstm_hidden_states') and self.model.lstm_hidden_states:
            viz_data['lstm_states'] = self.model.lstm_hidden_states
        else:
            viz_data['lstm_states'] = []
        
        # Attentionæƒé‡
        if (self.model_info['has_attention'] and 
            hasattr(self.model, 'attention_weights_history') and 
            self.model.attention_weights_history):
            viz_data['attention_weights'] = self.model.attention_weights_history
        else:
            viz_data['attention_weights'] = []
        
        # å…³èŠ‚é¢„æµ‹ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'joints' in outputs:
            viz_data['joint_predictions'] = outputs['joints'][0]
        else:
            viz_data['joint_predictions'] = None
            
        return viz_data
    
    def visualize_sample_sequence(self, sample_data, sample_id, save_dir, collect_for_joint_pca=True):
        """å¯è§†åŒ–å•ä¸ªæ ·æœ¬çš„å®Œæ•´åºåˆ—"""
        
        # åˆ›å»ºæ ·æœ¬ä¿å­˜ç›®å½•
        sample_dir = os.path.join(save_dir, f'sample_{sample_id}')
        os.makedirs(sample_dir, exist_ok=True)
        
        # å‡†å¤‡æ•°æ®
        sequence_data = {
            'images': sample_data['sequence_data']['images'].unsqueeze(0).to(self.device),
            'joints': sample_data['sequence_data']['joints'].unsqueeze(0).to(self.device),
            'timestamps': sample_data['sequence_data']['timestamps'].unsqueeze(0).to(self.device),
            'labels': sample_data['sequence_data']['labels'].unsqueeze(0).to(self.device)
        }
        
        seq_len = sequence_data['images'].shape[1]
        true_label = sample_data['label'].item()
        
        print(f"\nå¤„ç†æ ·æœ¬ {sample_id} (çœŸå®æ ‡ç­¾: {true_label}, åºåˆ—é•¿åº¦: {seq_len})")
        
        # è·å–æ¨¡å‹è¾“å‡ºå’Œå¯è§†åŒ–æ•°æ®
        outputs = self._get_model_outputs(sequence_data)
        viz_data = self._extract_visualization_data(outputs)
        
        # æ–°å¢ï¼šæ”¶é›†LSTMè½¨è¿¹ç”¨äºåç»­çš„jointPCAåˆ†æ
        if collect_for_joint_pca and viz_data['lstm_states']:
            self.collected_lstm_trajectories[(true_label, sample_id)] = viz_data['lstm_states']
        
        # ç”Ÿæˆæ¯ä¸€å¸§çš„å¯è§†åŒ–
        self._generate_frame_visualizations(
            sequence_data, viz_data, true_label, sample_id, sample_dir, seq_len
        )
        
        # ç”Ÿæˆæ±‡æ€»å›¾
        self._generate_summary_plot(
            viz_data, sequence_data, true_label, sample_id, sample_dir
        )
        
        # ä¿å­˜æ•°å€¼æ•°æ®
        self._save_numerical_data(
            viz_data, true_label, sample_id, sample_dir
        )
        
        print(f"âœ… æ ·æœ¬ {sample_id} å¯è§†åŒ–å®Œæˆ")
    
    def perform_joint_pca_analysis(self, save_dir):
        """æ‰§è¡Œè·¨æ ·æœ¬çš„jointPCAåˆ†æ"""
        if not self.collected_lstm_trajectories:
            print("âš ï¸ æ²¡æœ‰æ”¶é›†åˆ°LSTMè½¨è¿¹æ•°æ®")
            return None
        
        print(f"\nğŸ”„ å¼€å§‹jointPCAåˆ†æ...")
        print(f"   æ”¶é›†äº† {len(self.collected_lstm_trajectories)} ä¸ªæ ·æœ¬çš„è½¨è¿¹")
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = CircularDynamicsAnalyzer()
        
        # æŒ‰æ ‡ç­¾ç»Ÿè®¡
        label_counts = {}
        for (label, sample_id), lstm_states in self.collected_lstm_trajectories.items():
            analyzer.add_trajectory(lstm_states, label, sample_id)
            label_counts[label] = label_counts.get(label, 0) + 1
        
        print(f"   æ ‡ç­¾åˆ†å¸ƒ: {dict(sorted(label_counts.items()))}")
        
        # æ‰§è¡ŒjointPCA
        trajectories_pca, trajectory_info = analyzer.compute_joint_pca(n_components=3)
        explained_var = analyzer.analysis_results['joint_pca']['explained_variance_ratio']
        total_var = analyzer.analysis_results['joint_pca']['total_variance']
        
        print(f"   PCAè§£é‡Šæ–¹å·®: PC1={explained_var[0]:.2%}, PC2={explained_var[1]:.2%}, PC3={explained_var[2]:.2%}")
        print(f"   æ€»è§£é‡Šæ–¹å·®: {total_var:.2%}")
        
        # æ£€æµ‹æ—‹è½¬æ¨¡å¼
        patterns = analyzer.detect_rotation_patterns(min_circularity=0.5)
        circular_count = sum(1 for p in patterns if p['is_circular'])
        
        print(f"   æ£€æµ‹åˆ° {circular_count}/{len(patterns)} ä¸ªç¯å½¢è½¨è¿¹")
        
        # åˆ›å»ºå¯è§†åŒ–
        joint_pca_dir = os.path.join(save_dir, 'joint_pca_analysis')
        os.makedirs(joint_pca_dir, exist_ok=True)
        
        # 1. Joint PCAè½¨è¿¹å›¾
        analyzer.plot_joint_trajectories(
            save_path=os.path.join(joint_pca_dir, 'joint_pca_trajectories.png')
        )
        
        # 2. ç¯å½¢æ¨¡å¼åˆ†æ
        analyzer.plot_circular_analysis(
            save_path=os.path.join(joint_pca_dir, 'circular_patterns.png')
        )
        
        # 3. æ—‹è½¬æŒ‡æ ‡æ±‡æ€»
        analyzer.plot_rotation_metrics_summary(
            save_path=os.path.join(joint_pca_dir, 'rotation_metrics_summary.png')
        )
        
        # 4. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self._generate_joint_pca_report(analyzer, joint_pca_dir)
        
        print(f"âœ… JointPCAåˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åœ¨: {joint_pca_dir}")
        
        return analyzer
    
    def _generate_joint_pca_report(self, analyzer, save_dir):
        """ç”ŸæˆjointPCAåˆ†ææŠ¥å‘Š"""
        patterns = analyzer.analysis_results['rotation_patterns']
        
        # ç»Ÿè®¡å„æ ‡ç­¾çš„ç¯å½¢ç‰¹æ€§
        stats_by_label = {}
        for pattern in patterns:
            label = pattern['label']
            if label not in stats_by_label:
                stats_by_label[label] = {
                    'circular_count': 0,
                    'total_count': 0,
                    'avg_circularity': 0,
                    'avg_rotations': 0,
                    'direction_counts': {'CW': 0, 'CCW': 0}
                }
            
            stats = stats_by_label[label]
            stats['total_count'] += 1
            
            metrics = pattern['metrics']
            if pattern['is_circular']:
                stats['circular_count'] += 1
            
            stats['avg_circularity'] += metrics['circularity_score']
            stats['avg_rotations'] += abs(metrics['total_rotations'])
            
            if metrics['rotation_direction'] > 0:
                stats['direction_counts']['CCW'] += 1
            else:
                stats['direction_counts']['CW'] += 1
        
        # è®¡ç®—å¹³å‡å€¼å¹¶è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹
        for label in list(stats_by_label.keys()):
            stats = stats_by_label[label]
            n = stats['total_count']
            stats['avg_circularity'] = float(stats['avg_circularity'] / n)
            stats['avg_rotations'] = float(stats['avg_rotations'] / n)
            stats['circular_ratio'] = float(stats['circular_count'] / n)
            # ç¡®ä¿labelä¹Ÿæ˜¯åŸç”Ÿç±»å‹
            stats_by_label[int(label)] = stats_by_label.pop(label)
        
        # ç”ŸæˆæŠ¥å‘Š - ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„
        report = {
            'analysis_summary': {
                'total_samples': int(len(patterns)),
                'circular_samples': int(sum(1 for p in patterns if p['is_circular'])),
                'explained_variance': [float(x) for x in analyzer.analysis_results['joint_pca']['explained_variance_ratio'].tolist()],
                'total_variance': float(analyzer.analysis_results['joint_pca']['total_variance'])
            },
            'label_statistics': stats_by_label,
            'model_info': {k: v for k, v in self.model_info.items()}  # åˆ›å»ºå‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        }
        
        # ä¿å­˜JSONæŠ¥å‘Š
        with open(os.path.join(save_dir, 'joint_pca_report.json'), 'w') as f:
            json.dump(report, f, indent=2)
        
        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        text_report = f"""Joint PCA Analysis Report
=======================

Model Type: {self.model_info['model_type']}
Total Samples Analyzed: {report['analysis_summary']['total_samples']}
Circular Patterns Found: {report['analysis_summary']['circular_samples']} ({report['analysis_summary']['circular_samples']/report['analysis_summary']['total_samples']*100:.1f}%)

PCA Variance Explained:
- PC1: {report['analysis_summary']['explained_variance'][0]:.2%}
- PC2: {report['analysis_summary']['explained_variance'][1]:.2%}  
- PC3: {report['analysis_summary']['explained_variance'][2]:.2%}
- Total: {report['analysis_summary']['total_variance']:.2%}

Per-Label Statistics:
"""
        
        for label in sorted(stats_by_label.keys()):
            stats = stats_by_label[label]
            text_report += f"\nLabel {label}:\n"
            text_report += f"  - Samples: {stats['total_count']}\n"
            text_report += f"  - Circular: {stats['circular_count']} ({stats['circular_ratio']*100:.1f}%)\n"
            text_report += f"  - Avg Circularity: {stats['avg_circularity']:.3f}\n"
            text_report += f"  - Avg Rotations: {stats['avg_rotations']:.2f}\n"
            text_report += f"  - Direction: CCW={stats['direction_counts']['CCW']}, CW={stats['direction_counts']['CW']}\n"
        
        with open(os.path.join(save_dir, 'joint_pca_report.txt'), 'w') as f:
            f.write(text_report)
    
    # [å…¶ä½™æ–¹æ³•ä¿æŒä¸å˜ï¼Œä»åŸå§‹ä»£ç å¤åˆ¶]
    def _generate_frame_visualizations(self, sequence_data, viz_data, true_label, 
                                     sample_id, sample_dir, seq_len):
        """ç”Ÿæˆæ¯ä¸€å¸§çš„å¯è§†åŒ–"""
        
        softmax_probs = viz_data['softmax_probs']
        predictions = viz_data['predictions']
        lstm_states = viz_data['lstm_states']
        attention_weights = viz_data['attention_weights']
        
        for t in range(seq_len):
            fig = self._create_frame_figure(
                sequence_data, viz_data, t, true_label, sample_id, seq_len
            )
            
            # ä¿å­˜å½“å‰å¸§
            frame_path = os.path.join(sample_dir, f'frame_{t:03d}.png')
            plt.savefig(frame_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            # ç”Ÿæˆ3D LSTMçŠ¶æ€å›¾ï¼ˆå¦‚æœæ¡ä»¶æ»¡è¶³ï¼‰
            self._generate_3d_lstm_plot(viz_data['lstm_states'], t, sample_dir)
    
    def _create_frame_figure(self, sequence_data, viz_data, t, true_label, sample_id, seq_len):
        """åˆ›å»ºå•å¸§å¯è§†åŒ–å›¾"""
        
        # æ ¹æ®æ¨¡å‹èƒ½åŠ›ç¡®å®šå­å›¾å¸ƒå±€
        if self.model_info['has_attention']:
            fig = plt.figure(figsize=(20, 12))
            subplot_layout = (2, 3)
        else:
            fig = plt.figure(figsize=(16, 10))
            subplot_layout = (2, 2)
        
        subplot_idx = 1
        
        # 1. åŸå§‹å›¾åƒ
        ax1 = plt.subplot(subplot_layout[0], subplot_layout[1], subplot_idx)
        self._plot_original_image(ax1, sequence_data['images'][0, t], t, seq_len)
        subplot_idx += 1
        
        # 2. Attentionçƒ­åŠ›å›¾ (å¦‚æœæ”¯æŒ)
        if self.model_info['has_attention']:
            ax2 = plt.subplot(subplot_layout[0], subplot_layout[1], subplot_idx)
            self._plot_attention_map(ax2, viz_data['attention_weights'], 
                                   sequence_data['images'][0, t], t)
            subplot_idx += 1
        
        # 3. Softmaxè¾“å‡ºåˆ†å¸ƒ
        ax3 = plt.subplot(subplot_layout[0], subplot_layout[1], subplot_idx)
        self._plot_softmax_distribution(ax3, viz_data['softmax_probs'], 
                                      viz_data['predictions'], t)
        subplot_idx += 1
        
        # 4. Softmaxåˆ†å¸ƒæ—¶åºå˜åŒ–
        ax4 = plt.subplot(subplot_layout[0], subplot_layout[1], subplot_idx)
        self._plot_softmax_evolution(ax4, viz_data['softmax_probs'], 
                                   viz_data['predictions'], t, seq_len)
        subplot_idx += 1
        
        # 5. LSTMéšçŠ¶æ€å˜åŒ– (2D)
        if subplot_idx <= subplot_layout[0] * subplot_layout[1]:
            ax5 = plt.subplot(subplot_layout[0], subplot_layout[1], subplot_idx)
            self._plot_lstm_states_2d(ax5, viz_data['lstm_states'], t)
            subplot_idx += 1
        
        # 6. é¢„æµ‹åºåˆ—å’Œä¿¡æ¯
        if subplot_idx <= subplot_layout[0] * subplot_layout[1]:
            ax6 = plt.subplot(subplot_layout[0], subplot_layout[1], subplot_idx)
            self._plot_prediction_sequence(ax6, viz_data['predictions'], 
                                         sequence_data['labels'][0], t, 
                                         true_label, sample_id)
        
        plt.tight_layout()
        return fig
    
    def _plot_original_image(self, ax, img_tensor, t, seq_len):
        """ç»˜åˆ¶åŸå§‹å›¾åƒ"""
        img = img_tensor.cpu()
        
        if img.shape[0] == 1:  # ç°åº¦å›¾
            img = img.squeeze(0)
            ax.imshow(img, cmap='gray')
        else:  # RGB
            img = img.permute(1, 2, 0)
            # åå½’ä¸€åŒ–
            mean = torch.tensor([0.485, 0.456, 0.406])
            std = torch.tensor([0.229, 0.224, 0.225])
            img = img * std + mean
            img = torch.clamp(img, 0, 1)
            ax.imshow(img)
        
        ax.set_title(f'Frame {t+1}/{seq_len}')
        ax.axis('off')
    
    def _plot_attention_map(self, ax, attention_weights, img_tensor, t):
        """ç»˜åˆ¶attentionçƒ­åŠ›å›¾"""
        if t < len(attention_weights):
            att_weights = attention_weights[t].cpu().numpy().squeeze()
            spatial_size = len(att_weights)
            grid_size = int(np.sqrt(spatial_size))
            
            if grid_size * grid_size == spatial_size:
                att_map = att_weights.reshape(grid_size, grid_size)
                att_map_resized = cv2.resize(att_map, (224, 224))
                
                # æ˜¾ç¤ºå›¾åƒèƒŒæ™¯
                img = img_tensor.cpu()
                if img.shape[0] == 1:
                    img = img.squeeze(0)
                    ax.imshow(img, cmap='gray', alpha=0.5)
                else:
                    img = img.permute(1, 2, 0)
                    mean = torch.tensor([0.485, 0.456, 0.406])
                    std = torch.tensor([0.229, 0.224, 0.225])
                    img = img * std + mean
                    img = torch.clamp(img, 0, 1)
                    ax.imshow(img, alpha=0.5)
                
                # å åŠ attention
                im = ax.imshow(att_map_resized, cmap='viridis', alpha=0.5)
                plt.colorbar(im, ax=ax, fraction=0.046)
            else:
                ax.bar(range(len(att_weights)), att_weights)
                ax.set_xlabel('Spatial Position')
                ax.set_ylabel('Attention Weight')
            
            ax.set_title(f'Attention Map (t={t+1})')
        else:
            ax.text(0.5, 0.5, 'No attention data', ha='center', va='center')
            ax.set_title(f'Attention Map (t={t+1})')
    
    def _plot_softmax_distribution(self, ax, softmax_probs, predictions, t):
        """ç»˜åˆ¶Softmaxåˆ†å¸ƒ"""
        probs_t = softmax_probs[t].cpu().numpy()
        pred_t = predictions[t].item()
        
        bars = ax.bar(range(11), probs_t, color='skyblue', alpha=0.7)
        bars[pred_t].set_color('red')
        
        # æ·»åŠ æ¦‚ç‡å€¼æ ‡ç­¾
        for i, prob in enumerate(probs_t):
            if prob > 0.01:
                ax.text(i, prob + 0.01, f'{prob:.2f}', ha='center', fontsize=8)
        
        ax.set_xlabel('Count Class')
        ax.set_ylabel('Probability')
        ax.set_title(f'Softmax Output (Pred: {pred_t})')
        ax.set_xticks(range(11))
        ax.set_ylim(0, 1.1)
        ax.grid(True, alpha=0.3)
    
    def _plot_softmax_evolution(self, ax, softmax_probs, predictions, t, seq_len):
        """ç»˜åˆ¶Softmaxæ¼”åŒ–"""
        pred_t = predictions[t].item()
        
        for class_idx in range(11):
            probs_history = softmax_probs[:t+1, class_idx].cpu().numpy()
            if np.max(probs_history) > 0.1:
                ax.plot(range(t+1), probs_history, label=f'Class {class_idx}', 
                       linewidth=2 if class_idx == pred_t else 1,
                       alpha=1.0 if class_idx == pred_t else 0.5)
        
        ax.set_xlabel('Frame')
        ax.set_ylabel('Probability')
        ax.set_title('Softmax Evolution')
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.grid(True, alpha=0.3)
        ax.set_xlim(-0.5, seq_len-0.5)
    
    def _plot_lstm_states_2d(self, ax, lstm_states, t):
        """ç»˜åˆ¶2D LSTMçŠ¶æ€ - æ€»æ˜¯æ˜¾ç¤º2Dç‰ˆæœ¬"""
        if t < len(lstm_states):
            states_so_far = torch.stack(lstm_states[:t+1]).cpu().numpy()
            if len(states_so_far.shape) > 2:
                states_so_far = states_so_far.squeeze(1)
            
            if states_so_far.shape[0] > 2:  # è‡³å°‘éœ€è¦3ä¸ªæ—¶é—´æ­¥
                try:
                    from sklearn.decomposition import PCA
                    
                    # ä½¿ç”¨2D PCA
                    pca = PCA(n_components=2)
                    states_2d = pca.fit_transform(states_so_far)
                    
                    # ç»˜åˆ¶2Dè½¨è¿¹
                    ax.plot(states_2d[:, 0], states_2d[:, 1], 'b-', alpha=0.6, linewidth=2)
                    ax.scatter(states_2d[:, 0], states_2d[:, 1], 
                              c=range(t+1), cmap='viridis', s=60, alpha=0.8)
                    ax.scatter(states_2d[-1, 0], states_2d[-1, 1], 
                              color='red', s=100, marker='*', 
                              edgecolor='black', linewidth=1, label='Current')
                    
                    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')
                    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')
                    ax.set_title('LSTM State Trajectory (2D PCA)')
                    ax.legend()
                    
                    total_var = pca.explained_variance_ratio_.sum()
                    ax.text(0.02, 0.98, f'Total Var: {total_var:.1%}', 
                           transform=ax.transAxes, fontsize=9,
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
                    
                except ImportError:
                    # å¦‚æœæ²¡æœ‰sklearnï¼Œæ˜¾ç¤ºå‰ä¸¤ä¸ªç»´åº¦çš„åŸå§‹å€¼
                    self._plot_raw_states(ax, states_so_far)
                    
            else:
                # æ—¶é—´æ­¥ä¸å¤Ÿï¼Œæ˜¾ç¤ºåŸå§‹ç»´åº¦
                self._plot_raw_states(ax, states_so_far)
        else:
            ax.text(0.5, 0.5, 'No LSTM state data', ha='center', va='center')
            ax.set_title('LSTM States (Not Available)')
        
        ax.grid(True, alpha=0.3)
    
    def _generate_3d_lstm_plot(self, lstm_states, t, sample_dir):
        """ç”Ÿæˆç‹¬ç«‹çš„3D LSTMçŠ¶æ€å›¾"""
        if t < len(lstm_states):
            states_so_far = torch.stack(lstm_states[:t+1]).cpu().numpy()
            if len(states_so_far.shape) > 2:
                states_so_far = states_so_far.squeeze(1)
            
            # åªæœ‰åœ¨æ¡ä»¶æ»¡è¶³æ—¶æ‰ç”Ÿæˆ3Då›¾
            if (states_so_far.shape[0] > 4 and  # è‡³å°‘5ä¸ªæ—¶é—´æ­¥
                states_so_far.shape[1] >= 3 and  # ç»´åº¦è¶³å¤Ÿ
                t >= 6):  # è¶³å¤Ÿçš„æ—¶é—´æ­¥æ¥å±•ç¤ºè½¨è¿¹
                
                try:
                    from sklearn.decomposition import PCA
                    from mpl_toolkits.mplot3d import Axes3D
                    
                    # åˆ›å»ºç‹¬ç«‹çš„3Då›¾
                    fig = plt.figure(figsize=(10, 8))
                    ax = fig.add_subplot(111, projection='3d')
                    
                    pca = PCA(n_components=3)
                    states_3d = pca.fit_transform(states_so_far)
                    
                    # ç»˜åˆ¶3Dè½¨è¿¹
                    ax.plot(states_3d[:, 0], states_3d[:, 1], states_3d[:, 2], 
                           'b-', alpha=0.6, linewidth=2, label='Trajectory')
                    
                    # ç»˜åˆ¶æ—¶é—´æ­¥ç‚¹
                    scatter = ax.scatter(states_3d[:, 0], states_3d[:, 1], states_3d[:, 2],
                                       c=range(t+1), cmap='viridis', s=60, alpha=0.8)
                    
                    # çªå‡ºæ˜¾ç¤ºå½“å‰ç‚¹
                    ax.scatter(states_3d[-1, 0], states_3d[-1, 1], states_3d[-1, 2],
                              color='red', s=120, marker='*', 
                              edgecolor='black', linewidth=1, label='Current')
                    
                    # æ·»åŠ èµ·ç‚¹æ ‡è®°
                    ax.scatter(states_3d[0, 0], states_3d[0, 1], states_3d[0, 2],
                              color='green', s=100, marker='o', 
                              edgecolor='black', linewidth=1, label='Start')
                    
                    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')
                    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')
                    ax.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]:.2%})')
                    ax.set_title(f'LSTM State Trajectory 3D (Frame {t+1})')
                    ax.legend()
                    
                    # è®¾ç½®è§†è§’
                    ax.view_init(elev=20, azim=45)
                    
                    total_var = pca.explained_variance_ratio_.sum()
                    ax.text2D(0.02, 0.98, f'Total Var: {total_var:.1%}', 
                             transform=ax.transAxes, fontsize=10,
                             bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.8))
                    
                    # æ·»åŠ é¢œè‰²æ¡
                    cbar = plt.colorbar(scatter, ax=ax, shrink=0.5, aspect=5)
                    cbar.set_label('Time Step')
                    
                    plt.tight_layout()
                    
                    # ä¿å­˜3Då›¾
                    lstm_3d_path = os.path.join(sample_dir, f'lstm_3d_frame_{t:03d}.png')
                    plt.savefig(lstm_3d_path, dpi=200, bbox_inches='tight')
                    plt.close()
                    
                except Exception as e:
                    # å¦‚æœ3Dç»˜åˆ¶å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹
                    pass
    
    def _plot_raw_states(self, ax, states_so_far):
        """ç»˜åˆ¶åŸå§‹çŠ¶æ€å€¼"""
        ax.plot(states_so_far[:, 0], 'b-', label='Dim 0', linewidth=2)
        if states_so_far.shape[1] > 1:
            ax.plot(states_so_far[:, 1], 'r-', label='Dim 1', linewidth=2)
        if states_so_far.shape[1] > 2:
            ax.plot(states_so_far[:, 2], 'g-', label='Dim 2', linewidth=2)
        ax.set_xlabel('Frame')
        ax.set_ylabel('State Value')
        ax.set_title('LSTM State Evolution (Raw)')
        ax.legend()
        ax.text(0.02, 0.98, 'Raw dimensions', 
               transform=ax.transAxes, fontsize=9,
               bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.8))
    
    def _plot_prediction_sequence(self, ax, predictions, true_labels, t, 
                                true_label, sample_id):
        """ç»˜åˆ¶é¢„æµ‹åºåˆ—"""
        pred_seq = predictions[:t+1].cpu().numpy()
        true_seq = true_labels[:t+1].cpu().numpy()
        
        ax.plot(range(t+1), pred_seq, 'ro-', label='Predictions', markersize=8)
        ax.plot(range(t+1), true_seq, 'bs--', label='True Labels', markersize=6)
        
        ax.set_xlabel('Frame')
        ax.set_ylabel('Count')
        ax.set_title('Prediction Sequence')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim(-0.5, 10.5)
        ax.set_yticks(range(11))
        
        # æ·»åŠ ä¿¡æ¯æ–‡æœ¬
        pred_t = predictions[t].item()
        
        info_text = f"Sample ID: {sample_id}\n"
        info_text += f"True Label: {true_label}\n"
        info_text += f"Current Pred: {pred_t}\n"
        info_text += f"Final Pred: {predictions[-1].item()}\n"
        info_text += f"Model: {self.model_info['model_type']}"
        
        ax.text(0.02, 0.98, info_text, transform=ax.transAxes,
               bbox=dict(boxstyle="round,pad=0.3", facecolor="wheat", alpha=0.5),
               verticalalignment='top', fontsize=10)
    
    def _generate_summary_plot(self, viz_data, sequence_data, true_label, 
                              sample_id, sample_dir):
        """ç”Ÿæˆæ±‡æ€»å¯è§†åŒ–å›¾"""
        
        fig = plt.figure(figsize=(16, 10))
        
        # 1. Softmaxçƒ­åŠ›å›¾
        ax1 = plt.subplot(2, 2, 1)
        sns.heatmap(viz_data['softmax_probs'].cpu().numpy().T, 
                   cmap='YlOrRd', cbar=True, 
                   xticklabels=range(len(viz_data['softmax_probs'])),
                   yticklabels=range(11))
        ax1.set_xlabel('Frame')
        ax1.set_ylabel('Count Class')
        ax1.set_title('Softmax Probability Heatmap')
        
        # 2. é¢„æµ‹å‡†ç¡®åº¦æ—¶åºå›¾
        ax2 = plt.subplot(2, 2, 2)
        pred_np = viz_data['predictions'].cpu().numpy()
        true_np = sequence_data['labels'][0].cpu().numpy()
        correct = pred_np == true_np
        
        ax2.plot(range(len(pred_np)), pred_np, 'ro-', label='Predictions')
        ax2.plot(range(len(true_np)), true_np, 'bs--', label='True Labels')
        
        for i, is_correct in enumerate(correct):
            color = 'green' if is_correct else 'red'
            ax2.axvspan(i-0.3, i+0.3, alpha=0.2, color=color)
        
        ax2.set_xlabel('Frame')
        ax2.set_ylabel('Count')
        ax2.set_title('Prediction vs Ground Truth')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. LSTMçŠ¶æ€çƒ­åŠ›å›¾
        ax3 = plt.subplot(2, 2, 3)
        if viz_data['lstm_states']:
            lstm_array = torch.stack(viz_data['lstm_states']).cpu().numpy()
            if len(lstm_array.shape) > 2:
                lstm_array = lstm_array.squeeze(1)
            
            n_dims_to_show = min(50, lstm_array.shape[1])
            sns.heatmap(lstm_array[:, :n_dims_to_show].T,
                       cmap='coolwarm', center=0,
                       xticklabels=range(len(viz_data['lstm_states'])),
                       yticklabels=False)
            ax3.set_xlabel('Frame')
            ax3.set_ylabel(f'LSTM Hidden Dims (first {n_dims_to_show})')
            ax3.set_title('LSTM Hidden State Evolution')
        else:
            ax3.text(0.5, 0.5, 'No LSTM state data', ha='center', va='center')
            ax3.set_title('LSTM States (Not Available)')
        
        # 4. ç½®ä¿¡åº¦å˜åŒ–
        ax4 = plt.subplot(2, 2, 4)
        
        max_probs = torch.max(viz_data['softmax_probs'], dim=1)[0].cpu().numpy()
        
        correct_class_probs = []
        for t in range(len(viz_data['predictions'])):
            true_class = int(true_np[t])
            prob = viz_data['softmax_probs'][t, true_class].item()
            correct_class_probs.append(prob)
        
        ax4.plot(range(len(max_probs)), max_probs, 'b-', 
                label='Max Confidence', linewidth=2)
        ax4.plot(range(len(correct_class_probs)), correct_class_probs, 'g--', 
                label='True Class Prob', linewidth=2)
        
        ax4.fill_between(range(len(max_probs)), 0, max_probs, alpha=0.3)
        ax4.set_xlabel('Frame')
        ax4.set_ylabel('Probability')
        ax4.set_title('Model Confidence Over Time')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        ax4.set_ylim(0, 1.1)
        
        # æ·»åŠ æ¨¡å‹ä¿¡æ¯
        model_info_text = f"Model: {self.model_info['model_type']}\n"
        model_info_text += f"Capabilities: {', '.join(self.model_info['capabilities'])}"
        
        fig.suptitle(f'Sample {sample_id} Summary - True Label: {true_label}, '
                    f'Final Prediction: {viz_data["predictions"][-1].item()}\n'
                    f'{model_info_text}', fontsize=14)
        
        plt.tight_layout()
        
        summary_path = os.path.join(sample_dir, 'summary.png')
        plt.savefig(summary_path, dpi=200, bbox_inches='tight')
        plt.close()
        
        # ç”ŸæˆLSTMçŠ¶æ€çš„å®Œæ•´3Dè½¨è¿¹æ€»ç»“å›¾
        self._generate_full_3d_lstm_summary(viz_data['lstm_states'], sample_id, sample_dir)
    
    def _generate_full_3d_lstm_summary(self, lstm_states, sample_id, sample_dir):
        """ç”Ÿæˆå®Œæ•´çš„3D LSTMè½¨è¿¹æ€»ç»“å›¾"""
        if not lstm_states or len(lstm_states) < 5:
            return
        
        try:
            from sklearn.decomposition import PCA
            from mpl_toolkits.mplot3d import Axes3D
            
            states_array = torch.stack(lstm_states).cpu().numpy()
            if len(states_array.shape) > 2:
                states_array = states_array.squeeze(1)
            
            if states_array.shape[1] < 3:
                return
            
            # åˆ›å»º3Dæ€»ç»“å›¾
            fig = plt.figure(figsize=(12, 10))
            
            # 3D PCAå›¾
            ax1 = fig.add_subplot(221, projection='3d')
            
            pca = PCA(n_components=3)
            states_3d = pca.fit_transform(states_array)
            
            # ç»˜åˆ¶å®Œæ•´è½¨è¿¹
            ax1.plot(states_3d[:, 0], states_3d[:, 1], states_3d[:, 2], 
                    'b-', alpha=0.6, linewidth=3, label='Full Trajectory')
            
            # æ—¶é—´æ¸å˜çš„é¢œè‰²
            scatter = ax1.scatter(states_3d[:, 0], states_3d[:, 1], states_3d[:, 2],
                                c=range(len(states_3d)), cmap='viridis', s=60, alpha=0.8)
            
            # æ ‡è®°èµ·ç‚¹å’Œç»ˆç‚¹
            ax1.scatter(states_3d[0, 0], states_3d[0, 1], states_3d[0, 2],
                       color='green', s=150, marker='o', 
                       edgecolor='black', linewidth=2, label='Start')
            ax1.scatter(states_3d[-1, 0], states_3d[-1, 1], states_3d[-1, 2],
                       color='red', s=150, marker='*', 
                       edgecolor='black', linewidth=2, label='End')
            
            ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')
            ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')
            ax1.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]:.2%})')
            ax1.set_title('Complete LSTM Trajectory (3D PCA)')
            ax1.legend()
            ax1.view_init(elev=20, azim=45)
            
            total_var = pca.explained_variance_ratio_.sum()
            ax1.text2D(0.02, 0.98, f'Total Var: {total_var:.1%}', 
                      transform=ax1.transAxes, fontsize=9,
                      bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.8))
            
            # 2D PCAæŠ•å½±å›¾ - XYå¹³é¢
            ax2 = fig.add_subplot(222)
            ax2.plot(states_3d[:, 0], states_3d[:, 1], 'b-', alpha=0.6, linewidth=2)
            scatter2 = ax2.scatter(states_3d[:, 0], states_3d[:, 1], 
                                 c=range(len(states_3d)), cmap='viridis', s=60, alpha=0.8)
            ax2.scatter(states_3d[0, 0], states_3d[0, 1], color='green', s=100, marker='o')
            ax2.scatter(states_3d[-1, 0], states_3d[-1, 1], color='red', s=100, marker='*')
            ax2.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')
            ax2.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')
            ax2.set_title('LSTM Trajectory (PC1 vs PC2)')
            ax2.grid(True, alpha=0.3)
            
            # 2D PCAæŠ•å½±å›¾ - XZå¹³é¢
            ax3 = fig.add_subplot(223)
            ax3.plot(states_3d[:, 0], states_3d[:, 2], 'b-', alpha=0.6, linewidth=2)
            scatter3 = ax3.scatter(states_3d[:, 0], states_3d[:, 2], 
                                 c=range(len(states_3d)), cmap='viridis', s=60, alpha=0.8)
            ax3.scatter(states_3d[0, 0], states_3d[0, 2], color='green', s=100, marker='o')
            ax3.scatter(states_3d[-1, 0], states_3d[-1, 2], color='red', s=100, marker='*')
            ax3.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')
            ax3.set_ylabel(f'PC3 ({pca.explained_variance_ratio_[2]:.2%})')
            ax3.set_title('LSTM Trajectory (PC1 vs PC3)')
            ax3.grid(True, alpha=0.3)
            
            # 2D PCAæŠ•å½±å›¾ - YZå¹³é¢
            ax4 = fig.add_subplot(224)
            ax4.plot(states_3d[:, 1], states_3d[:, 2], 'b-', alpha=0.6, linewidth=2)
            scatter4 = ax4.scatter(states_3d[:, 1], states_3d[:, 2], 
                                 c=range(len(states_3d)), cmap='viridis', s=60, alpha=0.8)
            ax4.scatter(states_3d[0, 1], states_3d[0, 2], color='green', s=100, marker='o')
            ax4.scatter(states_3d[-1, 1], states_3d[-1, 2], color='red', s=100, marker='*')
            ax4.set_xlabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')
            ax4.set_ylabel(f'PC3 ({pca.explained_variance_ratio_[2]:.2%})')
            ax4.set_title('LSTM Trajectory (PC2 vs PC3)')
            ax4.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ä¿å­˜3Dæ€»ç»“å›¾
            lstm_summary_path = os.path.join(sample_dir, 'lstm_3d_summary.png')
            plt.savefig(lstm_summary_path, dpi=200, bbox_inches='tight')
            plt.close()
            
            print(f"  âœ… ç”Ÿæˆ3D LSTMè½¨è¿¹æ€»ç»“å›¾")
            
        except Exception as e:
            print(f"  âš ï¸ 3D LSTMæ€»ç»“å›¾ç”Ÿæˆå¤±è´¥: {e}")
    
    def _save_numerical_data(self, viz_data, true_label, sample_id, sample_dir):
        """ä¿å­˜æ•°å€¼æ•°æ®"""
        
        data = {
            'sample_id': sample_id,
            'true_label': int(true_label),
            'predictions': viz_data['predictions'].cpu().tolist(),
            'softmax_probs': viz_data['softmax_probs'].cpu().tolist(),
            'final_prediction': int(viz_data['predictions'][-1].item()),
            'sequence_length': len(viz_data['predictions']),
            'accuracy': float((viz_data['predictions'].cpu().numpy() == true_label).mean()),
            'model_info': self.model_info
        }
        
        # LSTMçŠ¶æ€ç»Ÿè®¡
        if viz_data['lstm_states']:
            lstm_array = torch.stack(viz_data['lstm_states']).cpu().numpy()
            if len(lstm_array.shape) > 2:
                lstm_array = lstm_array.squeeze(1)
            
            data['lstm_stats'] = {
                'mean': float(lstm_array.mean()),
                'std': float(lstm_array.std()),
                'shape': list(lstm_array.shape)
            }
        
        # Attentionç»Ÿè®¡
        if viz_data['attention_weights']:
            att_array = torch.cat(viz_data['attention_weights']).cpu().numpy()
            data['attention_stats'] = {
                'mean': float(att_array.mean()),
                'std': float(att_array.std()),
                'max': float(att_array.max()),
                'min': float(att_array.min())
            }
        
        json_path = os.path.join(sample_dir, 'data.json')
        with open(json_path, 'w') as f:
            json.dump(data, f, indent=2)


def load_model_and_data(checkpoint_path, val_csv, data_root, device='cuda'):
    """é€šç”¨æ¨¡å‹å’Œæ•°æ®åŠ è½½å‡½æ•°"""
    print("ğŸ“¥ åŠ è½½æ¨¡å‹å’Œæ•°æ®...")
    
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    config = checkpoint['config']
    
    # å¯¼å…¥æ¨¡å—
    from DataLoader_embodiment import BallCountingDataset
    
    # ç¡®å®šå›¾åƒæ¨¡å¼
    image_mode = config.get('image_mode', 'rgb')
    input_channels = 3 if image_mode == 'rgb' else 1
    
    # æ£€æŸ¥æ¨¡å‹ç±»å‹
    model_type = checkpoint.get('model_type', 'embodied')
    
    if model_type in ['counting_only', 'visual_only']:
        # Ablationæ¨¡å‹
        from Model_embodiment_ablation import create_ablation_model
        model = create_ablation_model(model_type, config)
        print(f"âœ… åŠ è½½æ¶ˆèå®éªŒæ¨¡å‹: {model_type}")
    else:
        # åŸå§‹Embodimentæ¨¡å‹
        from Model_embodiment import EmbodiedCountingModel
        model_config = config['model_config'].copy()
        model_config['input_channels'] = input_channels
        model = EmbodiedCountingModel(**model_config)
        print("âœ… åŠ è½½åŸå§‹å…·èº«è®¡æ•°æ¨¡å‹")
    
    model.load_state_dict(checkpoint['model_state_dict'])
    
    device = torch.device(device if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()
    
    print(f"   å›¾åƒæ¨¡å¼: {image_mode}, è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = BallCountingDataset(
        csv_path=val_csv,
        data_root=data_root,
        sequence_length=config['sequence_length'],
        normalize=config['normalize'],
        image_mode=image_mode,
        normalize_images=True
    )
    
    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œæ ·æœ¬æ•°: {len(dataset)}")
    
    return model, dataset, device, config


def main():
    parser = argparse.ArgumentParser(description='é€šç”¨åŠ¨æ€æ¨¡å‹å¯è§†åŒ–å·¥å…· - å¢å¼ºç‰ˆwith JointPCA')
    
    parser.add_argument('--checkpoint', type=str, required=True,
                       help='æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--val_csv', type=str, 
                       default='scratch/Ball_counting_CNN/Tools_script/ball_dynamic_val.csv',
                       help='éªŒè¯é›†CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--data_root', type=str, 
                       default='/mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/Ball_counting_CNN/ball_data_collection',
                       help='æ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--save_dir', type=str, default='./universal_visualizations_jointpca',
                       help='ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--device', type=str, default='cuda',
                       help='è®¾å¤‡ (cuda/cpu)')
    parser.add_argument('--sample_indices', type=int, nargs='+', default=None,
                       help='è¦å¯è§†åŒ–çš„æ ·æœ¬ç´¢å¼•ï¼ˆé»˜è®¤å…¨éƒ¨ï¼‰')
    parser.add_argument('--max_samples', type=int, default=60,
                       help='æœ€å¤§å¯è§†åŒ–æ ·æœ¬æ•°')
    parser.add_argument('--enable_joint_pca', action='store_true', default=True,
                       help='æ˜¯å¦æ‰§è¡ŒjointPCAåˆ†æ')
    
    args = parser.parse_args()
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_dir = os.path.join(args.save_dir, f'viz_{timestamp}')
    os.makedirs(save_dir, exist_ok=True)
    
    print("ğŸ¬ é€šç”¨åŠ¨æ€æ¨¡å‹å¯è§†åŒ–å·¥å…· - å¢å¼ºç‰ˆ")
    print("="*50)
    print(f"æ£€æŸ¥ç‚¹: {args.checkpoint}")
    print(f"æ•°æ®é›†: {args.val_csv}")
    print(f"ä¿å­˜ç›®å½•: {save_dir}")
    print(f"JointPCAåˆ†æ: {'å¯ç”¨' if args.enable_joint_pca else 'ç¦ç”¨'}")
    print("="*50)
    
    try:
        # åŠ è½½æ¨¡å‹å’Œæ•°æ®
        model, dataset, device, config = load_model_and_data(
            args.checkpoint, args.val_csv, args.data_root, args.device
        )
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = UniversalModelVisualizer(model, device)
        
        # ç¡®å®šè¦å¯è§†åŒ–çš„æ ·æœ¬
        if args.sample_indices is not None:
            sample_indices = args.sample_indices
        else:
            sample_indices = list(range(min(len(dataset), args.max_samples)))
        
        print(f"\nå‡†å¤‡å¯è§†åŒ– {len(sample_indices)} ä¸ªæ ·æœ¬: {sample_indices}")
        print("æ¯ä¸ªæ ·æœ¬å°†ç”Ÿæˆ:")
        print("  â€¢ é€å¸§2Då¯è§†åŒ– (ä¸»å›¾)")
        print("  â€¢ é€å¸§3D LSTMè½¨è¿¹ (ç‹¬ç«‹å›¾)")
        print("  â€¢ å®Œæ•´3Dè½¨è¿¹æ€»ç»“")
        print("  â€¢ æ±‡æ€»åˆ†æå›¾")
        if args.enable_joint_pca:
            print("  â€¢ JointPCAè·¨æ ·æœ¬åˆ†æ (æ–°å¢)")
        
        # å¯è§†åŒ–æ¯ä¸ªæ ·æœ¬
        for idx in sample_indices:
            if idx >= len(dataset):
                print(f"âš ï¸ æ ·æœ¬ç´¢å¼• {idx} è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡")
                continue
            
            try:
                sample_data = dataset[idx]
                visualizer.visualize_sample_sequence(
                    sample_data, idx, save_dir, 
                    collect_for_joint_pca=args.enable_joint_pca
                )
            except Exception as e:
                print(f"âŒ æ ·æœ¬ {idx} å¯è§†åŒ–å¤±è´¥: {e}")
                continue
        
        # æ‰§è¡ŒjointPCAåˆ†æ
        if args.enable_joint_pca:
            print("\n" + "="*50)
            print("å¼€å§‹JointPCAåˆ†æ...")
            print("="*50)
            
            analyzer = visualizer.perform_joint_pca_analysis(save_dir)
            
            if analyzer:
                print("\nğŸ¯ JointPCAåˆ†æäº®ç‚¹:")
                print(f"  â€¢ åˆ†æäº† {len(visualizer.collected_lstm_trajectories)} ä¸ªè½¨è¿¹")
                print(f"  â€¢ æ£€æµ‹åˆ°ç¯å½¢è½¨è¿¹æ¯”ä¾‹: {analyzer.analysis_results['rotation_patterns'][0]['metrics']['circularity_score']:.2%}")
                print(f"  â€¢ è¯¦ç»†æŠ¥å‘Šä¿å­˜åœ¨: {os.path.join(save_dir, 'joint_pca_analysis')}")
        
        print(f"\nğŸ‰ å¯è§†åŒ–å®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {save_dir}")
        print(f"ğŸ“Š ç”Ÿæˆçš„å¯è§†åŒ–å†…å®¹:")
        print(f"   â€¢ frame_XXX.png - é€å¸§2Dä¸»å¯è§†åŒ–")
        print(f"   â€¢ lstm_3d_frame_XXX.png - é€å¸§3D LSTMè½¨è¿¹")
        print(f"   â€¢ lstm_3d_summary.png - å®Œæ•´3Dè½¨è¿¹æ€»ç»“")
        print(f"   â€¢ summary.png - æ±‡æ€»åˆ†æå›¾")
        print(f"   â€¢ data.json - æ•°å€¼æ•°æ®")
        if args.enable_joint_pca:
            print(f"   â€¢ joint_pca_analysis/ - JointPCAåˆ†æç»“æœ")
            print(f"     - joint_pca_trajectories.png - è·¨æ ·æœ¬è½¨è¿¹")
            print(f"     - circular_patterns.png - ç¯å½¢æ¨¡å¼")
            print(f"     - rotation_metrics_summary.png - æ—‹è½¬æŒ‡æ ‡æ±‡æ€»")
            print(f"     - joint_pca_report.json/txt - è¯¦ç»†æŠ¥å‘Š")
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) == 1:
        print("ğŸ¬ é€šç”¨åŠ¨æ€æ¨¡å‹å¯è§†åŒ–å·¥å…· - å¢å¼ºç‰ˆ with JointPCA")
        print("="*50)
        print("æ–°åŠŸèƒ½ï¼š")
        print("  âœ¨ JointPCAåˆ†æ - è·¨æ ·æœ¬LSTMè½¨è¿¹åˆ†æ")
        print("  âœ¨ ç¯å½¢Attractoræ£€æµ‹ - å¯»æ‰¾Churchlandå¼æ—‹è½¬ç»“æ„")
        print("  âœ¨ æ—‹è½¬æŒ‡æ ‡é‡åŒ– - ç¯å½¢åº¦ã€æ—‹è½¬ä¸€è‡´æ€§ç­‰")
        print()
        print("æ”¯æŒæ‰€æœ‰æ¨¡å‹ç±»å‹:")
        print("  â€¢ åŸå§‹Embodimentæ¨¡å‹")
        print("  â€¢ Counting-Onlyæ¨¡å‹")
        print("  â€¢ Visual-Onlyæ¨¡å‹")
        print()
        print("ä½¿ç”¨æ–¹æ³•:")
        print("python Universal_LSTM_Viz_with_JointPCA.py --checkpoint MODEL.pth --val_csv VAL.csv")
        print()
        print("ç¤ºä¾‹:")
        print("# å®Œæ•´åˆ†æï¼ˆåŒ…å«JointPCAï¼‰")
        print("python Universal_LSTM_Viz_with_JointPCA.py \\")
        print("    --checkpoint ./best_model.pth \\")
        print("    --val_csv ./val_subset.csv \\")
        print("    --max_samples 50 \\")
        print("    --enable_joint_pca")
        print()
        print("# åªåšå•æ ·æœ¬åˆ†æï¼ˆä¸å«JointPCAï¼‰")
        print("python Universal_LSTM_Viz_with_JointPCA.py \\")
        print("    --checkpoint ./best_model.pth \\")
        print("    --val_csv ./val_subset.csv \\")
        print("    --sample_indices 0 1 2")
        print()
        print("å¯é€‰å‚æ•°:")
        print("  --save_dir DIR           ä¿å­˜ç›®å½•")
        print("  --device DEVICE          è®¾å¤‡ (cuda/cpu)")
        print("  --sample_indices LIST    æŒ‡å®šæ ·æœ¬ç´¢å¼•")
        print("  --max_samples N          æœ€å¤§æ ·æœ¬æ•°")
        print("  --enable_joint_pca       å¯ç”¨è·¨æ ·æœ¬JointPCAåˆ†æ")
        print()
        print("ğŸ’¡ å»ºè®®:")
        print("  â€¢ ä¸ºJointPCAåˆ†æå‡†å¤‡20-50ä¸ªæ ·æœ¬ï¼Œè¦†ç›–æ‰€æœ‰æ ‡ç­¾")
        print("  â€¢ ä½¿ç”¨å¹³è¡¡çš„æ•°æ®é›†ä»¥è·å¾—æ›´å¥½çš„åˆ†æç»“æœ")
        print("  â€¢ æŸ¥çœ‹rotation_metrics_summary.pngäº†è§£ä¸åŒæ•°å­—çš„æ—‹è½¬ç‰¹æ€§")
        sys.exit(0)
    
    main()