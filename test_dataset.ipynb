{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Ball Counter Dataset\n",
    "\n",
    "This notebook tests the dataset loading and preprocessing functionality for the ball counting project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dataset Module\n",
    "\n",
    "First, let's import our dataset module. Make sure this notebook is in the same directory as `dataset.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import dataset module\n",
    "import dataset\n",
    "from dataset import BallDataset, load_dataset, get_data_loaders\n",
    "\n",
    "print(\"Dataset module imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Specify Data Directory\n",
    "\n",
    "Enter the path to your data directory. This should be the directory that contains subdirectories named 1, 2, 3, 4, 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set your data directory here\n",
    "data_dir = \"data\"  # Update this to your data directory path\n",
    "\n",
    "# Check if directory exists\n",
    "if not os.path.exists(data_dir):\n",
    "    print(f\"Error: Directory '{data_dir}' not found!\")\n",
    "else:\n",
    "    print(f\"Found data directory: {data_dir}\")\n",
    "\n",
    "# Check class directories\n",
    "class_dirs = []\n",
    "for i in range(1, 6):\n",
    "    class_path = os.path.join(data_dir, str(i))\n",
    "    if os.path.exists(class_path):\n",
    "        num_images = len([f for f in os.listdir(class_path) \n",
    "                          if os.path.isfile(os.path.join(class_path, f)) and \n",
    "                          f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        class_dirs.append((str(i), num_images))\n",
    "\n",
    "if class_dirs:\n",
    "    print(\"\\nFound class directories:\")\n",
    "    for class_name, num_images in class_dirs:\n",
    "        print(f\"  Class {class_name}: {num_images} images\")\n",
    "else:\n",
    "    print(\"\\nNo class directories (1-5) found in data directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Sample Images\n",
    "\n",
    "Let's load a small set of images from each class to test our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load a small dataset (5 images per class)\n",
    "try:\n",
    "    image_paths, labels = load_dataset(data_dir, num_samples_per_class=5)\n",
    "    print(f\"Successfully loaded {len(image_paths)} images\")\n",
    "    \n",
    "    # Count images per class\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    for label, count in zip(unique_labels, counts):\n",
    "        print(f\"  Class {label+1}: {count} images\")\n",
    "    \n",
    "    # Check image paths to make sure they exist\n",
    "    all_exist = all(os.path.exists(path) for path in image_paths)\n",
    "    print(f\"All image paths exist: {all_exist}\")\n",
    "    \n",
    "    # Print first few paths\n",
    "    print(\"\\nFirst few image paths:\")\n",
    "    for i, path in enumerate(image_paths[:3]):\n",
    "        print(f\"  {i+1}. {path} (Class {labels[i]+1})\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Original Images\n",
    "\n",
    "Let's look at some of the original images to make sure they're loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display some original images\n",
    "if 'image_paths' in locals() and len(image_paths) > 0:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Select one image from each class if available\n",
    "    selected_indices = []\n",
    "    for label in range(5):  # 0-4 (representing 1-5 balls)\n",
    "        indices = [i for i, l in enumerate(labels) if l == label]\n",
    "        if indices:\n",
    "            selected_indices.append(indices[0])\n",
    "    \n",
    "    # If we don't have all classes, just take the first few images\n",
    "    if len(selected_indices) < 5:\n",
    "        selected_indices = list(range(min(5, len(image_paths))))\n",
    "    \n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        try:\n",
    "            img_path = image_paths[idx]\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            plt.subplot(1, len(selected_indices), i+1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Class {labels[idx]+1} (Balls)\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images available to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Dataset Class\n",
    "\n",
    "Now let's create a dataset and test the preprocessing functionality (resizing and binarization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create dataset with binary preprocessing\n",
    "if 'image_paths' in locals() and len(image_paths) > 0:\n",
    "    # Create dataset\n",
    "    dataset = BallDataset(image_paths, labels, binary=True)\n",
    "    print(f\"Created dataset with {len(dataset)} samples\")\n",
    "    \n",
    "    # Get and display some processed images\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        # Get processed image from dataset\n",
    "        img_tensor, label = dataset[idx]\n",
    "        \n",
    "        # Convert tensor to numpy for display\n",
    "        img_np = img_tensor.squeeze().numpy()\n",
    "        \n",
    "        # Display\n",
    "        plt.subplot(1, len(selected_indices), i+1)\n",
    "        plt.imshow(img_np, cmap='gray')\n",
    "        plt.title(f\"Class {label+1} (Binary)\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Image tensor shape:\", img_tensor.shape)\n",
    "    print(\"Processed image statistics:\")\n",
    "    print(f\"  Min: {img_np.min():.4f}, Max: {img_np.max():.4f}, Mean: {img_np.mean():.4f}\")\n",
    "else:\n",
    "    print(\"No images available to create dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Original vs. Processed Images\n",
    "\n",
    "Now let's compare original and processed (binary) versions side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare original and binary versions\n",
    "if 'dataset' in locals() and len(dataset) > 0:\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    for i, idx in enumerate(selected_indices[:3]):  # Show just 3 examples\n",
    "        # Original image\n",
    "        img_path = image_paths[idx]\n",
    "        orig_img = cv2.imread(img_path)\n",
    "        orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Processed image\n",
    "        proc_img, _ = dataset[idx]\n",
    "        proc_img = proc_img.squeeze().numpy()\n",
    "        \n",
    "        # Display original\n",
    "        plt.subplot(3, 2, i*2+1)\n",
    "        plt.imshow(orig_img)\n",
    "        plt.title(f\"Original - Class {labels[idx]+1}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Display binary\n",
    "        plt.subplot(3, 2, i*2+2)\n",
    "        plt.imshow(proc_img, cmap='gray')\n",
    "        plt.title(f\"Binary - Class {labels[idx]+1}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No dataset available for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test DataLoader Functionality\n",
    "\n",
    "Finally, let's test creating data loaders and getting batches of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create data loaders\n",
    "try:\n",
    "    train_loader, val_loader, test_loader = get_data_loaders(\n",
    "        data_dir, num_samples_per_class=5, batch_size=4\n",
    "    )\n",
    "    \n",
    "    print(f\"Created data loaders:\")\n",
    "    print(f\"  Train: {len(train_loader)} batches\")\n",
    "    print(f\"  Validation: {len(val_loader)} batches\")\n",
    "    print(f\"  Test: {len(test_loader)} batches\")\n",
    "    \n",
    "    # Get a batch from training loader\n",
    "    try:\n",
    "        batch_x, batch_y = next(iter(train_loader))\n",
    "        print(f\"\\nBatch shape: {batch_x.shape}, Labels: {batch_y}\")\n",
    "        \n",
    "        # Display the batch\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        for i in range(min(4, batch_x.shape[0])):\n",
    "            plt.subplot(2, 2, i+1)\n",
    "            plt.imshow(batch_x[i, 0].numpy(), cmap='gray')\n",
    "            plt.title(f\"Class {batch_y[i].item()+1} (Balls)\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except StopIteration:\n",
    "        print(\"Training loader is empty!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting batch from loader: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error creating data loaders: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Data Augmentation\n",
    "\n",
    "Let's check if data augmentation is working in the training dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test data augmentation\n",
    "if 'train_loader' in locals():\n",
    "    # Reset dataloader iterator\n",
    "    train_iter = iter(train_loader)\n",
    "    \n",
    "    # Get the same batch multiple times to show augmentation\n",
    "    try:\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # Get first batch\n",
    "        batch1_x, batch1_y = next(train_iter)\n",
    "        \n",
    "        # Reset and get \"same\" batch again (should have different augmentation)\n",
    "        train_iter = iter(train_loader)\n",
    "        batch2_x, batch2_y = next(train_iter)\n",
    "        \n",
    "        # Show a comparison\n",
    "        for i in range(min(2, batch1_x.shape[0])):\n",
    "            # First batch version\n",
    "            plt.subplot(2, 2, i*2+1)\n",
    "            plt.imshow(batch1_x[i, 0].numpy(), cmap='gray')\n",
    "            plt.title(f\"First Pass - Class {batch1_y[i].item()+1}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Second batch version (should be different due to augmentation)\n",
    "            plt.subplot(2, 2, i*2+2)\n",
    "            plt.imshow(batch2_x[i, 0].numpy(), cmap='gray')\n",
    "            plt.title(f\"Second Pass - Class {batch2_y[i].item()+1}\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"If images look different between passes, data augmentation is working!\")\n",
    "        \n",
    "    except StopIteration:\n",
    "        print(\"Training loader is empty!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing augmentation: {e}\")\n",
    "else:\n",
    "    print(\"No training loader available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Test Summary\n",
    "\n",
    "If all the cells above run without errors, your dataset functionality is working correctly! The dataset is successfully:\n",
    "\n",
    "1. Loading images from your data directories\n",
    "2. Preprocessing them (resizing to 320Ã—240 and binarizing)\n",
    "3. Creating proper data loaders with train/val/test splits\n",
    "4. Applying data augmentation during training\n",
    "\n",
    "You're now ready to move on to testing the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}