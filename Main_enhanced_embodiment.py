"""
ä¸»æ–‡ä»¶ - å¢å¼ºå…·èº«è®¡æ•°æ¨¡å‹è®­ç»ƒç¨‹åº (Enhanced Internal Model)
"""

import argparse
import os
import torch
import numpy as np
import random
import json
from Train_enhanced_embodiment import create_enhanced_trainer


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='Enhanced Embodied Counting Model Training')
    
    # åŸºç¡€é…ç½®
    parser.add_argument('--resume', type=str, default=None,
                        help='Path to checkpoint to resume from')
    parser.add_argument('--device', type=str, default='cuda',
                        help='Device to use (cuda/cpu)')
    
    # æ•°æ®è·¯å¾„
    parser.add_argument('--data_root', type=str, 
                        default='/mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/Ball_counting_CNN/ball_data_collection',
                        help='Data root directory')
    parser.add_argument('--train_csv', type=str,
                        default='scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_train.csv',
                        help='Train CSV file path')
    parser.add_argument('--val_csv', type=str,
                        default='scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_val.csv',
                        help='Validation CSV file path')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch_size', type=int, default=16,
                        help='Batch size')
    parser.add_argument('--learning_rate', type=float, default=1e-4,
                        help='Learning rate')
    parser.add_argument('--weight_decay', type=float, default=1e-5,
                        help='Weight decay for Adam optimizer')
    parser.add_argument('--grad_clip_norm', type=float, default=1.0,
                        help='Gradient clipping norm')
    parser.add_argument('--total_epochs', type=int, default=1000,
                        help='Total training epochs')
    
    # Enhancedæ¨¡å‹ç‰¹å®šçš„è®­ç»ƒé˜¶æ®µå‚æ•°
    parser.add_argument('--stage_1_epochs', type=int, default=0,
                        help='Epochs for stage 1 (Internal Model pretraining)')
    parser.add_argument('--stage_2_epochs', type=int, default=0,
                        help='Epochs for stage 2 (joint training)')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--cnn_layers', type=int, default=3,
                        help='Number of CNN layers')
    parser.add_argument('--cnn_channels', type=str, default='64,128,256',
                        help='CNN channels per layer, comma-separated')
    parser.add_argument('--lstm_layers', type=int, default=1,
                        help='Number of LSTM layers')
    parser.add_argument('--lstm_hidden_size', type=int, default=512,
                        help='LSTM hidden size')
    parser.add_argument('--feature_dim', type=int, default=256,
                        help='Feature dimension')
    parser.add_argument('--joint_dim', type=int, default=7,
                        help='Joint dimension (7 for your robot joints)')
    parser.add_argument('--dropout', type=float, default=0.1,
                        help='Dropout rate')
    
    # Enhancedæ¨¡å‹ç‰¹å®šå‚æ•°
    parser.add_argument('--use_fovea_bias', action='store_true', default=True,
                        help='Use fovea bias in attention (human eye-like)')
    parser.add_argument('--no_fovea_bias', action='store_true', default=False,
                        help='Disable fovea bias')
    parser.add_argument('--embodiment_loss_weight', type=float, default=0.3,
                        help='Weight for embodiment loss in joint training')
    parser.add_argument('--attention_loss_weight', type=float, default=0.1,
                        help='Weight for attention regularization loss')
    
    # å›¾åƒå¤„ç†å‚æ•°
    parser.add_argument('--image_mode', type=str, default='rgb',
                        choices=['rgb', 'grayscale'],
                        help='Image processing mode (rgb or grayscale)')
    
    # å­¦ä¹ ç‡è°ƒåº¦å‚æ•°
    parser.add_argument('--scheduler_type', type=str, default='none',
                        choices=['cosine', 'plateau', 'none'],
                        help='LR scheduler type')
    parser.add_argument('--scheduler_patience', type=int, default=5,
                        help='Patience for plateau scheduler')
    
    # æ•°æ®å¤„ç†å‚æ•°
    parser.add_argument('--sequence_length', type=int, default=11,
                        help='Sequence length')
    parser.add_argument('--normalize', action='store_true', default=True,
                        help='Normalize input data')
    
    # ä¿å­˜å’Œæ—¥å¿—å‚æ•°
    parser.add_argument('--save_dir', type=str, default='./scratch/Ball_counting_CNN/Result_data/Enhanced/checkpoints',
                        help='Directory to save checkpoints')
    parser.add_argument('--log_dir', type=str, default='./scratch/Ball_counting_CNN/Result_data/Enhanced/logs',
                        help='Directory to save logs')
    parser.add_argument('--save_every', type=int, default=5,
                        help='Save checkpoint every N epochs')
    parser.add_argument('--print_freq', type=int, default=10,
                        help='Print frequency (in batches)')
    
    # å…¶ä»–
    parser.add_argument('--seed', type=int, default=42,
                        help='Random seed')
    parser.add_argument('--num_workers', type=int, default=4,
                        help='Number of data loading workers')
    
    return parser.parse_args()


def set_random_seed(seed):
    """è®¾ç½®éšæœºç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def print_config(config):
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    print("="*70)
    print("å¢å¼ºå…·èº«è®¡æ•°æ¨¡å‹è®­ç»ƒé…ç½® (Enhanced Internal Model)")
    print("="*70)
    
    # æ¨¡å‹åˆ›æ–°ç‚¹
    print("ğŸ§  æ¨¡å‹åˆ›æ–°ç‚¹:")
    print("  âœ… Internal Model Architecture (Forward + Inverse)")
    print("  âœ… Multi-Scale Visual Features")
    print("  âœ… Early Fusion + Residual Connections")
    print("  âœ… Task-Guided Spatial Attention")
    print(f"  âœ… Fovea Bias (Human Eye-like): {config.get('use_fovea_bias', True)}")
    
    # åŸºç¡€é…ç½®
    print("\nğŸ“‹ åŸºç¡€é…ç½®:")
    basic_keys = ['device', 'batch_size', 'learning_rate', 'total_epochs', 'image_mode']
    for key in basic_keys:
        if key in config:
            print(f"  {key}: {config[key]}")
    
    # æ•°æ®é…ç½®
    print("\nğŸ“ æ•°æ®é…ç½®:")
    data_keys = ['data_root', 'train_csv', 'val_csv', 'sequence_length', 'normalize']
    for key in data_keys:
        if key in config:
            print(f"  {key}: {config[key]}")
    
    # è®­ç»ƒé˜¶æ®µé…ç½®
    print("\nğŸ—ï¸ è®­ç»ƒé˜¶æ®µ:")
    stage_keys = ['stage_1_epochs', 'stage_2_epochs']
    for key in stage_keys:
        if key in config:
            print(f"  {key}: {config[key]}")
    
    print(f"  Stage 1 (0-{config['stage_1_epochs']}): Internal Modelé¢„è®­ç»ƒ")
    print(f"  Stage 2 ({config['stage_1_epochs']}-{config['stage_2_epochs']}): è”åˆè®­ç»ƒ")
    print(f"  Stage 3 ({config['stage_2_epochs']}-{config['total_epochs']}): è®¡æ•°ç²¾è°ƒ")
    
    # Enhancedæ¨¡å‹ç‰¹å®šé…ç½®
    print("\nğŸ”¬ Enhancedæ¨¡å‹é…ç½®:")
    enhanced_keys = ['embodiment_loss_weight', 'attention_loss_weight', 'use_fovea_bias']
    for key in enhanced_keys:
        if key in config:
            print(f"  {key}: {config[key]}")
    
    # æ¨¡å‹å‚æ•°
    print("\nğŸ›ï¸ æ¨¡å‹æ¶æ„:")
    for key, value in config['model_config'].items():
        print(f"  {key}: {value}")
    
    # ä¿å­˜é…ç½®
    print("\nğŸ’¾ ä¿å­˜é…ç½®:")
    save_keys = ['save_dir', 'log_dir', 'save_every']
    for key in save_keys:
        if key in config:
            print(f"  {key}: {config[key]}")
    
    print("="*70)


def validate_paths(config):
    """éªŒè¯æ–‡ä»¶è·¯å¾„æ˜¯å¦å­˜åœ¨"""
    errors = []
    
    # æ£€æŸ¥æ•°æ®æ ¹ç›®å½•
    if not os.path.exists(config['data_root']):
        errors.append(f"æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {config['data_root']}")
    
    # æ£€æŸ¥CSVæ–‡ä»¶
    if not os.path.exists(config['train_csv']):
        errors.append(f"è®­ç»ƒCSVæ–‡ä»¶ä¸å­˜åœ¨: {config['train_csv']}")
    
    if not os.path.exists(config['val_csv']):
        errors.append(f"éªŒè¯CSVæ–‡ä»¶ä¸å­˜åœ¨: {config['val_csv']}")
    
    if errors:
        print("âŒ è·¯å¾„éªŒè¯å¤±è´¥:")
        for error in errors:
            print(f"  - {error}")
        return False
    
    print("âœ… æ‰€æœ‰è·¯å¾„éªŒè¯é€šè¿‡")
    return True


def save_config(config, save_path):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    # åˆ›å»ºå¯åºåˆ—åŒ–çš„é…ç½®å‰¯æœ¬
    serializable_config = {
        'model_type': 'Enhanced_Embodied_Counting_Model',
        'experiment_type': 'internal_model_with_early_fusion',
        'features': [
            'Internal_Model_Architecture',
            'Multi_Scale_Visual_Features',
            'Early_Fusion_Residual',
            'Task_Guided_Attention',
            'Fovea_Bias'
        ]
    }
    
    for key, value in config.items():
        if isinstance(value, dict):
            serializable_config[key] = dict(value)
        else:
            serializable_config[key] = value
    
    with open(save_path, 'w') as f:
        json.dump(serializable_config, f, indent=2)
    print(f"ğŸ’¾ é…ç½®ä¿å­˜åˆ°: {save_path}")


def build_config_from_args(args):
    """ä»å‘½ä»¤è¡Œå‚æ•°æ„å»ºé…ç½®"""
    # å¤„ç†fovea biasè®¾ç½®
    use_fovea_bias = args.use_fovea_bias and not args.no_fovea_bias
    
    # å°†CNNé€šé“ä»å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨
    cnn_channels = [int(c) for c in args.cnn_channels.split(',')]
    
    # æ„å»ºæ¨¡å‹é…ç½®
    model_config = {
        'cnn_layers': args.cnn_layers,
        'cnn_channels': cnn_channels,
        'lstm_layers': args.lstm_layers,
        'lstm_hidden_size': args.lstm_hidden_size,
        'feature_dim': args.feature_dim,
        'joint_dim': args.joint_dim,
        'dropout': args.dropout,
        'use_fovea_bias': use_fovea_bias,
        # input_channelså°†åœ¨trainerä¸­æ ¹æ®image_modeè®¾ç½®
    }
    
    # æ„å»ºå®Œæ•´é…ç½®
    config = {
        # æ•°æ®é…ç½®
        'data_root': args.data_root,
        'train_csv': args.train_csv,
        'val_csv': args.val_csv,
        'sequence_length': args.sequence_length,
        'normalize': args.normalize,
        'image_mode': args.image_mode,
        
        # æ¨¡å‹é…ç½®
        'model_config': model_config,
        'use_fovea_bias': use_fovea_bias,
        
        # è®­ç»ƒé…ç½®
        'batch_size': args.batch_size,
        'learning_rate': args.learning_rate,
        'weight_decay': args.weight_decay,
        'adam_betas': (0.9, 0.999),
        'grad_clip_norm': args.grad_clip_norm,
        'total_epochs': args.total_epochs,
        'stage_1_epochs': args.stage_1_epochs,
        'stage_2_epochs': args.stage_2_epochs,
        
        # Enhancedæ¨¡å‹ç‰¹å®šå‚æ•°
        'embodiment_loss_weight': args.embodiment_loss_weight,
        'attention_loss_weight': args.attention_loss_weight,
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        'scheduler_type': args.scheduler_type,
        'scheduler_patience': args.scheduler_patience,
        
        # ä¿å­˜å’Œæ—¥å¿—
        'save_dir': args.save_dir,
        'log_dir': args.log_dir,
        'save_every': args.save_every,
        'print_freq': args.print_freq,
        
        # è®¾å¤‡å’Œæ•°æ®åŠ è½½
        'device': args.device,
        'num_workers': args.num_workers,
        
        # éšæœºç§å­
        'seed': args.seed
    }
    
    return config


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°å¹¶æ„å»ºé…ç½®
    args = parse_arguments()
    config = build_config_from_args(args)
    
    # è®¾ç½®éšæœºç§å­
    set_random_seed(config['seed'])
    
    # æ‰“å°é…ç½®
    print_config(config)
    
    # éªŒè¯è·¯å¾„
    if not validate_paths(config):
        print("âŒ è·¯å¾„éªŒè¯å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(config['save_dir'], exist_ok=True)
    os.makedirs(config['log_dir'], exist_ok=True)
    
    # ä¿å­˜å½“å‰é…ç½®
    config_save_path = os.path.join(config['save_dir'], 'enhanced_embodied_config.json')
    save_config(config, config_save_path)
    
    # åˆ›å»ºEnhancedè®­ç»ƒå™¨
    print(f"\nğŸš€ æ­£åœ¨åˆå§‹åŒ–Enhancedå…·èº«è®¡æ•°æ¨¡å‹è®­ç»ƒå™¨...")
    print(f"ğŸ–¼ï¸ å›¾åƒæ¨¡å¼: {config['image_mode'].upper()}")
    print(f"ğŸ¦¾ å…³èŠ‚ç»´åº¦: {config['model_config']['joint_dim']}")
    print(f"ğŸ‘ï¸ Foveaåç½®: {config['use_fovea_bias']}")
    
    try:
        trainer = create_enhanced_trainer(config)
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–è®­ç»ƒå™¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # å¦‚æœæŒ‡å®šäº†resumeè·¯å¾„ï¼ŒåŠ è½½æ£€æŸ¥ç‚¹
    if args.resume:
        if os.path.exists(args.resume):
            print(f"ğŸ“‚ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {args.resume}")
            trainer.load_checkpoint(args.resume)
        else:
            print(f"âŒ æ‰¾ä¸åˆ°æ¢å¤æ£€æŸ¥ç‚¹: {args.resume}")
            return
    
    # å¼€å§‹è®­ç»ƒ
    print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒEnhancedå…·èº«è®¡æ•°æ¨¡å‹...")
    print(f"ğŸ§  æ ¸å¿ƒåˆ›æ–°:")
    print(f"   â€¢ Internal Model: Forwardé¢„æµ‹ + Inverseè§„åˆ’")
    print(f"   â€¢ Early Fusion: å¤šå±‚æ¬¡è§†è§‰-å…³èŠ‚ç‰¹å¾èåˆ")
    print(f"   â€¢ Residual Connections: ä¸‰è·¯æ®‹å·®è¿æ¥")
    print(f"   â€¢ Task-Guided Attention: ä»»åŠ¡é©±åŠ¨çš„ç©ºé—´æ³¨æ„åŠ›")
    print(f"   â€¢ Fovea Bias: ç±»äººçœ¼é»„æ–‘åŒºæ³¨æ„åŠ›åç½®")
    
    print(f"\nğŸ“… è®­ç»ƒè®¡åˆ’:")
    print(f"   é˜¶æ®µ1 (0-{config['stage_1_epochs']}): Internal Modelç»„ä»¶é¢„è®­ç»ƒ")
    print(f"   é˜¶æ®µ2 ({config['stage_1_epochs']}-{config['stage_2_epochs']}): è”åˆè®­ç»ƒæ‰€æœ‰ç»„ä»¶")
    print(f"   é˜¶æ®µ3 ({config['stage_2_epochs']}-{config['total_epochs']}): ä¸“æ³¨è®¡æ•°ä»»åŠ¡ç²¾è°ƒ")
    
    try:
        trainer.train()
        print("\nğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼")
        
        # æ‰“å°æœ€ç»ˆç»“æœ
        print(f"\nğŸ“Š æœ€ç»ˆç»“æœ:")
        print(f"   ğŸ† æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {trainer.best_val_accuracy:.4f}")
        print(f"   ğŸ“‰ æœ€ä½³éªŒè¯æŸå¤±: {trainer.best_val_loss:.4f}")
        print(f"   ğŸ’¾ æ¨¡å‹ä¿å­˜ä½ç½®: {config['save_dir']}")
        
        print(f"\nğŸ”¬ å®éªŒä»·å€¼:")
        print(f"   â€¢ éªŒè¯äº†Internal Modelåœ¨å…·èº«AIä¸­çš„æœ‰æ•ˆæ€§")
        print(f"   â€¢ è¯æ˜äº†æ—©æœŸèåˆ+æ®‹å·®ç»“æ„çš„ä¼˜è¶Šæ€§")
        print(f"   â€¢ å®ç°äº†ç±»äººçœ¼çš„task-guided attentionæœºåˆ¶")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        # ä¿å­˜å½“å‰çŠ¶æ€
        current_epoch = trainer.start_epoch if hasattr(trainer, 'start_epoch') else 0
        trainer.save_checkpoint(
            epoch=current_epoch,
            val_loss=trainer.best_val_loss,
            val_accuracy=trainer.best_val_accuracy,
            checkpoint_type='interrupted'
        )
        print("ğŸ’¾ å·²ä¿å­˜ä¸­æ–­æ—¶çš„æ¨¡å‹çŠ¶æ€")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥ï¼Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
        # å°è¯•ä¿å­˜å½“å‰çŠ¶æ€
        try:
            current_epoch = trainer.start_epoch if hasattr(trainer, 'start_epoch') else 0
            trainer.save_checkpoint(
                epoch=current_epoch,
                val_loss=trainer.best_val_loss if hasattr(trainer, 'best_val_loss') else float('inf'),
                val_accuracy=trainer.best_val_accuracy if hasattr(trainer, 'best_val_accuracy') else 0.0,
                checkpoint_type='error'
            )
            print("ğŸ’¾ å·²ä¿å­˜é”™è¯¯æ—¶çš„æ¨¡å‹çŠ¶æ€")
        except:
            print("âŒ æ— æ³•ä¿å­˜é”™è¯¯æ—¶çš„æ¨¡å‹çŠ¶æ€")
    
    print("ğŸ ç¨‹åºç»“æŸã€‚")


def print_usage_examples():
    """æ‰“å°ä½¿ç”¨ç¤ºä¾‹"""
    print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
    print("="*70)
    
    print("1ï¸âƒ£ åŸºç¡€è®­ç»ƒ (å¯ç”¨æ‰€æœ‰Enhancedç‰¹æ€§):")
    print("python Main_enhanced_embodiment.py --image_mode rgb --batch_size 16")
    
    print("\n2ï¸âƒ£ ç°åº¦æ¨¡å¼è®­ç»ƒ:")
    print("python Main_enhanced_embodiment.py --image_mode grayscale --batch_size 32")
    
    print("\n3ï¸âƒ£ è‡ªå®šä¹‰è®­ç»ƒé˜¶æ®µ:")
    print("python Main_enhanced_embodiment.py \\")
    print("    --stage_1_epochs 50 \\")
    print("    --stage_2_epochs 180 \\") 
    print("    --total_epochs 250")
    
    print("\n4ï¸âƒ£ è°ƒæ•´æŸå¤±æƒé‡:")
    print("python Main_enhanced_embodiment.py \\")
    print("    --embodiment_loss_weight 0.2 \\")
    print("    --attention_loss_weight 0.15")
    
    print("\n5ï¸âƒ£ ç¦ç”¨Foveaåç½®:")
    print("python Main_enhanced_embodiment.py --no_fovea_bias")
    
    print("\n6ï¸âƒ£ ä»æ£€æŸ¥ç‚¹æ¢å¤:")
    print("python Main_enhanced_embodiment.py \\")
    print("    --resume ./checkpoints/best_enhanced_model.pth")
    
    print("\n7ï¸âƒ£ å¿«é€Ÿæµ‹è¯•(å°‘é‡epoch):")
    print("python Main_enhanced_embodiment.py \\")
    print("    --stage_1_epochs 5 \\")
    print("    --stage_2_epochs 20 \\")
    print("    --total_epochs 30 \\")
    print("    --batch_size 8")
    
    print("\n8ï¸âƒ£ é«˜æ€§èƒ½è®­ç»ƒ:")
    print("python Main_enhanced_embodiment.py \\")
    print("    --batch_size 32 \\")
    print("    --learning_rate 2e-4 \\")
    print("    --num_workers 8")
    
    print("="*70)
    
    print("\nğŸ§  Enhancedæ¨¡å‹æ ¸å¿ƒç‰¹æ€§:")
    print("  ğŸ”¸ Internal Model: ç»“åˆè®¤çŸ¥ç¥ç»ç§‘å­¦çš„Forward/Inverseæ¨¡å‹")
    print("  ğŸ”¸ Multi-Scale Features: å¤šå°ºåº¦è§†è§‰ç‰¹å¾æå–")
    print("  ğŸ”¸ Early Fusion + Residual: æ—©æœŸèåˆ+ä¸‰è·¯æ®‹å·®è¿æ¥")
    print("  ğŸ”¸ Task-Guided Attention: ä»»åŠ¡é©±åŠ¨çš„ç©ºé—´æ³¨æ„åŠ›")
    print("  ğŸ”¸ Fovea Bias: æ¨¡æ‹Ÿäººçœ¼é»„æ–‘åŒºçš„ä¸­å¤®æ³¨æ„åŠ›åç½®")
    
    print("\nğŸ’¡ å®éªŒå»ºè®®:")
    print("  â€¢ å¯¹æ¯”åŸå§‹æ¨¡å‹å’ŒEnhancedæ¨¡å‹çš„æ€§èƒ½å·®å¼‚")
    print("  â€¢ åˆ†æattentionæƒé‡çš„å¯è§†åŒ–ç»“æœ")
    print("  â€¢ è¯„ä¼°ä¸åŒé˜¶æ®µè®­ç»ƒçš„æ•ˆæœ")
    print("  â€¢ æµ‹è¯•fovea biaså¯¹æ³¨æ„åŠ›èšç„¦çš„å½±å“")
    
    print("\nğŸ“Š æœŸæœ›æ”¹è¿›:")
    print("  â€¢ æ›´ç²¾å‡†çš„è®¡æ•°å‡†ç¡®ç‡")
    print("  â€¢ æ›´åˆç†çš„å…³èŠ‚è¿åŠ¨é¢„æµ‹")
    print("  â€¢ æ›´é›†ä¸­çš„è§†è§‰æ³¨æ„åŠ›")
    print("  â€¢ æ›´å¼ºçš„å¯è§£é‡Šæ€§")


if __name__ == '__main__':
    # æ£€æŸ¥æ˜¯å¦è¯·æ±‚å¸®åŠ©
    import sys
    if len(sys.argv) == 1:
        print("ğŸ§  å¢å¼ºå…·èº«è®¡æ•°æ¨¡å‹è®­ç»ƒç¨‹åº")
        print("é›†æˆInternal Modelã€Early Fusionã€Task-Guided Attention")
        print("ä½¿ç”¨ --help æŸ¥çœ‹å®Œæ•´å‚æ•°åˆ—è¡¨")
        print_usage_examples()
    else:
        main()