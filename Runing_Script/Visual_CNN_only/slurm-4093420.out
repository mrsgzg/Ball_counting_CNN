=== 作业信息 ===
节点: node803
GPU: 1 (ID: 0)
CPU核心: 4
内存: 20480 MB
开始时间: Sun  3 Aug 18:53:44 BST 2025
=== 激活环境 ===
/var/spool/slurmd/job4093420/slurm_script: line 25: --version: command not found
Python版本: 
当前环境: cgtest
=== 开始训练 ===
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:279: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(test_path, map_location=self.device)
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')
============================================================
单图像分类模型训练配置
============================================================
基础配置:
  device: cuda
  batch_size: 16
  learning_rate: 0.0001
  total_epochs: 350
  image_mode: rgb

数据配置:
  data_root: /mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/Ball_counting_CNN/ball_data_collection
  train_csv: scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_train_5.csv
  val_csv: scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_val.csv

模型配置:
  use_attention: True
  cnn_layers: 3
  cnn_channels: [64, 128, 256]
  feature_dim: 256
  attention_heads: 1
  dropout: 0.1

训练配置:
  scheduler_type: none
  label_smoothing: 0.0
  grad_clip_norm: 1.0

保存配置:
  save_dir: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points
  log_dir: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/logs
  save_every: 10
============================================================
所有路径验证通过
配置保存到: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_config.json

正在初始化单图像分类模型训练器...
图像模式: RGB
使用注意力机制: True
标签范围: 1-10 (对应10个类别)
SingleImageClassifier初始化:
  CNN层数: 3
  CNN通道: [64, 128, 256]
  输入通道: 3
  输出类别: 10 (对应标签1-10)
  特征维度: 256
  隐藏维度: 256
  使用注意力: True
  注意力头数: 1
创建带注意力机制的单图像分类模型 (标签1-10)
✓ Model initialization validation passed
=== 创建单图像数据加载器 - 图像模式: RGB ===
标签: 直接使用ball_count
单图像数据集构建完成:
  原始序列数: 46
  提取的单图像样本数: 194
  图像模式: rgb
  标签: 直接使用ball_count
单图像数据集构建完成:
  原始序列数: 242
  提取的单图像样本数: 1074
  图像模式: rgb
  标签: 直接使用ball_count

训练集类别分布:
  球数 1: 32 样本
  球数 2: 24 样本
  球数 3: 24 样本
  球数 4: 20 样本
  球数 5: 18 样本
  球数 6: 21 样本
  球数 7: 16 样本
  球数 8: 18 样本
  球数 9: 10 样本
  球数 10: 11 样本

验证集类别分布:
  球数 1: 162 样本
  球数 2: 126 样本
  球数 3: 108 样本
  球数 4: 105 样本
  球数 5: 102 样本
  球数 6: 98 样本
  球数 7: 96 样本
  球数 8: 99 样本
  球数 9: 90 样本
  球数 10: 88 样本
SingleImageTrainer initialized:
  Model parameters: 734,858
  Training samples: 194
  Validation samples: 1,074
  Image mode: RGB
  Use attention: True
  Label mapping: 1-10 -> 0-9 (for loss calculation)

开始训练单图像分类模型...
目标: 作为具身计数模型的对比基线
使用所有帧图像，标签为对应序列的ball_count

开始训练单图像分类模型
总计 350 个epoch
设备: cuda
图像模式: rgb
Testing model save/load functionality...
✓ Model save/load test passed
Saving initial model state...
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/initial_single_image_model.pth

Performing initial validation...
Initial validation - Loss: 2.3060, Accuracy: 0.1006
Epoch [0] Batch [0/13] Loss: 2.3262 LR: 0.000100
Epoch [0] Batch [10/13] Loss: 2.2790 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [1/350] - Time: 6.42s
Train Loss: 2.2868 | Val Loss: 2.2991
Train Acc: 0.1289 | Val Acc: 0.1006
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.000    Count 2: 0.000    Count 3: 1.000    Count 4: 0.000    Count 5: 0.000  
  Count 6: 0.000    Count 7: 0.000    Count 8: 0.000    Count 9: 0.000    Count 10: 0.000  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.1006
新的最佳模型! 验证准确率: 0.1006
Epoch [1] Batch [0/13] Loss: 2.2568 LR: 0.000100
Epoch [1] Batch [10/13] Loss: 2.2510 LR: 0.000100

Epoch [2/350] - Time: 4.70s
Train Loss: 2.2430 | Val Loss: 2.2713
Train Acc: 0.2062 | Val Acc: 0.1006
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.000    Count 2: 0.468    Count 3: 0.454    Count 4: 0.000    Count 5: 0.000  
  Count 6: 0.000    Count 7: 0.000    Count 8: 0.000    Count 9: 0.000    Count 10: 0.000  
Epoch [2] Batch [0/13] Loss: 2.2063 LR: 0.000100
Epoch [2] Batch [10/13] Loss: 2.1857 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [3/350] - Time: 4.45s
Train Loss: 2.1929 | Val Loss: 2.1879
Train Acc: 0.3041 | Val Acc: 0.2039
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.988    Count 2: 0.016    Count 3: 0.009    Count 4: 0.000    Count 5: 0.000  
  Count 6: 0.000    Count 7: 0.583    Count 8: 0.000    Count 9: 0.000    Count 10: 0.000  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.2039
新的最佳模型! 验证准确率: 0.2039
Epoch [3] Batch [0/13] Loss: 2.1504 LR: 0.000100
Epoch [3] Batch [10/13] Loss: 2.1508 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [4/350] - Time: 4.38s
Train Loss: 2.1237 | Val Loss: 2.0753
Train Acc: 0.3041 | Val Acc: 0.3296
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.981    Count 2: 0.048    Count 3: 0.037    Count 4: 0.000    Count 5: 0.000  
  Count 6: 0.031    Count 7: 0.938    Count 8: 0.040    Count 9: 0.000    Count 10: 1.000  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.3296
新的最佳模型! 验证准确率: 0.3296
Epoch [4] Batch [0/13] Loss: 2.0093 LR: 0.000100
Epoch [4] Batch [10/13] Loss: 1.9708 LR: 0.000100

Epoch [5/350] - Time: 4.41s
Train Loss: 2.0040 | Val Loss: 2.0070
Train Acc: 0.3041 | Val Acc: 0.1955
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.988    Count 2: 0.008    Count 3: 0.000    Count 4: 0.000    Count 5: 0.000  
  Count 6: 0.000    Count 7: 0.510    Count 8: 0.000    Count 9: 0.000    Count 10: 0.000  
Epoch [5] Batch [0/13] Loss: 1.9190 LR: 0.000100
Epoch [5] Batch [10/13] Loss: 1.8873 LR: 0.000100

Epoch [6/350] - Time: 4.30s
Train Loss: 1.8562 | Val Loss: 1.9977
Train Acc: 0.2887 | Val Acc: 0.1676
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 1.000    Count 2: 0.000    Count 3: 0.009    Count 4: 0.000    Count 5: 0.000  
  Count 6: 0.082    Count 7: 0.062    Count 8: 0.000    Count 9: 0.000    Count 10: 0.034  
Epoch [6] Batch [0/13] Loss: 1.5287 LR: 0.000100
Epoch [6] Batch [10/13] Loss: 1.6480 LR: 0.000100

Epoch [7/350] - Time: 4.40s
Train Loss: 1.7237 | Val Loss: 1.8019
Train Acc: 0.3247 | Val Acc: 0.3231
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.988    Count 2: 0.016    Count 3: 0.102    Count 4: 0.143    Count 5: 0.000  
  Count 6: 0.408    Count 7: 0.469    Count 8: 0.010    Count 9: 0.000    Count 10: 0.830  
Epoch [7] Batch [0/13] Loss: 1.7080 LR: 0.000100
Epoch [7] Batch [10/13] Loss: 1.7015 LR: 0.000100

Epoch [8/350] - Time: 4.35s
Train Loss: 1.6341 | Val Loss: 1.8585
Train Acc: 0.3660 | Val Acc: 0.2309
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.994    Count 2: 0.000    Count 3: 0.083    Count 4: 0.181    Count 5: 0.000  
  Count 6: 0.367    Count 7: 0.000    Count 8: 0.010    Count 9: 0.000    Count 10: 0.250  
Epoch [8] Batch [0/13] Loss: 1.5216 LR: 0.000100
Epoch [8] Batch [10/13] Loss: 1.5399 LR: 0.000100

Epoch [9/350] - Time: 4.36s
Train Loss: 1.5950 | Val Loss: 1.8752
Train Acc: 0.3814 | Val Acc: 0.2011
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.988    Count 2: 0.032    Count 3: 0.000    Count 4: 0.029    Count 5: 0.000  
  Count 6: 0.337    Count 7: 0.000    Count 8: 0.061    Count 9: 0.000    Count 10: 0.114  
Epoch [9] Batch [0/13] Loss: 1.5369 LR: 0.000100
Epoch [9] Batch [10/13] Loss: 1.6111 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [10/350] - Time: 4.74s
Train Loss: 1.4818 | Val Loss: 2.0647
Train Acc: 0.4072 | Val Acc: 0.2188
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.981    Count 2: 0.095    Count 3: 0.019    Count 4: 0.067    Count 5: 0.000  
  Count 6: 0.429    Count 7: 0.000    Count 8: 0.131    Count 9: 0.000    Count 10: 0.000  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_9.pth
Epoch [10] Batch [0/13] Loss: 1.8184 LR: 0.000100
Epoch [10] Batch [10/13] Loss: 1.6693 LR: 0.000100

Epoch [11/350] - Time: 4.35s
Train Loss: 1.5267 | Val Loss: 1.7296
Train Acc: 0.3763 | Val Acc: 0.2980
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.063    Count 3: 0.472    Count 4: 0.048    Count 5: 0.000  
  Count 6: 0.510    Count 7: 0.000    Count 8: 0.495    Count 9: 0.000    Count 10: 0.000  
Epoch [11] Batch [0/13] Loss: 1.4486 LR: 0.000100
Epoch [11] Batch [10/13] Loss: 1.4485 LR: 0.000100

Epoch [12/350] - Time: 4.43s
Train Loss: 1.3413 | Val Loss: 1.7358
Train Acc: 0.4485 | Val Acc: 0.3203
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.190    Count 3: 0.407    Count 4: 0.076    Count 5: 0.010  
  Count 6: 0.429    Count 7: 0.031    Count 8: 0.586    Count 9: 0.000    Count 10: 0.080  
Epoch [12] Batch [0/13] Loss: 1.3000 LR: 0.000100
Epoch [12] Batch [10/13] Loss: 1.3133 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [13/350] - Time: 4.45s
Train Loss: 1.2832 | Val Loss: 1.7634
Train Acc: 0.4485 | Val Acc: 0.3445
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.365    Count 3: 0.157    Count 4: 0.486    Count 5: 0.020  
  Count 6: 0.663    Count 7: 0.000    Count 8: 0.495    Count 9: 0.000    Count 10: 0.000  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.3445
新的最佳模型! 验证准确率: 0.3445
Epoch [13] Batch [0/13] Loss: 0.9847 LR: 0.000100
Epoch [13] Batch [10/13] Loss: 1.0750 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [14/350] - Time: 4.38s
Train Loss: 1.2010 | Val Loss: 1.7476
Train Acc: 0.5000 | Val Acc: 0.3594
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.325    Count 3: 0.259    Count 4: 0.695    Count 5: 0.000  
  Count 6: 0.592    Count 7: 0.000    Count 8: 0.424    Count 9: 0.000    Count 10: 0.011  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.3594
新的最佳模型! 验证准确率: 0.3594
Epoch [14] Batch [0/13] Loss: 0.8578 LR: 0.000100
Epoch [14] Batch [10/13] Loss: 0.9890 LR: 0.000100

Epoch [15/350] - Time: 4.28s
Train Loss: 1.1334 | Val Loss: 1.8672
Train Acc: 0.5464 | Val Acc: 0.2756
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.617    Count 2: 0.333    Count 3: 0.111    Count 4: 0.229    Count 5: 0.000  
  Count 6: 0.469    Count 7: 0.042    Count 8: 0.677    Count 9: 0.000    Count 10: 0.011  
Epoch [15] Batch [0/13] Loss: 0.9649 LR: 0.000100
Epoch [15] Batch [10/13] Loss: 1.6176 LR: 0.000100

Epoch [16/350] - Time: 4.33s
Train Loss: 1.0702 | Val Loss: 1.9245
Train Acc: 0.5515 | Val Acc: 0.3259
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.286    Count 3: 0.333    Count 4: 0.276    Count 5: 0.108  
  Count 6: 0.541    Count 7: 0.000    Count 8: 0.293    Count 9: 0.044    Count 10: 0.057  
Epoch [16] Batch [0/13] Loss: 0.9901 LR: 0.000100
Epoch [16] Batch [10/13] Loss: 0.9026 LR: 0.000100

Epoch [17/350] - Time: 4.36s
Train Loss: 1.0358 | Val Loss: 2.0409
Train Acc: 0.5928 | Val Acc: 0.2840
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.981    Count 2: 0.270    Count 3: 0.167    Count 4: 0.295    Count 5: 0.000  
  Count 6: 0.306    Count 7: 0.000    Count 8: 0.263    Count 9: 0.078    Count 10: 0.000  
Epoch [17] Batch [0/13] Loss: 0.9008 LR: 0.000100
Epoch [17] Batch [10/13] Loss: 1.3782 LR: 0.000100

Epoch [18/350] - Time: 4.76s
Train Loss: 1.0787 | Val Loss: 2.2146
Train Acc: 0.5670 | Val Acc: 0.3091
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.278    Count 3: 0.472    Count 4: 0.210    Count 5: 0.059  
  Count 6: 0.378    Count 7: 0.000    Count 8: 0.202    Count 9: 0.111    Count 10: 0.000  
Epoch [18] Batch [0/13] Loss: 0.7573 LR: 0.000100
Epoch [18] Batch [10/13] Loss: 0.8944 LR: 0.000100

Epoch [19/350] - Time: 4.41s
Train Loss: 0.9573 | Val Loss: 2.3407
Train Acc: 0.6340 | Val Acc: 0.2793
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.957    Count 2: 0.302    Count 3: 0.361    Count 4: 0.105    Count 5: 0.020  
  Count 6: 0.224    Count 7: 0.000    Count 8: 0.131    Count 9: 0.111    Count 10: 0.114  
Epoch [19] Batch [0/13] Loss: 0.8502 LR: 0.000100
Epoch [19] Batch [10/13] Loss: 1.0613 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [20/350] - Time: 4.43s
Train Loss: 0.9880 | Val Loss: 1.9301
Train Acc: 0.6237 | Val Acc: 0.3520
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.341    Count 3: 0.231    Count 4: 0.305    Count 5: 0.353  
  Count 6: 0.398    Count 7: 0.000    Count 8: 0.283    Count 9: 0.111    Count 10: 0.091  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_19.pth
Epoch [20] Batch [0/13] Loss: 0.9605 LR: 0.000100
Epoch [20] Batch [10/13] Loss: 0.5802 LR: 0.000100

Epoch [21/350] - Time: 4.34s
Train Loss: 0.8812 | Val Loss: 2.0424
Train Acc: 0.6186 | Val Acc: 0.3371
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.484    Count 3: 0.213    Count 4: 0.114    Count 5: 0.451  
  Count 6: 0.520    Count 7: 0.000    Count 8: 0.273    Count 9: 0.111    Count 10: 0.045  
Epoch [21] Batch [0/13] Loss: 0.8629 LR: 0.000100
Epoch [21] Batch [10/13] Loss: 0.8349 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [22/350] - Time: 4.38s
Train Loss: 0.8174 | Val Loss: 2.2571
Train Acc: 0.6392 | Val Acc: 0.3650
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.238    Count 3: 0.463    Count 4: 0.162    Count 5: 0.471  
  Count 6: 0.571    Count 7: 0.000    Count 8: 0.242    Count 9: 0.111    Count 10: 0.091  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.3650
新的最佳模型! 验证准确率: 0.3650
Epoch [22] Batch [0/13] Loss: 0.5701 LR: 0.000100
Epoch [22] Batch [10/13] Loss: 0.7024 LR: 0.000100

Epoch [23/350] - Time: 4.40s
Train Loss: 0.7367 | Val Loss: 2.7992
Train Acc: 0.6959 | Val Acc: 0.2626
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.254    Count 3: 0.287    Count 4: 0.190    Count 5: 0.078  
  Count 6: 0.122    Count 7: 0.000    Count 8: 0.111    Count 9: 0.111    Count 10: 0.011  
Epoch [23] Batch [0/13] Loss: 1.1273 LR: 0.000100
Epoch [23] Batch [10/13] Loss: 0.6424 LR: 0.000100

Epoch [24/350] - Time: 4.43s
Train Loss: 1.0291 | Val Loss: 2.4145
Train Acc: 0.5722 | Val Acc: 0.2970
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.540    Count 3: 0.148    Count 4: 0.438    Count 5: 0.039  
  Count 6: 0.153    Count 7: 0.000    Count 8: 0.121    Count 9: 0.111    Count 10: 0.000  
Epoch [24] Batch [0/13] Loss: 0.9583 LR: 0.000100
Epoch [24] Batch [10/13] Loss: 0.8838 LR: 0.000100

Epoch [25/350] - Time: 4.51s
Train Loss: 0.8565 | Val Loss: 2.1377
Train Acc: 0.6443 | Val Acc: 0.3454
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.127    Count 3: 0.278    Count 4: 0.210    Count 5: 0.343  
  Count 6: 0.510    Count 7: 0.000    Count 8: 0.566    Count 9: 0.111    Count 10: 0.080  
Epoch [25] Batch [0/13] Loss: 0.8407 LR: 0.000100
Epoch [25] Batch [10/13] Loss: 1.4796 LR: 0.000100

Epoch [26/350] - Time: 4.80s
Train Loss: 0.7928 | Val Loss: 2.2466
Train Acc: 0.6804 | Val Acc: 0.3650
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.716    Count 2: 0.556    Count 3: 0.083    Count 4: 0.638    Count 5: 0.235  
  Count 6: 0.622    Count 7: 0.000    Count 8: 0.202    Count 9: 0.111    Count 10: 0.170  
Epoch [26] Batch [0/13] Loss: 0.5405 LR: 0.000100
Epoch [26] Batch [10/13] Loss: 0.7152 LR: 0.000100

Epoch [27/350] - Time: 4.50s
Train Loss: 0.6624 | Val Loss: 3.0632
Train Acc: 0.7268 | Val Acc: 0.2635
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.183    Count 3: 0.287    Count 4: 0.133    Count 5: 0.127  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.192    Count 9: 0.111    Count 10: 0.045  
Epoch [27] Batch [0/13] Loss: 1.4930 LR: 0.000100
Epoch [27] Batch [10/13] Loss: 0.7941 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [28/350] - Time: 4.44s
Train Loss: 0.8343 | Val Loss: 2.2731
Train Acc: 0.6495 | Val Acc: 0.3780
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.294    Count 3: 0.361    Count 4: 0.314    Count 5: 0.549  
  Count 6: 0.551    Count 7: 0.000    Count 8: 0.242    Count 9: 0.111    Count 10: 0.136  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.3780
新的最佳模型! 验证准确率: 0.3780
Epoch [28] Batch [0/13] Loss: 1.1189 LR: 0.000100
Epoch [28] Batch [10/13] Loss: 0.7196 LR: 0.000100

Epoch [29/350] - Time: 4.39s
Train Loss: 0.7441 | Val Loss: 2.5475
Train Acc: 0.7113 | Val Acc: 0.3445
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.349    Count 3: 0.241    Count 4: 0.305    Count 5: 0.480  
  Count 6: 0.378    Count 7: 0.000    Count 8: 0.242    Count 9: 0.111    Count 10: 0.068  
Epoch [29] Batch [0/13] Loss: 0.4738 LR: 0.000100
Epoch [29] Batch [10/13] Loss: 0.9825 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [30/350] - Time: 4.43s
Train Loss: 0.7484 | Val Loss: 2.0591
Train Acc: 0.7010 | Val Acc: 0.3203
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.759    Count 2: 0.373    Count 3: 0.167    Count 4: 0.019    Count 5: 0.225  
  Count 6: 0.704    Count 7: 0.000    Count 8: 0.333    Count 9: 0.089    Count 10: 0.239  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_29.pth
Epoch [30] Batch [0/13] Loss: 0.8031 LR: 0.000100
Epoch [30] Batch [10/13] Loss: 0.7106 LR: 0.000100

Epoch [31/350] - Time: 4.45s
Train Loss: 0.8350 | Val Loss: 2.1285
Train Acc: 0.6546 | Val Acc: 0.3622
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.302    Count 3: 0.194    Count 4: 0.257    Count 5: 0.343  
  Count 6: 0.490    Count 7: 0.021    Count 8: 0.636    Count 9: 0.111    Count 10: 0.034  
Epoch [31] Batch [0/13] Loss: 0.6269 LR: 0.000100
Epoch [31] Batch [10/13] Loss: 0.5759 LR: 0.000100

Epoch [32/350] - Time: 4.42s
Train Loss: 0.6596 | Val Loss: 2.5212
Train Acc: 0.7320 | Val Acc: 0.3538
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.858    Count 2: 0.349    Count 3: 0.370    Count 4: 0.314    Count 5: 0.431  
  Count 6: 0.469    Count 7: 0.000    Count 8: 0.192    Count 9: 0.122    Count 10: 0.045  
Epoch [32] Batch [0/13] Loss: 0.8206 LR: 0.000100
Epoch [32] Batch [10/13] Loss: 0.5857 LR: 0.000100

Epoch [33/350] - Time: 4.32s
Train Loss: 0.5740 | Val Loss: 2.6367
Train Acc: 0.7629 | Val Acc: 0.3371
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.246    Count 3: 0.407    Count 4: 0.371    Count 5: 0.206  
  Count 6: 0.357    Count 7: 0.010    Count 8: 0.141    Count 9: 0.111    Count 10: 0.182  
Epoch [33] Batch [0/13] Loss: 0.2845 LR: 0.000100
Epoch [33] Batch [10/13] Loss: 0.5812 LR: 0.000100

Epoch [34/350] - Time: 4.43s
Train Loss: 0.5694 | Val Loss: 3.3168
Train Acc: 0.7990 | Val Acc: 0.2821
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.294    Count 3: 0.343    Count 4: 0.162    Count 5: 0.255  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.111    Count 9: 0.111    Count 10: 0.034  
Epoch [34] Batch [0/13] Loss: 0.2765 LR: 0.000100
Epoch [34] Batch [10/13] Loss: 0.5143 LR: 0.000100

Epoch [35/350] - Time: 4.76s
Train Loss: 0.5353 | Val Loss: 2.8216
Train Acc: 0.8041 | Val Acc: 0.3389
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.704    Count 2: 0.397    Count 3: 0.213    Count 4: 0.686    Count 5: 0.265  
  Count 6: 0.439    Count 7: 0.021    Count 8: 0.162    Count 9: 0.111    Count 10: 0.080  
Epoch [35] Batch [0/13] Loss: 1.0541 LR: 0.000100
Epoch [35] Batch [10/13] Loss: 0.4559 LR: 0.000100

Epoch [36/350] - Time: 4.45s
Train Loss: 0.5699 | Val Loss: 2.7573
Train Acc: 0.7784 | Val Acc: 0.3417
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.294    Count 3: 0.370    Count 4: 0.295    Count 5: 0.441  
  Count 6: 0.316    Count 7: 0.000    Count 8: 0.232    Count 9: 0.111    Count 10: 0.023  
Epoch [36] Batch [0/13] Loss: 0.7218 LR: 0.000100
Epoch [36] Batch [10/13] Loss: 0.5701 LR: 0.000100

Epoch [37/350] - Time: 4.49s
Train Loss: 0.5299 | Val Loss: 2.8911
Train Acc: 0.8041 | Val Acc: 0.3575
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.341    Count 3: 0.352    Count 4: 0.505    Count 5: 0.294  
  Count 6: 0.500    Count 7: 0.000    Count 8: 0.121    Count 9: 0.111    Count 10: 0.057  
Epoch [37] Batch [0/13] Loss: 0.6285 LR: 0.000100
Epoch [37] Batch [10/13] Loss: 0.5033 LR: 0.000100

Epoch [38/350] - Time: 4.39s
Train Loss: 0.5439 | Val Loss: 2.6322
Train Acc: 0.7887 | Val Acc: 0.3641
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.310    Count 3: 0.343    Count 4: 0.457    Count 5: 0.471  
  Count 6: 0.551    Count 7: 0.000    Count 8: 0.212    Count 9: 0.111    Count 10: 0.068  
Epoch [38] Batch [0/13] Loss: 0.5254 LR: 0.000100
Epoch [38] Batch [10/13] Loss: 0.3645 LR: 0.000100

Epoch [39/350] - Time: 4.46s
Train Loss: 0.4617 | Val Loss: 3.1995
Train Acc: 0.7990 | Val Acc: 0.2933
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.437    Count 3: 0.269    Count 4: 0.362    Count 5: 0.157  
  Count 6: 0.153    Count 7: 0.000    Count 8: 0.121    Count 9: 0.111    Count 10: 0.034  
Epoch [39] Batch [0/13] Loss: 0.2650 LR: 0.000100
Epoch [39] Batch [10/13] Loss: 0.5524 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [40/350] - Time: 4.42s
Train Loss: 0.4962 | Val Loss: 3.4166
Train Acc: 0.8093 | Val Acc: 0.2961
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.246    Count 3: 0.343    Count 4: 0.276    Count 5: 0.176  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.182    Count 9: 0.111    Count 10: 0.011  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_39.pth
Epoch [40] Batch [0/13] Loss: 0.2766 LR: 0.000100
Epoch [40] Batch [10/13] Loss: 0.4720 LR: 0.000100

Epoch [41/350] - Time: 4.42s
Train Loss: 0.4066 | Val Loss: 3.9198
Train Acc: 0.8454 | Val Acc: 0.2970
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.175    Count 3: 0.361    Count 4: 0.152    Count 5: 0.343  
  Count 6: 0.357    Count 7: 0.000    Count 8: 0.152    Count 9: 0.122    Count 10: 0.034  
Epoch [41] Batch [0/13] Loss: 0.4406 LR: 0.000100
Epoch [41] Batch [10/13] Loss: 0.4087 LR: 0.000100

Epoch [42/350] - Time: 4.81s
Train Loss: 0.4421 | Val Loss: 3.4859
Train Acc: 0.8144 | Val Acc: 0.3017
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.444    Count 3: 0.241    Count 4: 0.305    Count 5: 0.304  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.121    Count 9: 0.122    Count 10: 0.023  
Epoch [42] Batch [0/13] Loss: 0.3978 LR: 0.000100
Epoch [42] Batch [10/13] Loss: 0.3842 LR: 0.000100

Epoch [43/350] - Time: 4.42s
Train Loss: 0.4408 | Val Loss: 3.1920
Train Acc: 0.8402 | Val Acc: 0.3333
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.679    Count 2: 0.484    Count 3: 0.287    Count 4: 0.476    Count 5: 0.431  
  Count 6: 0.316    Count 7: 0.000    Count 8: 0.111    Count 9: 0.111    Count 10: 0.114  
Epoch [43] Batch [0/13] Loss: 0.3572 LR: 0.000100
Epoch [43] Batch [10/13] Loss: 0.4572 LR: 0.000100

Epoch [44/350] - Time: 4.36s
Train Loss: 0.3160 | Val Loss: 3.5583
Train Acc: 0.8763 | Val Acc: 0.2877
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.183    Count 3: 0.389    Count 4: 0.171    Count 5: 0.206  
  Count 6: 0.184    Count 7: 0.000    Count 8: 0.232    Count 9: 0.122    Count 10: 0.034  
Epoch [44] Batch [0/13] Loss: 0.3567 LR: 0.000100
Epoch [44] Batch [10/13] Loss: 0.4576 LR: 0.000100

Epoch [45/350] - Time: 4.48s
Train Loss: 0.3495 | Val Loss: 3.9464
Train Acc: 0.8763 | Val Acc: 0.3035
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.302    Count 3: 0.370    Count 4: 0.390    Count 5: 0.284  
  Count 6: 0.153    Count 7: 0.000    Count 8: 0.162    Count 9: 0.122    Count 10: 0.034  
Epoch [45] Batch [0/13] Loss: 0.2385 LR: 0.000100
Epoch [45] Batch [10/13] Loss: 0.2310 LR: 0.000100

Epoch [46/350] - Time: 4.46s
Train Loss: 0.6041 | Val Loss: 3.0614
Train Acc: 0.7938 | Val Acc: 0.3520
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.238    Count 3: 0.352    Count 4: 0.086    Count 5: 0.588  
  Count 6: 0.439    Count 7: 0.000    Count 8: 0.424    Count 9: 0.111    Count 10: 0.114  
Epoch [46] Batch [0/13] Loss: 0.2171 LR: 0.000100
Epoch [46] Batch [10/13] Loss: 0.3242 LR: 0.000100

Epoch [47/350] - Time: 4.45s
Train Loss: 0.2996 | Val Loss: 3.4674
Train Acc: 0.8918 | Val Acc: 0.3026
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.286    Count 3: 0.370    Count 4: 0.162    Count 5: 0.343  
  Count 6: 0.224    Count 7: 0.000    Count 8: 0.152    Count 9: 0.122    Count 10: 0.159  
Epoch [47] Batch [0/13] Loss: 0.0676 LR: 0.000100
Epoch [47] Batch [10/13] Loss: 0.3863 LR: 0.000100

Epoch [48/350] - Time: 4.43s
Train Loss: 0.3356 | Val Loss: 4.1473
Train Acc: 0.8711 | Val Acc: 0.2961
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.710    Count 2: 0.413    Count 3: 0.259    Count 4: 0.467    Count 5: 0.196  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.121    Count 9: 0.122    Count 10: 0.023  
Epoch [48] Batch [0/13] Loss: 0.1760 LR: 0.000100
Epoch [48] Batch [10/13] Loss: 0.3102 LR: 0.000100

Epoch [49/350] - Time: 4.49s
Train Loss: 0.3410 | Val Loss: 3.6983
Train Acc: 0.8814 | Val Acc: 0.3035
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.679    Count 2: 0.500    Count 3: 0.278    Count 4: 0.457    Count 5: 0.324  
  Count 6: 0.143    Count 7: 0.010    Count 8: 0.091    Count 9: 0.111    Count 10: 0.091  
Epoch [49] Batch [0/13] Loss: 0.1927 LR: 0.000100
Epoch [49] Batch [10/13] Loss: 0.2724 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [50/350] - Time: 4.86s
Train Loss: 0.2716 | Val Loss: 3.4108
Train Acc: 0.9124 | Val Acc: 0.3194
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.238    Count 3: 0.407    Count 4: 0.181    Count 5: 0.461  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.172    Count 9: 0.122    Count 10: 0.057  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_49.pth
Epoch [50] Batch [0/13] Loss: 0.0941 LR: 0.000100
Epoch [50] Batch [10/13] Loss: 0.1159 LR: 0.000100

Epoch [51/350] - Time: 4.47s
Train Loss: 0.2643 | Val Loss: 4.2685
Train Acc: 0.9278 | Val Acc: 0.2886
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.741    Count 2: 0.452    Count 3: 0.176    Count 4: 0.400    Count 5: 0.324  
  Count 6: 0.173    Count 7: 0.000    Count 8: 0.091    Count 9: 0.122    Count 10: 0.023  
Epoch [51] Batch [0/13] Loss: 0.2698 LR: 0.000100
Epoch [51] Batch [10/13] Loss: 0.5033 LR: 0.000100

Epoch [52/350] - Time: 4.55s
Train Loss: 0.2664 | Val Loss: 3.8567
Train Acc: 0.9175 | Val Acc: 0.3119
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.286    Count 3: 0.380    Count 4: 0.286    Count 5: 0.324  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.141    Count 9: 0.111    Count 10: 0.125  
Epoch [52] Batch [0/13] Loss: 0.3402 LR: 0.000100
Epoch [52] Batch [10/13] Loss: 0.2368 LR: 0.000100

Epoch [53/350] - Time: 4.36s
Train Loss: 0.2541 | Val Loss: 4.1098
Train Acc: 0.9072 | Val Acc: 0.3026
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.357    Count 3: 0.250    Count 4: 0.352    Count 5: 0.294  
  Count 6: 0.173    Count 7: 0.000    Count 8: 0.101    Count 9: 0.122    Count 10: 0.091  
Epoch [53] Batch [0/13] Loss: 0.3433 LR: 0.000100
Epoch [53] Batch [10/13] Loss: 0.2332 LR: 0.000100

Epoch [54/350] - Time: 4.50s
Train Loss: 0.1681 | Val Loss: 4.2214
Train Acc: 0.9588 | Val Acc: 0.2896
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.270    Count 3: 0.398    Count 4: 0.133    Count 5: 0.284  
  Count 6: 0.265    Count 7: 0.000    Count 8: 0.131    Count 9: 0.133    Count 10: 0.045  
Epoch [54] Batch [0/13] Loss: 0.2991 LR: 0.000100
Epoch [54] Batch [10/13] Loss: 0.1070 LR: 0.000100

Epoch [55/350] - Time: 4.45s
Train Loss: 0.2212 | Val Loss: 4.0442
Train Acc: 0.9278 | Val Acc: 0.3082
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.183    Count 3: 0.481    Count 4: 0.124    Count 5: 0.373  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.141    Count 9: 0.122    Count 10: 0.114  
Epoch [55] Batch [0/13] Loss: 0.2845 LR: 0.000100
Epoch [55] Batch [10/13] Loss: 0.1615 LR: 0.000100

Epoch [56/350] - Time: 4.45s
Train Loss: 0.2058 | Val Loss: 3.7538
Train Acc: 0.9227 | Val Acc: 0.3380
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.183    Count 3: 0.519    Count 4: 0.162    Count 5: 0.618  
  Count 6: 0.214    Count 7: 0.010    Count 8: 0.152    Count 9: 0.111    Count 10: 0.170  
Epoch [56] Batch [0/13] Loss: 0.2391 LR: 0.000100
Epoch [56] Batch [10/13] Loss: 0.1388 LR: 0.000100

Epoch [57/350] - Time: 4.35s
Train Loss: 0.1494 | Val Loss: 4.0862
Train Acc: 0.9485 | Val Acc: 0.3324
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.722    Count 2: 0.349    Count 3: 0.269    Count 4: 0.181    Count 5: 0.490  
  Count 6: 0.398    Count 7: 0.000    Count 8: 0.394    Count 9: 0.189    Count 10: 0.034  
Epoch [57] Batch [0/13] Loss: 0.0575 LR: 0.000100
Epoch [57] Batch [10/13] Loss: 0.5366 LR: 0.000100

Epoch [58/350] - Time: 4.73s
Train Loss: 0.2069 | Val Loss: 4.8414
Train Acc: 0.9227 | Val Acc: 0.3007
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.765    Count 2: 0.357    Count 3: 0.278    Count 4: 0.467    Count 5: 0.333  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.081    Count 9: 0.122    Count 10: 0.125  
Epoch [58] Batch [0/13] Loss: 0.4219 LR: 0.000100
Epoch [58] Batch [10/13] Loss: 0.2937 LR: 0.000100

Epoch [59/350] - Time: 4.43s
Train Loss: 0.1844 | Val Loss: 4.7753
Train Acc: 0.9485 | Val Acc: 0.2998
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.246    Count 3: 0.296    Count 4: 0.257    Count 5: 0.324  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.162    Count 9: 0.122    Count 10: 0.034  
Epoch [59] Batch [0/13] Loss: 0.0714 LR: 0.000100
Epoch [59] Batch [10/13] Loss: 0.6826 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [60/350] - Time: 4.44s
Train Loss: 0.1578 | Val Loss: 4.1201
Train Acc: 0.9588 | Val Acc: 0.3175
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.630    Count 2: 0.421    Count 3: 0.204    Count 4: 0.324    Count 5: 0.461  
  Count 6: 0.357    Count 7: 0.010    Count 8: 0.222    Count 9: 0.122    Count 10: 0.159  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_59.pth
Epoch [60] Batch [0/13] Loss: 0.1722 LR: 0.000100
Epoch [60] Batch [10/13] Loss: 0.0888 LR: 0.000100

Epoch [61/350] - Time: 4.46s
Train Loss: 0.1990 | Val Loss: 4.6228
Train Acc: 0.9433 | Val Acc: 0.3147
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.710    Count 2: 0.349    Count 3: 0.194    Count 4: 0.295    Count 5: 0.441  
  Count 6: 0.418    Count 7: 0.000    Count 8: 0.232    Count 9: 0.122    Count 10: 0.080  
Epoch [61] Batch [0/13] Loss: 0.0582 LR: 0.000100
Epoch [61] Batch [10/13] Loss: 0.1795 LR: 0.000100

Epoch [62/350] - Time: 4.38s
Train Loss: 0.1535 | Val Loss: 5.2995
Train Acc: 0.9639 | Val Acc: 0.2831
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.246    Count 3: 0.417    Count 4: 0.124    Count 5: 0.353  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.111    Count 9: 0.122    Count 10: 0.057  
Epoch [62] Batch [0/13] Loss: 0.1055 LR: 0.000100
Epoch [62] Batch [10/13] Loss: 0.0266 LR: 0.000100

Epoch [63/350] - Time: 4.50s
Train Loss: 0.1491 | Val Loss: 5.1601
Train Acc: 0.9691 | Val Acc: 0.2905
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.722    Count 2: 0.325    Count 3: 0.167    Count 4: 0.343    Count 5: 0.451  
  Count 6: 0.214    Count 7: 0.000    Count 8: 0.111    Count 9: 0.122    Count 10: 0.125  
Epoch [63] Batch [0/13] Loss: 0.0989 LR: 0.000100
Epoch [63] Batch [10/13] Loss: 0.3723 LR: 0.000100

Epoch [64/350] - Time: 4.49s
Train Loss: 0.1943 | Val Loss: 5.1097
Train Acc: 0.9433 | Val Acc: 0.3203
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.286    Count 3: 0.398    Count 4: 0.333    Count 5: 0.520  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.091    Count 9: 0.122    Count 10: 0.136  
Epoch [64] Batch [0/13] Loss: 0.0282 LR: 0.000100
Epoch [64] Batch [10/13] Loss: 0.0748 LR: 0.000100

Epoch [65/350] - Time: 4.36s
Train Loss: 0.1347 | Val Loss: 4.4899
Train Acc: 0.9588 | Val Acc: 0.3296
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.246    Count 3: 0.287    Count 4: 0.171    Count 5: 0.480  
  Count 6: 0.296    Count 7: 0.010    Count 8: 0.394    Count 9: 0.144    Count 10: 0.125  
Epoch [65] Batch [0/13] Loss: 0.0333 LR: 0.000100
Epoch [65] Batch [10/13] Loss: 0.2731 LR: 0.000100

Epoch [66/350] - Time: 4.79s
Train Loss: 0.0917 | Val Loss: 5.4920
Train Acc: 0.9639 | Val Acc: 0.3296
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.765    Count 2: 0.310    Count 3: 0.306    Count 4: 0.181    Count 5: 0.627  
  Count 6: 0.306    Count 7: 0.000    Count 8: 0.303    Count 9: 0.122    Count 10: 0.045  
Epoch [66] Batch [0/13] Loss: 0.0386 LR: 0.000100
Epoch [66] Batch [10/13] Loss: 0.0720 LR: 0.000100

Epoch [67/350] - Time: 4.46s
Train Loss: 0.0893 | Val Loss: 5.6491
Train Acc: 0.9794 | Val Acc: 0.3007
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.765    Count 2: 0.357    Count 3: 0.176    Count 4: 0.581    Count 5: 0.245  
  Count 6: 0.184    Count 7: 0.021    Count 8: 0.101    Count 9: 0.111    Count 10: 0.102  
Epoch [67] Batch [0/13] Loss: 0.1392 LR: 0.000100
Epoch [67] Batch [10/13] Loss: 0.0653 LR: 0.000100

Epoch [68/350] - Time: 4.51s
Train Loss: 0.1542 | Val Loss: 6.0330
Train Acc: 0.9588 | Val Acc: 0.2840
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.294    Count 3: 0.231    Count 4: 0.276    Count 5: 0.324  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.091    Count 9: 0.122    Count 10: 0.091  
Epoch [68] Batch [0/13] Loss: 0.0915 LR: 0.000100
Epoch [68] Batch [10/13] Loss: 0.0339 LR: 0.000100

Epoch [69/350] - Time: 4.44s
Train Loss: 0.1837 | Val Loss: 5.9478
Train Acc: 0.9691 | Val Acc: 0.3073
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.809    Count 2: 0.302    Count 3: 0.361    Count 4: 0.219    Count 5: 0.451  
  Count 6: 0.235    Count 7: 0.000    Count 8: 0.141    Count 9: 0.122    Count 10: 0.057  
Epoch [69] Batch [0/13] Loss: 0.1320 LR: 0.000100
Epoch [69] Batch [10/13] Loss: 0.1207 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [70/350] - Time: 4.51s
Train Loss: 0.1176 | Val Loss: 5.2691
Train Acc: 0.9588 | Val Acc: 0.3101
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.599    Count 2: 0.341    Count 3: 0.194    Count 4: 0.400    Count 5: 0.363  
  Count 6: 0.500    Count 7: 0.010    Count 8: 0.253    Count 9: 0.111    Count 10: 0.091  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_69.pth
Epoch [70] Batch [0/13] Loss: 0.1290 LR: 0.000100
Epoch [70] Batch [10/13] Loss: 0.0870 LR: 0.000100

Epoch [71/350] - Time: 4.38s
Train Loss: 0.0824 | Val Loss: 5.6026
Train Acc: 0.9691 | Val Acc: 0.3231
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.230    Count 3: 0.361    Count 4: 0.248    Count 5: 0.500  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.172    Count 9: 0.122    Count 10: 0.091  
Epoch [71] Batch [0/13] Loss: 0.0107 LR: 0.000100
Epoch [71] Batch [10/13] Loss: 0.0077 LR: 0.000100

Epoch [72/350] - Time: 4.44s
Train Loss: 0.0442 | Val Loss: 5.7297
Train Acc: 0.9897 | Val Acc: 0.3054
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.802    Count 2: 0.286    Count 3: 0.324    Count 4: 0.371    Count 5: 0.373  
  Count 6: 0.153    Count 7: 0.000    Count 8: 0.152    Count 9: 0.122    Count 10: 0.102  
Epoch [72] Batch [0/13] Loss: 0.0094 LR: 0.000100
Epoch [72] Batch [10/13] Loss: 0.0060 LR: 0.000100

Epoch [73/350] - Time: 4.63s
Train Loss: 0.0642 | Val Loss: 6.3688
Train Acc: 0.9742 | Val Acc: 0.2942
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.349    Count 3: 0.269    Count 4: 0.371    Count 5: 0.324  
  Count 6: 0.051    Count 7: 0.000    Count 8: 0.101    Count 9: 0.122    Count 10: 0.114  
Epoch [73] Batch [0/13] Loss: 0.2546 LR: 0.000100
Epoch [73] Batch [10/13] Loss: 0.2945 LR: 0.000100

Epoch [74/350] - Time: 4.51s
Train Loss: 0.2121 | Val Loss: 5.0043
Train Acc: 0.9227 | Val Acc: 0.2998
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.611    Count 2: 0.262    Count 3: 0.194    Count 4: 0.267    Count 5: 0.529  
  Count 6: 0.347    Count 7: 0.021    Count 8: 0.263    Count 9: 0.133    Count 10: 0.148  
Epoch [74] Batch [0/13] Loss: 0.4642 LR: 0.000100
Epoch [74] Batch [10/13] Loss: 0.0522 LR: 0.000100

Epoch [75/350] - Time: 4.87s
Train Loss: 0.2209 | Val Loss: 5.3529
Train Acc: 0.9278 | Val Acc: 0.3110
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.183    Count 3: 0.231    Count 4: 0.143    Count 5: 0.549  
  Count 6: 0.235    Count 7: 0.010    Count 8: 0.333    Count 9: 0.189    Count 10: 0.011  
Epoch [75] Batch [0/13] Loss: 0.0064 LR: 0.000100
Epoch [75] Batch [10/13] Loss: 0.0916 LR: 0.000100

Epoch [76/350] - Time: 4.50s
Train Loss: 0.0673 | Val Loss: 6.3661
Train Acc: 0.9794 | Val Acc: 0.2821
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.246    Count 3: 0.259    Count 4: 0.181    Count 5: 0.402  
  Count 6: 0.071    Count 7: 0.000    Count 8: 0.091    Count 9: 0.133    Count 10: 0.125  
Epoch [76] Batch [0/13] Loss: 0.0051 LR: 0.000100
Epoch [76] Batch [10/13] Loss: 0.0103 LR: 0.000100

Epoch [77/350] - Time: 4.50s
Train Loss: 0.0128 | Val Loss: 5.9531
Train Acc: 1.0000 | Val Acc: 0.3184
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.772    Count 2: 0.270    Count 3: 0.231    Count 4: 0.276    Count 5: 0.520  
  Count 6: 0.316    Count 7: 0.010    Count 8: 0.172    Count 9: 0.156    Count 10: 0.148  
Epoch [77] Batch [0/13] Loss: 0.0048 LR: 0.000100
Epoch [77] Batch [10/13] Loss: 0.0445 LR: 0.000100

Epoch [78/350] - Time: 4.45s
Train Loss: 0.0330 | Val Loss: 6.2442
Train Acc: 0.9845 | Val Acc: 0.3166
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.151    Count 3: 0.398    Count 4: 0.076    Count 5: 0.608  
  Count 6: 0.286    Count 7: 0.000    Count 8: 0.242    Count 9: 0.156    Count 10: 0.102  
Epoch [78] Batch [0/13] Loss: 0.0113 LR: 0.000100
Epoch [78] Batch [10/13] Loss: 0.0017 LR: 0.000100

Epoch [79/350] - Time: 4.42s
Train Loss: 0.0502 | Val Loss: 6.0969
Train Acc: 0.9742 | Val Acc: 0.3156
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.809    Count 2: 0.302    Count 3: 0.204    Count 4: 0.505    Count 5: 0.422  
  Count 6: 0.245    Count 7: 0.000    Count 8: 0.091    Count 9: 0.111    Count 10: 0.102  
Epoch [79] Batch [0/13] Loss: 0.0066 LR: 0.000100
Epoch [79] Batch [10/13] Loss: 0.0052 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [80/350] - Time: 4.46s
Train Loss: 0.0267 | Val Loss: 6.5094
Train Acc: 0.9897 | Val Acc: 0.3128
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.765    Count 2: 0.413    Count 3: 0.157    Count 4: 0.390    Count 5: 0.490  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.121    Count 9: 0.122    Count 10: 0.102  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_79.pth
Epoch [80] Batch [0/13] Loss: 0.1885 LR: 0.000100
Epoch [80] Batch [10/13] Loss: 0.0007 LR: 0.000100

Epoch [81/350] - Time: 4.38s
Train Loss: 0.0357 | Val Loss: 6.4196
Train Acc: 0.9897 | Val Acc: 0.3212
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.294    Count 3: 0.333    Count 4: 0.333    Count 5: 0.422  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.162    Count 9: 0.122    Count 10: 0.125  
Epoch [81] Batch [0/13] Loss: 0.0011 LR: 0.000100
Epoch [81] Batch [10/13] Loss: 0.0022 LR: 0.000100

Epoch [82/350] - Time: 4.44s
Train Loss: 0.0331 | Val Loss: 6.3914
Train Acc: 0.9845 | Val Acc: 0.3343
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.254    Count 3: 0.213    Count 4: 0.295    Count 5: 0.441  
  Count 6: 0.347    Count 7: 0.000    Count 8: 0.343    Count 9: 0.144    Count 10: 0.125  
Epoch [82] Batch [0/13] Loss: 0.0016 LR: 0.000100
Epoch [82] Batch [10/13] Loss: 0.0083 LR: 0.000100

Epoch [83/350] - Time: 4.75s
Train Loss: 0.0080 | Val Loss: 7.1177
Train Acc: 1.0000 | Val Acc: 0.3184
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.778    Count 2: 0.254    Count 3: 0.278    Count 4: 0.229    Count 5: 0.657  
  Count 6: 0.245    Count 7: 0.000    Count 8: 0.212    Count 9: 0.122    Count 10: 0.080  
Epoch [83] Batch [0/13] Loss: 0.0977 LR: 0.000100
Epoch [83] Batch [10/13] Loss: 0.0031 LR: 0.000100

Epoch [84/350] - Time: 4.39s
Train Loss: 0.0149 | Val Loss: 7.0370
Train Acc: 0.9948 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.710    Count 2: 0.310    Count 3: 0.231    Count 4: 0.352    Count 5: 0.529  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.141    Count 9: 0.122    Count 10: 0.080  
Epoch [84] Batch [0/13] Loss: 0.0026 LR: 0.000100
Epoch [84] Batch [10/13] Loss: 0.0019 LR: 0.000100

Epoch [85/350] - Time: 4.37s
Train Loss: 0.0140 | Val Loss: 6.7118
Train Acc: 0.9948 | Val Acc: 0.3156
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.302    Count 3: 0.259    Count 4: 0.219    Count 5: 0.490  
  Count 6: 0.214    Count 7: 0.010    Count 8: 0.172    Count 9: 0.156    Count 10: 0.170  
Epoch [85] Batch [0/13] Loss: 0.0013 LR: 0.000100
Epoch [85] Batch [10/13] Loss: 0.1105 LR: 0.000100

Epoch [86/350] - Time: 4.39s
Train Loss: 0.0242 | Val Loss: 7.2062
Train Acc: 0.9897 | Val Acc: 0.3035
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.765    Count 2: 0.294    Count 3: 0.352    Count 4: 0.152    Count 5: 0.520  
  Count 6: 0.235    Count 7: 0.000    Count 8: 0.141    Count 9: 0.144    Count 10: 0.091  
Epoch [86] Batch [0/13] Loss: 0.0031 LR: 0.000100
Epoch [86] Batch [10/13] Loss: 0.2150 LR: 0.000100

Epoch [87/350] - Time: 4.38s
Train Loss: 0.0421 | Val Loss: 8.1004
Train Acc: 0.9845 | Val Acc: 0.2886
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.747    Count 2: 0.167    Count 3: 0.519    Count 4: 0.105    Count 5: 0.441  
  Count 6: 0.184    Count 7: 0.000    Count 8: 0.192    Count 9: 0.133    Count 10: 0.080  
Epoch [87] Batch [0/13] Loss: 0.0145 LR: 0.000100
Epoch [87] Batch [10/13] Loss: 0.0042 LR: 0.000100

Epoch [88/350] - Time: 4.45s
Train Loss: 0.0609 | Val Loss: 7.6638
Train Acc: 0.9845 | Val Acc: 0.3082
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.858    Count 2: 0.317    Count 3: 0.204    Count 4: 0.248    Count 5: 0.441  
  Count 6: 0.265    Count 7: 0.000    Count 8: 0.162    Count 9: 0.122    Count 10: 0.068  
Epoch [88] Batch [0/13] Loss: 0.0143 LR: 0.000100
Epoch [88] Batch [10/13] Loss: 0.0107 LR: 0.000100

Epoch [89/350] - Time: 4.48s
Train Loss: 0.0398 | Val Loss: 7.0052
Train Acc: 0.9845 | Val Acc: 0.3128
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.698    Count 2: 0.357    Count 3: 0.231    Count 4: 0.333    Count 5: 0.431  
  Count 6: 0.398    Count 7: 0.000    Count 8: 0.172    Count 9: 0.122    Count 10: 0.080  
Epoch [89] Batch [0/13] Loss: 0.2433 LR: 0.000100
Epoch [89] Batch [10/13] Loss: 0.0054 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [90/350] - Time: 4.45s
Train Loss: 0.0478 | Val Loss: 7.2505
Train Acc: 0.9845 | Val Acc: 0.2905
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.648    Count 2: 0.190    Count 3: 0.407    Count 4: 0.124    Count 5: 0.637  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.202    Count 9: 0.144    Count 10: 0.102  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_89.pth
Epoch [90] Batch [0/13] Loss: 0.0974 LR: 0.000100
Epoch [90] Batch [10/13] Loss: 0.0017 LR: 0.000100

Epoch [91/350] - Time: 4.88s
Train Loss: 0.0159 | Val Loss: 8.0850
Train Acc: 0.9948 | Val Acc: 0.2849
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.852    Count 2: 0.341    Count 3: 0.222    Count 4: 0.429    Count 5: 0.206  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.111    Count 9: 0.122    Count 10: 0.045  
Epoch [91] Batch [0/13] Loss: 0.0043 LR: 0.000100
Epoch [91] Batch [10/13] Loss: 0.1096 LR: 0.000100

Epoch [92/350] - Time: 4.43s
Train Loss: 0.0179 | Val Loss: 8.6784
Train Acc: 0.9948 | Val Acc: 0.3035
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.198    Count 3: 0.380    Count 4: 0.095    Count 5: 0.608  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.263    Count 9: 0.144    Count 10: 0.023  
Epoch [92] Batch [0/13] Loss: 0.0006 LR: 0.000100
Epoch [92] Batch [10/13] Loss: 0.0046 LR: 0.000100

Epoch [93/350] - Time: 4.41s
Train Loss: 0.0059 | Val Loss: 7.8980
Train Acc: 1.0000 | Val Acc: 0.3231
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.238    Count 3: 0.407    Count 4: 0.276    Count 5: 0.529  
  Count 6: 0.173    Count 7: 0.000    Count 8: 0.222    Count 9: 0.167    Count 10: 0.045  
Epoch [93] Batch [0/13] Loss: 0.0004 LR: 0.000100
Epoch [93] Batch [10/13] Loss: 0.0077 LR: 0.000100

Epoch [94/350] - Time: 4.33s
Train Loss: 0.0192 | Val Loss: 7.4077
Train Acc: 0.9897 | Val Acc: 0.3343
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.262    Count 3: 0.315    Count 4: 0.429    Count 5: 0.461  
  Count 6: 0.235    Count 7: 0.000    Count 8: 0.242    Count 9: 0.144    Count 10: 0.068  
Epoch [94] Batch [0/13] Loss: 0.0058 LR: 0.000100
Epoch [94] Batch [10/13] Loss: 0.0006 LR: 0.000100

Epoch [95/350] - Time: 4.41s
Train Loss: 0.0056 | Val Loss: 7.6009
Train Acc: 1.0000 | Val Acc: 0.3250
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.198    Count 3: 0.361    Count 4: 0.162    Count 5: 0.451  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.374    Count 9: 0.189    Count 10: 0.091  
Epoch [95] Batch [0/13] Loss: 0.0019 LR: 0.000100
Epoch [95] Batch [10/13] Loss: 0.0003 LR: 0.000100

Epoch [96/350] - Time: 4.38s
Train Loss: 0.0018 | Val Loss: 8.4296
Train Acc: 1.0000 | Val Acc: 0.3073
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.254    Count 3: 0.370    Count 4: 0.352    Count 5: 0.343  
  Count 6: 0.163    Count 7: 0.000    Count 8: 0.202    Count 9: 0.133    Count 10: 0.068  
Epoch [96] Batch [0/13] Loss: 0.0020 LR: 0.000100
Epoch [96] Batch [10/13] Loss: 0.0003 LR: 0.000100

Epoch [97/350] - Time: 4.42s
Train Loss: 0.0314 | Val Loss: 8.7000
Train Acc: 0.9897 | Val Acc: 0.2886
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.772    Count 2: 0.230    Count 3: 0.491    Count 4: 0.143    Count 5: 0.353  
  Count 6: 0.122    Count 7: 0.000    Count 8: 0.222    Count 9: 0.156    Count 10: 0.045  
Epoch [97] Batch [0/13] Loss: 0.0004 LR: 0.000100
Epoch [97] Batch [10/13] Loss: 0.0023 LR: 0.000100

Epoch [98/350] - Time: 4.34s
Train Loss: 0.0192 | Val Loss: 8.0473
Train Acc: 0.9897 | Val Acc: 0.3175
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.735    Count 2: 0.294    Count 3: 0.269    Count 4: 0.410    Count 5: 0.402  
  Count 6: 0.316    Count 7: 0.000    Count 8: 0.242    Count 9: 0.133    Count 10: 0.057  
Epoch [98] Batch [0/13] Loss: 0.0003 LR: 0.000100
Epoch [98] Batch [10/13] Loss: 0.0004 LR: 0.000100

Epoch [99/350] - Time: 4.80s
Train Loss: 0.0025 | Val Loss: 9.7588
Train Acc: 1.0000 | Val Acc: 0.2737
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.230    Count 3: 0.444    Count 4: 0.133    Count 5: 0.275  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.111    Count 9: 0.133    Count 10: 0.011  
Epoch [99] Batch [0/13] Loss: 0.0004 LR: 0.000100
Epoch [99] Batch [10/13] Loss: 0.0008 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [100/350] - Time: 4.45s
Train Loss: 0.0043 | Val Loss: 7.5453
Train Acc: 1.0000 | Val Acc: 0.3147
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.630    Count 2: 0.270    Count 3: 0.269    Count 4: 0.286    Count 5: 0.559  
  Count 6: 0.255    Count 7: 0.010    Count 8: 0.303    Count 9: 0.178    Count 10: 0.159  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_99.pth
Epoch [100] Batch [0/13] Loss: 0.0015 LR: 0.000100
Epoch [100] Batch [10/13] Loss: 0.0002 LR: 0.000100

Epoch [101/350] - Time: 4.45s
Train Loss: 0.0216 | Val Loss: 8.7415
Train Acc: 0.9948 | Val Acc: 0.3007
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.735    Count 2: 0.214    Count 3: 0.287    Count 4: 0.143    Count 5: 0.529  
  Count 6: 0.306    Count 7: 0.000    Count 8: 0.263    Count 9: 0.167    Count 10: 0.068  
Epoch [101] Batch [0/13] Loss: 0.0011 LR: 0.000100
Epoch [101] Batch [10/13] Loss: 0.0019 LR: 0.000100

Epoch [102/350] - Time: 4.40s
Train Loss: 0.0475 | Val Loss: 8.5161
Train Acc: 0.9948 | Val Acc: 0.3017
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.254    Count 3: 0.278    Count 4: 0.314    Count 5: 0.441  
  Count 6: 0.153    Count 7: 0.000    Count 8: 0.111    Count 9: 0.122    Count 10: 0.057  
Epoch [102] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [102] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [103/350] - Time: 4.46s
Train Loss: 0.0009 | Val Loss: 8.2814
Train Acc: 1.0000 | Val Acc: 0.3007
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.254    Count 3: 0.287    Count 4: 0.257    Count 5: 0.559  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.141    Count 9: 0.122    Count 10: 0.091  
Epoch [103] Batch [0/13] Loss: 0.0004 LR: 0.000100
Epoch [103] Batch [10/13] Loss: 0.0107 LR: 0.000100

Epoch [104/350] - Time: 4.35s
Train Loss: 0.0302 | Val Loss: 10.1038
Train Acc: 0.9948 | Val Acc: 0.2644
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.238    Count 3: 0.343    Count 4: 0.114    Count 5: 0.265  
  Count 6: 0.041    Count 7: 0.000    Count 8: 0.101    Count 9: 0.122    Count 10: 0.057  
Epoch [104] Batch [0/13] Loss: 0.0022 LR: 0.000100
Epoch [104] Batch [10/13] Loss: 0.0040 LR: 0.000100

Epoch [105/350] - Time: 4.32s
Train Loss: 0.0242 | Val Loss: 9.1192
Train Acc: 0.9897 | Val Acc: 0.2914
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.691    Count 2: 0.214    Count 3: 0.231    Count 4: 0.257    Count 5: 0.588  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.212    Count 9: 0.122    Count 10: 0.034  
Epoch [105] Batch [0/13] Loss: 0.0015 LR: 0.000100
Epoch [105] Batch [10/13] Loss: 0.2406 LR: 0.000100

Epoch [106/350] - Time: 4.44s
Train Loss: 0.0300 | Val Loss: 7.8549
Train Acc: 0.9897 | Val Acc: 0.3296
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.802    Count 2: 0.294    Count 3: 0.231    Count 4: 0.419    Count 5: 0.490  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.222    Count 9: 0.122    Count 10: 0.068  
Epoch [106] Batch [0/13] Loss: 0.0149 LR: 0.000100
Epoch [106] Batch [10/13] Loss: 0.0003 LR: 0.000100

Epoch [107/350] - Time: 4.81s
Train Loss: 0.0481 | Val Loss: 8.5212
Train Acc: 0.9897 | Val Acc: 0.2933
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.246    Count 3: 0.426    Count 4: 0.248    Count 5: 0.333  
  Count 6: 0.122    Count 7: 0.000    Count 8: 0.172    Count 9: 0.122    Count 10: 0.068  
Epoch [107] Batch [0/13] Loss: 0.0018 LR: 0.000100
Epoch [107] Batch [10/13] Loss: 0.0010 LR: 0.000100

Epoch [108/350] - Time: 4.44s
Train Loss: 0.0321 | Val Loss: 8.0890
Train Acc: 0.9897 | Val Acc: 0.3054
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.679    Count 2: 0.206    Count 3: 0.343    Count 4: 0.210    Count 5: 0.500  
  Count 6: 0.337    Count 7: 0.010    Count 8: 0.242    Count 9: 0.167    Count 10: 0.102  
Epoch [108] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [108] Batch [10/13] Loss: 0.0010 LR: 0.000100

Epoch [109/350] - Time: 4.43s
Train Loss: 0.0027 | Val Loss: 9.5657
Train Acc: 1.0000 | Val Acc: 0.2784
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.759    Count 2: 0.222    Count 3: 0.269    Count 4: 0.219    Count 5: 0.500  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.172    Count 9: 0.122    Count 10: 0.080  
Epoch [109] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [109] Batch [10/13] Loss: 0.0071 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [110/350] - Time: 4.43s
Train Loss: 0.1288 | Val Loss: 9.0384
Train Acc: 0.9742 | Val Acc: 0.2886
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.784    Count 2: 0.238    Count 3: 0.352    Count 4: 0.229    Count 5: 0.431  
  Count 6: 0.102    Count 7: 0.010    Count 8: 0.131    Count 9: 0.122    Count 10: 0.136  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_109.pth
Epoch [110] Batch [0/13] Loss: 0.0014 LR: 0.000100
Epoch [110] Batch [10/13] Loss: 0.0085 LR: 0.000100

Epoch [111/350] - Time: 4.53s
Train Loss: 0.0496 | Val Loss: 9.9024
Train Acc: 0.9897 | Val Acc: 0.2812
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.735    Count 2: 0.294    Count 3: 0.287    Count 4: 0.305    Count 5: 0.490  
  Count 6: 0.082    Count 7: 0.000    Count 8: 0.101    Count 9: 0.122    Count 10: 0.045  
Epoch [111] Batch [0/13] Loss: 0.1066 LR: 0.000100
Epoch [111] Batch [10/13] Loss: 0.0843 LR: 0.000100

Epoch [112/350] - Time: 4.40s
Train Loss: 0.0761 | Val Loss: 8.1660
Train Acc: 0.9742 | Val Acc: 0.3194
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.784    Count 2: 0.214    Count 3: 0.296    Count 4: 0.200    Count 5: 0.471  
  Count 6: 0.347    Count 7: 0.021    Count 8: 0.212    Count 9: 0.178    Count 10: 0.170  
Epoch [112] Batch [0/13] Loss: 0.0423 LR: 0.000100
Epoch [112] Batch [10/13] Loss: 0.0397 LR: 0.000100

Epoch [113/350] - Time: 4.44s
Train Loss: 0.0294 | Val Loss: 9.1074
Train Acc: 0.9897 | Val Acc: 0.3017
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.222    Count 3: 0.259    Count 4: 0.229    Count 5: 0.500  
  Count 6: 0.173    Count 7: 0.000    Count 8: 0.162    Count 9: 0.122    Count 10: 0.091  
Epoch [113] Batch [0/13] Loss: 0.0030 LR: 0.000100
Epoch [113] Batch [10/13] Loss: 0.0017 LR: 0.000100

Epoch [114/350] - Time: 4.34s
Train Loss: 0.0042 | Val Loss: 8.4995
Train Acc: 1.0000 | Val Acc: 0.3138
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.741    Count 2: 0.302    Count 3: 0.213    Count 4: 0.343    Count 5: 0.559  
  Count 6: 0.224    Count 7: 0.000    Count 8: 0.202    Count 9: 0.122    Count 10: 0.114  
Epoch [114] Batch [0/13] Loss: 0.0016 LR: 0.000100
Epoch [114] Batch [10/13] Loss: 0.0003 LR: 0.000100

Epoch [115/350] - Time: 4.71s
Train Loss: 0.0604 | Val Loss: 9.1022
Train Acc: 0.9948 | Val Acc: 0.2952
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.679    Count 2: 0.325    Count 3: 0.231    Count 4: 0.390    Count 5: 0.471  
  Count 6: 0.153    Count 7: 0.000    Count 8: 0.162    Count 9: 0.133    Count 10: 0.102  
Epoch [115] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [115] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [116/350] - Time: 4.46s
Train Loss: 0.0020 | Val Loss: 9.2164
Train Acc: 1.0000 | Val Acc: 0.3045
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.704    Count 2: 0.278    Count 3: 0.343    Count 4: 0.314    Count 5: 0.451  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.182    Count 9: 0.167    Count 10: 0.114  
Epoch [116] Batch [0/13] Loss: 0.0008 LR: 0.000100
Epoch [116] Batch [10/13] Loss: 0.0012 LR: 0.000100

Epoch [117/350] - Time: 4.47s
Train Loss: 0.0008 | Val Loss: 9.7181
Train Acc: 1.0000 | Val Acc: 0.3110
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.772    Count 2: 0.246    Count 3: 0.343    Count 4: 0.324    Count 5: 0.441  
  Count 6: 0.265    Count 7: 0.000    Count 8: 0.182    Count 9: 0.156    Count 10: 0.045  
Epoch [117] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [117] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [118/350] - Time: 4.51s
Train Loss: 0.0019 | Val Loss: 9.3276
Train Acc: 1.0000 | Val Acc: 0.3101
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.704    Count 2: 0.341    Count 3: 0.278    Count 4: 0.390    Count 5: 0.431  
  Count 6: 0.265    Count 7: 0.000    Count 8: 0.162    Count 9: 0.144    Count 10: 0.068  
Epoch [118] Batch [0/13] Loss: 0.0004 LR: 0.000100
Epoch [118] Batch [10/13] Loss: 0.0169 LR: 0.000100

Epoch [119/350] - Time: 4.45s
Train Loss: 0.0026 | Val Loss: 9.6882
Train Acc: 1.0000 | Val Acc: 0.2998
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.222    Count 3: 0.361    Count 4: 0.171    Count 5: 0.549  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.192    Count 9: 0.178    Count 10: 0.057  
Epoch [119] Batch [0/13] Loss: 0.0007 LR: 0.000100
Epoch [119] Batch [10/13] Loss: 0.0005 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [120/350] - Time: 4.47s
Train Loss: 0.0063 | Val Loss: 9.0473
Train Acc: 0.9948 | Val Acc: 0.3054
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.660    Count 2: 0.230    Count 3: 0.306    Count 4: 0.381    Count 5: 0.441  
  Count 6: 0.316    Count 7: 0.000    Count 8: 0.212    Count 9: 0.156    Count 10: 0.091  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_119.pth
Epoch [120] Batch [0/13] Loss: 0.0003 LR: 0.000100
Epoch [120] Batch [10/13] Loss: 0.0290 LR: 0.000100

Epoch [121/350] - Time: 4.46s
Train Loss: 0.0034 | Val Loss: 9.2643
Train Acc: 1.0000 | Val Acc: 0.3054
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.809    Count 2: 0.190    Count 3: 0.380    Count 4: 0.200    Count 5: 0.441  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.283    Count 9: 0.144    Count 10: 0.057  
Epoch [121] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [121] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [122/350] - Time: 4.43s
Train Loss: 0.0077 | Val Loss: 9.5762
Train Acc: 0.9948 | Val Acc: 0.2942
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.654    Count 2: 0.429    Count 3: 0.204    Count 4: 0.410    Count 5: 0.461  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.121    Count 9: 0.133    Count 10: 0.125  
Epoch [122] Batch [0/13] Loss: 0.0021 LR: 0.000100
Epoch [122] Batch [10/13] Loss: 0.0005 LR: 0.000100

Epoch [123/350] - Time: 4.71s
Train Loss: 0.0268 | Val Loss: 9.5630
Train Acc: 0.9897 | Val Acc: 0.3073
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.230    Count 3: 0.380    Count 4: 0.248    Count 5: 0.382  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.141    Count 9: 0.122    Count 10: 0.125  
Epoch [123] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [123] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [124/350] - Time: 4.43s
Train Loss: 0.0325 | Val Loss: 9.3142
Train Acc: 0.9948 | Val Acc: 0.3119
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.246    Count 3: 0.352    Count 4: 0.314    Count 5: 0.412  
  Count 6: 0.122    Count 7: 0.000    Count 8: 0.141    Count 9: 0.122    Count 10: 0.136  
Epoch [124] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [124] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [125/350] - Time: 4.50s
Train Loss: 0.0037 | Val Loss: 8.5746
Train Acc: 1.0000 | Val Acc: 0.3305
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.270    Count 3: 0.333    Count 4: 0.305    Count 5: 0.569  
  Count 6: 0.163    Count 7: 0.000    Count 8: 0.192    Count 9: 0.122    Count 10: 0.136  
Epoch [125] Batch [0/13] Loss: 0.0385 LR: 0.000100
Epoch [125] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [126/350] - Time: 4.41s
Train Loss: 0.0037 | Val Loss: 9.1612
Train Acc: 1.0000 | Val Acc: 0.3184
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.302    Count 3: 0.287    Count 4: 0.371    Count 5: 0.451  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.162    Count 9: 0.122    Count 10: 0.136  
Epoch [126] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [126] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [127/350] - Time: 4.38s
Train Loss: 0.0007 | Val Loss: 9.4154
Train Acc: 1.0000 | Val Acc: 0.3138
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.310    Count 3: 0.241    Count 4: 0.352    Count 5: 0.441  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.192    Count 9: 0.122    Count 10: 0.136  
Epoch [127] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [127] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [128/350] - Time: 4.42s
Train Loss: 0.0002 | Val Loss: 9.3582
Train Acc: 1.0000 | Val Acc: 0.3054
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.270    Count 3: 0.315    Count 4: 0.210    Count 5: 0.441  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.152    Count 9: 0.133    Count 10: 0.148  
Epoch [128] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [128] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [129/350] - Time: 4.50s
Train Loss: 0.0010 | Val Loss: 9.2070
Train Acc: 1.0000 | Val Acc: 0.3277
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.302    Count 3: 0.259    Count 4: 0.410    Count 5: 0.422  
  Count 6: 0.235    Count 7: 0.000    Count 8: 0.192    Count 9: 0.122    Count 10: 0.170  
Epoch [129] Batch [0/13] Loss: 0.0025 LR: 0.000100
Epoch [129] Batch [10/13] Loss: 0.0002 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [130/350] - Time: 4.51s
Train Loss: 0.0131 | Val Loss: 9.5588
Train Acc: 0.9948 | Val Acc: 0.3138
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.262    Count 3: 0.324    Count 4: 0.371    Count 5: 0.353  
  Count 6: 0.173    Count 7: 0.010    Count 8: 0.172    Count 9: 0.144    Count 10: 0.136  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_129.pth
Epoch [130] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [130] Batch [10/13] Loss: 0.0058 LR: 0.000100

Epoch [131/350] - Time: 4.40s
Train Loss: 0.0008 | Val Loss: 9.7596
Train Acc: 1.0000 | Val Acc: 0.3101
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.270    Count 3: 0.352    Count 4: 0.267    Count 5: 0.451  
  Count 6: 0.153    Count 7: 0.000    Count 8: 0.162    Count 9: 0.167    Count 10: 0.148  
Epoch [131] Batch [0/13] Loss: 0.0008 LR: 0.000100
Epoch [131] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [132/350] - Time: 4.89s
Train Loss: 0.0006 | Val Loss: 9.3676
Train Acc: 1.0000 | Val Acc: 0.3184
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.294    Count 3: 0.352    Count 4: 0.314    Count 5: 0.441  
  Count 6: 0.173    Count 7: 0.000    Count 8: 0.131    Count 9: 0.133    Count 10: 0.114  
Epoch [132] Batch [0/13] Loss: 0.0006 LR: 0.000100
Epoch [132] Batch [10/13] Loss: 0.0007 LR: 0.000100

Epoch [133/350] - Time: 4.57s
Train Loss: 0.0006 | Val Loss: 10.2091
Train Acc: 1.0000 | Val Acc: 0.3119
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.222    Count 3: 0.315    Count 4: 0.238    Count 5: 0.343  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.323    Count 9: 0.144    Count 10: 0.068  
Epoch [133] Batch [0/13] Loss: 0.0048 LR: 0.000100
Epoch [133] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [134/350] - Time: 4.44s
Train Loss: 0.0019 | Val Loss: 9.6997
Train Acc: 1.0000 | Val Acc: 0.3184
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.728    Count 2: 0.270    Count 3: 0.315    Count 4: 0.162    Count 5: 0.559  
  Count 6: 0.316    Count 7: 0.000    Count 8: 0.343    Count 9: 0.122    Count 10: 0.068  
Epoch [134] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [134] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [135/350] - Time: 4.39s
Train Loss: 0.0015 | Val Loss: 9.7755
Train Acc: 1.0000 | Val Acc: 0.3045
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.294    Count 3: 0.352    Count 4: 0.286    Count 5: 0.480  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.141    Count 9: 0.122    Count 10: 0.080  
Epoch [135] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [135] Batch [10/13] Loss: 0.0008 LR: 0.000100

Epoch [136/350] - Time: 4.48s
Train Loss: 0.0005 | Val Loss: 8.9309
Train Acc: 1.0000 | Val Acc: 0.3212
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.772    Count 2: 0.246    Count 3: 0.315    Count 4: 0.286    Count 5: 0.441  
  Count 6: 0.337    Count 7: 0.000    Count 8: 0.222    Count 9: 0.144    Count 10: 0.136  
Epoch [136] Batch [0/13] Loss: 0.0153 LR: 0.000100
Epoch [136] Batch [10/13] Loss: 0.0049 LR: 0.000100

Epoch [137/350] - Time: 4.45s
Train Loss: 0.0018 | Val Loss: 9.3886
Train Acc: 1.0000 | Val Acc: 0.3147
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.716    Count 2: 0.381    Count 3: 0.204    Count 4: 0.448    Count 5: 0.382  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.141    Count 9: 0.144    Count 10: 0.136  
Epoch [137] Batch [0/13] Loss: 0.0023 LR: 0.000100
Epoch [137] Batch [10/13] Loss: 0.0032 LR: 0.000100

Epoch [138/350] - Time: 4.49s
Train Loss: 0.0043 | Val Loss: 9.8011
Train Acc: 1.0000 | Val Acc: 0.2980
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.704    Count 2: 0.238    Count 3: 0.324    Count 4: 0.152    Count 5: 0.608  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.253    Count 9: 0.156    Count 10: 0.045  
Epoch [138] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [138] Batch [10/13] Loss: 0.0099 LR: 0.000100

Epoch [139/350] - Time: 4.39s
Train Loss: 0.0065 | Val Loss: 9.0367
Train Acc: 0.9948 | Val Acc: 0.3315
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.759    Count 2: 0.341    Count 3: 0.250    Count 4: 0.276    Count 5: 0.500  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.273    Count 9: 0.156    Count 10: 0.148  
Epoch [139] Batch [0/13] Loss: 0.0028 LR: 0.000100
Epoch [139] Batch [10/13] Loss: 0.1727 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [140/350] - Time: 4.80s
Train Loss: 0.0191 | Val Loss: 10.1108
Train Acc: 0.9897 | Val Acc: 0.3128
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.294    Count 3: 0.324    Count 4: 0.286    Count 5: 0.441  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.192    Count 9: 0.133    Count 10: 0.091  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_139.pth
Epoch [140] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [140] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [141/350] - Time: 4.48s
Train Loss: 0.0234 | Val Loss: 9.8507
Train Acc: 0.9897 | Val Acc: 0.3147
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.325    Count 3: 0.306    Count 4: 0.286    Count 5: 0.490  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.222    Count 9: 0.133    Count 10: 0.080  
Epoch [141] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [141] Batch [10/13] Loss: 0.1442 LR: 0.000100

Epoch [142/350] - Time: 4.53s
Train Loss: 0.2364 | Val Loss: 9.8975
Train Acc: 0.9691 | Val Acc: 0.3101
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.278    Count 3: 0.296    Count 4: 0.171    Count 5: 0.471  
  Count 6: 0.153    Count 7: 0.000    Count 8: 0.202    Count 9: 0.178    Count 10: 0.148  
Epoch [142] Batch [0/13] Loss: 0.0003 LR: 0.000100
Epoch [142] Batch [10/13] Loss: 0.0026 LR: 0.000100

Epoch [143/350] - Time: 4.51s
Train Loss: 0.1593 | Val Loss: 8.8292
Train Acc: 0.9794 | Val Acc: 0.3156
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.722    Count 2: 0.365    Count 3: 0.213    Count 4: 0.400    Count 5: 0.412  
  Count 6: 0.316    Count 7: 0.000    Count 8: 0.121    Count 9: 0.122    Count 10: 0.170  
Epoch [143] Batch [0/13] Loss: 0.0027 LR: 0.000100
Epoch [143] Batch [10/13] Loss: 0.0003 LR: 0.000100

Epoch [144/350] - Time: 4.53s
Train Loss: 0.0012 | Val Loss: 9.5718
Train Acc: 1.0000 | Val Acc: 0.3156
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.286    Count 3: 0.315    Count 4: 0.219    Count 5: 0.578  
  Count 6: 0.122    Count 7: 0.000    Count 8: 0.182    Count 9: 0.144    Count 10: 0.125  
Epoch [144] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [144] Batch [10/13] Loss: 0.0002 LR: 0.000100

Epoch [145/350] - Time: 4.45s
Train Loss: 0.0018 | Val Loss: 9.2939
Train Acc: 1.0000 | Val Acc: 0.3156
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.765    Count 2: 0.365    Count 3: 0.213    Count 4: 0.476    Count 5: 0.294  
  Count 6: 0.184    Count 7: 0.000    Count 8: 0.242    Count 9: 0.167    Count 10: 0.102  
Epoch [145] Batch [0/13] Loss: 0.0048 LR: 0.000100
Epoch [145] Batch [10/13] Loss: 0.0003 LR: 0.000100

Epoch [146/350] - Time: 4.44s
Train Loss: 0.0012 | Val Loss: 10.2221
Train Acc: 1.0000 | Val Acc: 0.3175
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.765    Count 2: 0.198    Count 3: 0.370    Count 4: 0.095    Count 5: 0.647  
  Count 6: 0.184    Count 7: 0.000    Count 8: 0.374    Count 9: 0.167    Count 10: 0.068  
Epoch [146] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [146] Batch [10/13] Loss: 0.0966 LR: 0.000100

Epoch [147/350] - Time: 4.48s
Train Loss: 0.0164 | Val Loss: 9.5524
Train Acc: 0.9897 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.341    Count 3: 0.204    Count 4: 0.457    Count 5: 0.255  
  Count 6: 0.184    Count 7: 0.000    Count 8: 0.152    Count 9: 0.133    Count 10: 0.102  
Epoch [147] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [147] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [148/350] - Time: 4.82s
Train Loss: 0.0019 | Val Loss: 9.6238
Train Acc: 1.0000 | Val Acc: 0.3222
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.802    Count 2: 0.246    Count 3: 0.370    Count 4: 0.114    Count 5: 0.647  
  Count 6: 0.163    Count 7: 0.000    Count 8: 0.273    Count 9: 0.156    Count 10: 0.114  
Epoch [148] Batch [0/13] Loss: 0.0764 LR: 0.000100
Epoch [148] Batch [10/13] Loss: 0.0036 LR: 0.000100

Epoch [149/350] - Time: 4.53s
Train Loss: 0.0118 | Val Loss: 9.6605
Train Acc: 0.9948 | Val Acc: 0.3240
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.310    Count 3: 0.259    Count 4: 0.190    Count 5: 0.520  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.273    Count 9: 0.156    Count 10: 0.114  
Epoch [149] Batch [0/13] Loss: 0.0003 LR: 0.000100
Epoch [149] Batch [10/13] Loss: 0.0001 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [150/350] - Time: 4.47s
Train Loss: 0.0129 | Val Loss: 10.1622
Train Acc: 0.9948 | Val Acc: 0.3212
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.198    Count 3: 0.333    Count 4: 0.162    Count 5: 0.510  
  Count 6: 0.255    Count 7: 0.010    Count 8: 0.364    Count 9: 0.167    Count 10: 0.102  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_149.pth
Epoch [150] Batch [0/13] Loss: 0.0019 LR: 0.000100
Epoch [150] Batch [10/13] Loss: 0.0007 LR: 0.000100

Epoch [151/350] - Time: 4.37s
Train Loss: 0.0044 | Val Loss: 10.7967
Train Acc: 0.9948 | Val Acc: 0.2914
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.302    Count 3: 0.222    Count 4: 0.419    Count 5: 0.255  
  Count 6: 0.122    Count 7: 0.010    Count 8: 0.152    Count 9: 0.122    Count 10: 0.068  
Epoch [151] Batch [0/13] Loss: 0.0039 LR: 0.000100
Epoch [151] Batch [10/13] Loss: 0.0007 LR: 0.000100

Epoch [152/350] - Time: 4.42s
Train Loss: 0.0376 | Val Loss: 10.2957
Train Acc: 0.9948 | Val Acc: 0.2989
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.537    Count 2: 0.254    Count 3: 0.315    Count 4: 0.067    Count 5: 0.637  
  Count 6: 0.245    Count 7: 0.000    Count 8: 0.424    Count 9: 0.200    Count 10: 0.136  
Epoch [152] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [152] Batch [10/13] Loss: 0.1069 LR: 0.000100

Epoch [153/350] - Time: 4.43s
Train Loss: 0.0275 | Val Loss: 10.4801
Train Acc: 0.9897 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.214    Count 3: 0.370    Count 4: 0.143    Count 5: 0.529  
  Count 6: 0.163    Count 7: 0.000    Count 8: 0.121    Count 9: 0.122    Count 10: 0.148  
Epoch [153] Batch [0/13] Loss: 0.0011 LR: 0.000100
Epoch [153] Batch [10/13] Loss: 0.0003 LR: 0.000100

Epoch [154/350] - Time: 4.41s
Train Loss: 0.0010 | Val Loss: 9.1557
Train Acc: 1.0000 | Val Acc: 0.3305
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.728    Count 2: 0.413    Count 3: 0.241    Count 4: 0.524    Count 5: 0.324  
  Count 6: 0.357    Count 7: 0.010    Count 8: 0.091    Count 9: 0.156    Count 10: 0.136  
Epoch [154] Batch [0/13] Loss: 0.7487 LR: 0.000100
Epoch [154] Batch [10/13] Loss: 0.0349 LR: 0.000100

Epoch [155/350] - Time: 4.46s
Train Loss: 0.0849 | Val Loss: 10.1761
Train Acc: 0.9897 | Val Acc: 0.2933
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.642    Count 2: 0.349    Count 3: 0.343    Count 4: 0.105    Count 5: 0.608  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.192    Count 9: 0.178    Count 10: 0.091  
Epoch [155] Batch [0/13] Loss: 0.0017 LR: 0.000100
Epoch [155] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [156/350] - Time: 4.89s
Train Loss: 0.0304 | Val Loss: 10.6541
Train Acc: 0.9948 | Val Acc: 0.2998
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.586    Count 2: 0.381    Count 3: 0.194    Count 4: 0.381    Count 5: 0.520  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.263    Count 9: 0.144    Count 10: 0.011  
Epoch [156] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [156] Batch [10/13] Loss: 0.0002 LR: 0.000100

Epoch [157/350] - Time: 4.51s
Train Loss: 0.0006 | Val Loss: 10.0442
Train Acc: 1.0000 | Val Acc: 0.3156
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.246    Count 3: 0.278    Count 4: 0.362    Count 5: 0.422  
  Count 6: 0.163    Count 7: 0.000    Count 8: 0.242    Count 9: 0.133    Count 10: 0.057  
Epoch [157] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [157] Batch [10/13] Loss: 0.0008 LR: 0.000100

Epoch [158/350] - Time: 4.40s
Train Loss: 0.0011 | Val Loss: 10.0889
Train Acc: 1.0000 | Val Acc: 0.3128
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.310    Count 3: 0.269    Count 4: 0.200    Count 5: 0.559  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.293    Count 9: 0.133    Count 10: 0.034  
Epoch [158] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [158] Batch [10/13] Loss: 0.0005 LR: 0.000100

Epoch [159/350] - Time: 4.48s
Train Loss: 0.0086 | Val Loss: 10.6341
Train Acc: 0.9948 | Val Acc: 0.3026
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.753    Count 2: 0.365    Count 3: 0.194    Count 4: 0.476    Count 5: 0.392  
  Count 6: 0.153    Count 7: 0.000    Count 8: 0.162    Count 9: 0.133    Count 10: 0.034  
Epoch [159] Batch [0/13] Loss: 0.0005 LR: 0.000100
Epoch [159] Batch [10/13] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [160/350] - Time: 4.32s
Train Loss: 0.0020 | Val Loss: 10.3848
Train Acc: 1.0000 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.852    Count 2: 0.325    Count 3: 0.222    Count 4: 0.352    Count 5: 0.422  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.182    Count 9: 0.133    Count 10: 0.034  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_159.pth
Epoch [160] Batch [0/13] Loss: 0.0006 LR: 0.000100
Epoch [160] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [161/350] - Time: 4.34s
Train Loss: 0.0010 | Val Loss: 10.2763
Train Acc: 1.0000 | Val Acc: 0.3156
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.302    Count 3: 0.278    Count 4: 0.171    Count 5: 0.608  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.263    Count 9: 0.144    Count 10: 0.057  
Epoch [161] Batch [0/13] Loss: 0.0011 LR: 0.000100
Epoch [161] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [162/350] - Time: 4.47s
Train Loss: 0.0003 | Val Loss: 11.0667
Train Acc: 1.0000 | Val Acc: 0.2933
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.278    Count 3: 0.269    Count 4: 0.124    Count 5: 0.510  
  Count 6: 0.082    Count 7: 0.000    Count 8: 0.222    Count 9: 0.133    Count 10: 0.023  
Epoch [162] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [162] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [163/350] - Time: 4.40s
Train Loss: 0.0002 | Val Loss: 10.9477
Train Acc: 1.0000 | Val Acc: 0.3007
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.238    Count 3: 0.306    Count 4: 0.124    Count 5: 0.520  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.242    Count 9: 0.133    Count 10: 0.011  
Epoch [163] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [163] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [164/350] - Time: 4.81s
Train Loss: 0.0002 | Val Loss: 10.6260
Train Acc: 1.0000 | Val Acc: 0.3119
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.270    Count 3: 0.269    Count 4: 0.324    Count 5: 0.451  
  Count 6: 0.163    Count 7: 0.000    Count 8: 0.192    Count 9: 0.133    Count 10: 0.045  
Epoch [164] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [164] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [165/350] - Time: 4.47s
Train Loss: 0.0001 | Val Loss: 10.7558
Train Acc: 1.0000 | Val Acc: 0.3175
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.317    Count 3: 0.250    Count 4: 0.495    Count 5: 0.363  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.172    Count 9: 0.133    Count 10: 0.045  
Epoch [165] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [165] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [166/350] - Time: 4.36s
Train Loss: 0.0004 | Val Loss: 9.8089
Train Acc: 1.0000 | Val Acc: 0.3268
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.294    Count 3: 0.278    Count 4: 0.333    Count 5: 0.529  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.313    Count 9: 0.144    Count 10: 0.102  
Epoch [166] Batch [0/13] Loss: 0.0006 LR: 0.000100
Epoch [166] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [167/350] - Time: 4.50s
Train Loss: 0.0002 | Val Loss: 10.3746
Train Acc: 1.0000 | Val Acc: 0.3212
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.802    Count 2: 0.333    Count 3: 0.250    Count 4: 0.429    Count 5: 0.490  
  Count 6: 0.122    Count 7: 0.000    Count 8: 0.222    Count 9: 0.133    Count 10: 0.057  
Epoch [167] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [167] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [168/350] - Time: 4.32s
Train Loss: 0.0001 | Val Loss: 10.5235
Train Acc: 1.0000 | Val Acc: 0.3138
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.784    Count 2: 0.317    Count 3: 0.250    Count 4: 0.419    Count 5: 0.471  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.212    Count 9: 0.133    Count 10: 0.045  
Epoch [168] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [168] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [169/350] - Time: 4.50s
Train Loss: 0.0001 | Val Loss: 10.6680
Train Acc: 1.0000 | Val Acc: 0.3147
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.317    Count 3: 0.259    Count 4: 0.400    Count 5: 0.451  
  Count 6: 0.173    Count 7: 0.000    Count 8: 0.212    Count 9: 0.133    Count 10: 0.045  
Epoch [169] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [169] Batch [10/13] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [170/350] - Time: 4.39s
Train Loss: 0.0001 | Val Loss: 10.7961
Train Acc: 1.0000 | Val Acc: 0.3091
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.278    Count 3: 0.287    Count 4: 0.248    Count 5: 0.539  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.222    Count 9: 0.133    Count 10: 0.045  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_169.pth
Epoch [170] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [170] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [171/350] - Time: 4.40s
Train Loss: 0.0002 | Val Loss: 10.9336
Train Acc: 1.0000 | Val Acc: 0.3017
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.270    Count 3: 0.287    Count 4: 0.133    Count 5: 0.588  
  Count 6: 0.122    Count 7: 0.000    Count 8: 0.242    Count 9: 0.133    Count 10: 0.045  
Epoch [171] Batch [0/13] Loss: 0.0004 LR: 0.000100
Epoch [171] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [172/350] - Time: 4.83s
Train Loss: 0.0001 | Val Loss: 10.6611
Train Acc: 1.0000 | Val Acc: 0.3101
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.270    Count 3: 0.278    Count 4: 0.152    Count 5: 0.569  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.293    Count 9: 0.133    Count 10: 0.045  
Epoch [172] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [172] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [173/350] - Time: 4.52s
Train Loss: 0.0001 | Val Loss: 11.1755
Train Acc: 1.0000 | Val Acc: 0.2970
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.278    Count 3: 0.333    Count 4: 0.133    Count 5: 0.539  
  Count 6: 0.082    Count 7: 0.000    Count 8: 0.172    Count 9: 0.133    Count 10: 0.057  
Epoch [173] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [173] Batch [10/13] Loss: 0.0006 LR: 0.000100

Epoch [174/350] - Time: 4.30s
Train Loss: 0.0415 | Val Loss: 10.4642
Train Acc: 0.9948 | Val Acc: 0.3128
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.784    Count 2: 0.270    Count 3: 0.333    Count 4: 0.152    Count 5: 0.676  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.253    Count 9: 0.144    Count 10: 0.080  
Epoch [174] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [174] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [175/350] - Time: 4.40s
Train Loss: 0.0004 | Val Loss: 11.1036
Train Acc: 1.0000 | Val Acc: 0.3045
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.222    Count 3: 0.361    Count 4: 0.114    Count 5: 0.578  
  Count 6: 0.082    Count 7: 0.000    Count 8: 0.212    Count 9: 0.133    Count 10: 0.034  
Epoch [175] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [175] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [176/350] - Time: 4.46s
Train Loss: 0.0611 | Val Loss: 11.1506
Train Acc: 0.9948 | Val Acc: 0.3222
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.270    Count 3: 0.278    Count 4: 0.410    Count 5: 0.422  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.192    Count 9: 0.133    Count 10: 0.068  
Epoch [176] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [176] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [177/350] - Time: 4.56s
Train Loss: 0.0006 | Val Loss: 11.2621
Train Acc: 1.0000 | Val Acc: 0.3184
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.286    Count 3: 0.278    Count 4: 0.371    Count 5: 0.431  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.212    Count 9: 0.144    Count 10: 0.057  
Epoch [177] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [177] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [178/350] - Time: 4.46s
Train Loss: 0.0003 | Val Loss: 10.9618
Train Acc: 1.0000 | Val Acc: 0.3138
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.802    Count 2: 0.262    Count 3: 0.231    Count 4: 0.324    Count 5: 0.490  
  Count 6: 0.173    Count 7: 0.000    Count 8: 0.313    Count 9: 0.156    Count 10: 0.034  
Epoch [178] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [178] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [179/350] - Time: 4.41s
Train Loss: 0.0002 | Val Loss: 11.4825
Train Acc: 1.0000 | Val Acc: 0.3073
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.753    Count 2: 0.294    Count 3: 0.167    Count 4: 0.343    Count 5: 0.471  
  Count 6: 0.224    Count 7: 0.000    Count 8: 0.293    Count 9: 0.167    Count 10: 0.034  
Epoch [179] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [179] Batch [10/13] Loss: 0.0058 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [180/350] - Time: 4.84s
Train Loss: 0.0008 | Val Loss: 11.5130
Train Acc: 1.0000 | Val Acc: 0.3035
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.278    Count 3: 0.278    Count 4: 0.181    Count 5: 0.578  
  Count 6: 0.082    Count 7: 0.000    Count 8: 0.232    Count 9: 0.167    Count 10: 0.034  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_179.pth
Epoch [180] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [180] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [181/350] - Time: 4.40s
Train Loss: 0.0003 | Val Loss: 11.1612
Train Acc: 1.0000 | Val Acc: 0.2924
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.747    Count 2: 0.254    Count 3: 0.509    Count 4: 0.133    Count 5: 0.451  
  Count 6: 0.071    Count 7: 0.000    Count 8: 0.131    Count 9: 0.178    Count 10: 0.114  
Epoch [181] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [181] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [182/350] - Time: 4.45s
Train Loss: 0.0297 | Val Loss: 10.5631
Train Acc: 0.9948 | Val Acc: 0.3296
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.772    Count 2: 0.317    Count 3: 0.306    Count 4: 0.210    Count 5: 0.529  
  Count 6: 0.133    Count 7: 0.010    Count 8: 0.414    Count 9: 0.189    Count 10: 0.091  
Epoch [182] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [182] Batch [10/13] Loss: 0.0003 LR: 0.000100

Epoch [183/350] - Time: 4.48s
Train Loss: 0.0004 | Val Loss: 10.7109
Train Acc: 1.0000 | Val Acc: 0.3119
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.214    Count 3: 0.352    Count 4: 0.200    Count 5: 0.500  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.333    Count 9: 0.133    Count 10: 0.034  
Epoch [183] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [183] Batch [10/13] Loss: 0.0003 LR: 0.000100

Epoch [184/350] - Time: 4.52s
Train Loss: 0.0018 | Val Loss: 11.0574
Train Acc: 1.0000 | Val Acc: 0.3082
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.270    Count 3: 0.352    Count 4: 0.200    Count 5: 0.480  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.313    Count 9: 0.122    Count 10: 0.045  
Epoch [184] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [184] Batch [10/13] Loss: 0.0100 LR: 0.000100

Epoch [185/350] - Time: 4.42s
Train Loss: 0.0035 | Val Loss: 11.0780
Train Acc: 1.0000 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.728    Count 2: 0.270    Count 3: 0.398    Count 4: 0.124    Count 5: 0.549  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.323    Count 9: 0.167    Count 10: 0.045  
Epoch [185] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [185] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [186/350] - Time: 4.43s
Train Loss: 0.0557 | Val Loss: 11.0653
Train Acc: 0.9845 | Val Acc: 0.3128
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.317    Count 3: 0.231    Count 4: 0.371    Count 5: 0.392  
  Count 6: 0.184    Count 7: 0.000    Count 8: 0.222    Count 9: 0.133    Count 10: 0.034  
Epoch [186] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [186] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [187/350] - Time: 4.35s
Train Loss: 0.0093 | Val Loss: 11.9705
Train Acc: 0.9948 | Val Acc: 0.2933
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.175    Count 3: 0.343    Count 4: 0.124    Count 5: 0.353  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.404    Count 9: 0.167    Count 10: 0.011  
Epoch [187] Batch [0/13] Loss: 0.1479 LR: 0.000100
Epoch [187] Batch [10/13] Loss: 0.1063 LR: 0.000100

Epoch [188/350] - Time: 4.75s
Train Loss: 0.2242 | Val Loss: 10.7601
Train Acc: 0.9742 | Val Acc: 0.2998
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.444    Count 2: 0.516    Count 3: 0.102    Count 4: 0.314    Count 5: 0.559  
  Count 6: 0.235    Count 7: 0.000    Count 8: 0.404    Count 9: 0.178    Count 10: 0.057  
Epoch [188] Batch [0/13] Loss: 0.3625 LR: 0.000100
Epoch [188] Batch [10/13] Loss: 0.0006 LR: 0.000100

Epoch [189/350] - Time: 4.48s
Train Loss: 0.0555 | Val Loss: 10.0511
Train Acc: 0.9897 | Val Acc: 0.3017
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.222    Count 3: 0.361    Count 4: 0.133    Count 5: 0.431  
  Count 6: 0.051    Count 7: 0.010    Count 8: 0.212    Count 9: 0.167    Count 10: 0.114  
Epoch [189] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [189] Batch [10/13] Loss: 0.0002 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [190/350] - Time: 4.44s
Train Loss: 0.0012 | Val Loss: 9.6659
Train Acc: 1.0000 | Val Acc: 0.3268
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.302    Count 3: 0.370    Count 4: 0.152    Count 5: 0.608  
  Count 6: 0.112    Count 7: 0.010    Count 8: 0.232    Count 9: 0.133    Count 10: 0.125  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_189.pth
Epoch [190] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [190] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [191/350] - Time: 4.41s
Train Loss: 0.0082 | Val Loss: 10.3176
Train Acc: 0.9948 | Val Acc: 0.3166
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.246    Count 3: 0.352    Count 4: 0.257    Count 5: 0.441  
  Count 6: 0.102    Count 7: 0.010    Count 8: 0.192    Count 9: 0.133    Count 10: 0.102  
Epoch [191] Batch [0/13] Loss: 0.0053 LR: 0.000100
Epoch [191] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [192/350] - Time: 4.42s
Train Loss: 0.0429 | Val Loss: 10.6519
Train Acc: 0.9845 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.735    Count 2: 0.405    Count 3: 0.204    Count 4: 0.200    Count 5: 0.608  
  Count 6: 0.082    Count 7: 0.000    Count 8: 0.283    Count 9: 0.156    Count 10: 0.045  
Epoch [192] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [192] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [193/350] - Time: 4.45s
Train Loss: 0.0106 | Val Loss: 10.5541
Train Acc: 0.9948 | Val Acc: 0.3203
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.741    Count 2: 0.246    Count 3: 0.259    Count 4: 0.219    Count 5: 0.529  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.364    Count 9: 0.189    Count 10: 0.068  
Epoch [193] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [193] Batch [10/13] Loss: 0.0009 LR: 0.000100

Epoch [194/350] - Time: 4.44s
Train Loss: 0.0004 | Val Loss: 10.3006
Train Acc: 1.0000 | Val Acc: 0.3194
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.747    Count 2: 0.294    Count 3: 0.213    Count 4: 0.410    Count 5: 0.412  
  Count 6: 0.306    Count 7: 0.000    Count 8: 0.222    Count 9: 0.189    Count 10: 0.091  
Epoch [194] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [194] Batch [10/13] Loss: 0.0018 LR: 0.000100

Epoch [195/350] - Time: 4.40s
Train Loss: 0.0531 | Val Loss: 11.0426
Train Acc: 0.9897 | Val Acc: 0.2849
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.238    Count 3: 0.269    Count 4: 0.086    Count 5: 0.431  
  Count 6: 0.061    Count 7: 0.010    Count 8: 0.212    Count 9: 0.178    Count 10: 0.091  
Epoch [195] Batch [0/13] Loss: 0.0251 LR: 0.000100
Epoch [195] Batch [10/13] Loss: 0.0007 LR: 0.000100

Epoch [196/350] - Time: 4.39s
Train Loss: 0.0040 | Val Loss: 10.9369
Train Acc: 1.0000 | Val Acc: 0.2998
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.698    Count 2: 0.365    Count 3: 0.259    Count 4: 0.390    Count 5: 0.402  
  Count 6: 0.173    Count 7: 0.000    Count 8: 0.202    Count 9: 0.133    Count 10: 0.045  
Epoch [196] Batch [0/13] Loss: 0.0009 LR: 0.000100
Epoch [196] Batch [10/13] Loss: 0.0017 LR: 0.000100

Epoch [197/350] - Time: 4.68s
Train Loss: 0.0743 | Val Loss: 11.0894
Train Acc: 0.9897 | Val Acc: 0.3250
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.728    Count 2: 0.405    Count 3: 0.306    Count 4: 0.438    Count 5: 0.500  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.152    Count 9: 0.133    Count 10: 0.045  
Epoch [197] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [197] Batch [10/13] Loss: 0.0007 LR: 0.000100

Epoch [198/350] - Time: 4.53s
Train Loss: 0.0168 | Val Loss: 10.2744
Train Acc: 0.9948 | Val Acc: 0.3389
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.778    Count 2: 0.341    Count 3: 0.278    Count 4: 0.143    Count 5: 0.588  
  Count 6: 0.224    Count 7: 0.000    Count 8: 0.465    Count 9: 0.200    Count 10: 0.045  
Epoch [198] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [198] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [199/350] - Time: 4.50s
Train Loss: 0.0640 | Val Loss: 11.2536
Train Acc: 0.9845 | Val Acc: 0.2840
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.310    Count 3: 0.315    Count 4: 0.162    Count 5: 0.402  
  Count 6: 0.082    Count 7: 0.000    Count 8: 0.152    Count 9: 0.133    Count 10: 0.034  
Epoch [199] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [199] Batch [10/13] Loss: 0.3699 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [200/350] - Time: 8.16s
Train Loss: 0.0749 | Val Loss: 11.3289
Train Acc: 0.9897 | Val Acc: 0.2691
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.270    Count 3: 0.333    Count 4: 0.171    Count 5: 0.255  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.121    Count 9: 0.133    Count 10: 0.068  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_199.pth
Epoch [200] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [200] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [201/350] - Time: 4.37s
Train Loss: 0.0076 | Val Loss: 10.5892
Train Acc: 0.9948 | Val Acc: 0.2989
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.704    Count 2: 0.262    Count 3: 0.296    Count 4: 0.095    Count 5: 0.490  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.354    Count 9: 0.189    Count 10: 0.114  
Epoch [201] Batch [0/13] Loss: 0.0008 LR: 0.000100
Epoch [201] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [202/350] - Time: 4.47s
Train Loss: 0.0008 | Val Loss: 10.6388
Train Acc: 1.0000 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.716    Count 2: 0.405    Count 3: 0.213    Count 4: 0.562    Count 5: 0.225  
  Count 6: 0.224    Count 7: 0.000    Count 8: 0.141    Count 9: 0.122    Count 10: 0.114  
Epoch [202] Batch [0/13] Loss: 0.0026 LR: 0.000100
Epoch [202] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [203/350] - Time: 4.54s
Train Loss: 0.0278 | Val Loss: 11.1008
Train Acc: 0.9845 | Val Acc: 0.2942
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.772    Count 2: 0.270    Count 3: 0.259    Count 4: 0.067    Count 5: 0.608  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.273    Count 9: 0.222    Count 10: 0.045  
Epoch [203] Batch [0/13] Loss: 0.0004 LR: 0.000100
Epoch [203] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [204/350] - Time: 4.43s
Train Loss: 0.1093 | Val Loss: 10.8906
Train Acc: 0.9794 | Val Acc: 0.3110
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.617    Count 2: 0.492    Count 3: 0.148    Count 4: 0.648    Count 5: 0.176  
  Count 6: 0.347    Count 7: 0.010    Count 8: 0.101    Count 9: 0.144    Count 10: 0.136  
Epoch [204] Batch [0/13] Loss: 0.5805 LR: 0.000100
Epoch [204] Batch [10/13] Loss: 1.0566 LR: 0.000100

Epoch [205/350] - Time: 4.83s
Train Loss: 0.2042 | Val Loss: 10.5717
Train Acc: 0.9691 | Val Acc: 0.3101
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.735    Count 2: 0.341    Count 3: 0.241    Count 4: 0.229    Count 5: 0.578  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.192    Count 9: 0.133    Count 10: 0.125  
Epoch [205] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [205] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [206/350] - Time: 4.33s
Train Loss: 0.0848 | Val Loss: 10.6754
Train Acc: 0.9845 | Val Acc: 0.2961
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.691    Count 2: 0.254    Count 3: 0.306    Count 4: 0.200    Count 5: 0.490  
  Count 6: 0.306    Count 7: 0.000    Count 8: 0.232    Count 9: 0.156    Count 10: 0.034  
Epoch [206] Batch [0/13] Loss: 0.0009 LR: 0.000100
Epoch [206] Batch [10/13] Loss: 0.0007 LR: 0.000100

Epoch [207/350] - Time: 4.51s
Train Loss: 0.0345 | Val Loss: 11.6625
Train Acc: 0.9845 | Val Acc: 0.2709
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.802    Count 2: 0.286    Count 3: 0.250    Count 4: 0.152    Count 5: 0.441  
  Count 6: 0.061    Count 7: 0.000    Count 8: 0.162    Count 9: 0.144    Count 10: 0.023  
Epoch [207] Batch [0/13] Loss: 0.0006 LR: 0.000100
Epoch [207] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [208/350] - Time: 4.49s
Train Loss: 0.0875 | Val Loss: 9.0625
Train Acc: 0.9845 | Val Acc: 0.3287
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.747    Count 2: 0.357    Count 3: 0.213    Count 4: 0.352    Count 5: 0.480  
  Count 6: 0.265    Count 7: 0.000    Count 8: 0.212    Count 9: 0.178    Count 10: 0.170  
Epoch [208] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [208] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [209/350] - Time: 4.48s
Train Loss: 0.0007 | Val Loss: 9.0479
Train Acc: 1.0000 | Val Acc: 0.3156
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.809    Count 2: 0.270    Count 3: 0.269    Count 4: 0.133    Count 5: 0.725  
  Count 6: 0.082    Count 7: 0.000    Count 8: 0.182    Count 9: 0.167    Count 10: 0.182  
Epoch [209] Batch [0/13] Loss: 0.1860 LR: 0.000100
Epoch [209] Batch [10/13] Loss: 0.0014 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [210/350] - Time: 4.50s
Train Loss: 0.0297 | Val Loss: 10.3139
Train Acc: 0.9897 | Val Acc: 0.3184
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.858    Count 2: 0.230    Count 3: 0.222    Count 4: 0.467    Count 5: 0.431  
  Count 6: 0.235    Count 7: 0.000    Count 8: 0.141    Count 9: 0.122    Count 10: 0.102  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_209.pth
Epoch [210] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [210] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [211/350] - Time: 4.50s
Train Loss: 0.0042 | Val Loss: 10.5355
Train Acc: 1.0000 | Val Acc: 0.2998
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.254    Count 3: 0.296    Count 4: 0.352    Count 5: 0.294  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.121    Count 9: 0.122    Count 10: 0.080  
Epoch [211] Batch [0/13] Loss: 0.2117 LR: 0.000100
Epoch [211] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [212/350] - Time: 4.33s
Train Loss: 0.0202 | Val Loss: 10.1386
Train Acc: 0.9948 | Val Acc: 0.3147
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.190    Count 3: 0.417    Count 4: 0.076    Count 5: 0.618  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.263    Count 9: 0.144    Count 10: 0.148  
Epoch [212] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [212] Batch [10/13] Loss: 0.0255 LR: 0.000100

Epoch [213/350] - Time: 4.88s
Train Loss: 0.0034 | Val Loss: 10.0216
Train Acc: 1.0000 | Val Acc: 0.3082
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.716    Count 2: 0.333    Count 3: 0.250    Count 4: 0.219    Count 5: 0.549  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.242    Count 9: 0.144    Count 10: 0.114  
Epoch [213] Batch [0/13] Loss: 0.0003 LR: 0.000100
Epoch [213] Batch [10/13] Loss: 0.0013 LR: 0.000100

Epoch [214/350] - Time: 4.52s
Train Loss: 0.0017 | Val Loss: 9.8042
Train Acc: 1.0000 | Val Acc: 0.3231
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.222    Count 3: 0.361    Count 4: 0.267    Count 5: 0.510  
  Count 6: 0.204    Count 7: 0.010    Count 8: 0.202    Count 9: 0.144    Count 10: 0.102  
Epoch [214] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [214] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [215/350] - Time: 4.45s
Train Loss: 0.0375 | Val Loss: 9.1025
Train Acc: 0.9948 | Val Acc: 0.3194
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.206    Count 3: 0.352    Count 4: 0.162    Count 5: 0.510  
  Count 6: 0.163    Count 7: 0.010    Count 8: 0.202    Count 9: 0.111    Count 10: 0.148  
Epoch [215] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [215] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [216/350] - Time: 4.33s
Train Loss: 0.0575 | Val Loss: 9.7451
Train Acc: 0.9897 | Val Acc: 0.2868
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.753    Count 2: 0.341    Count 3: 0.259    Count 4: 0.162    Count 5: 0.422  
  Count 6: 0.122    Count 7: 0.010    Count 8: 0.172    Count 9: 0.133    Count 10: 0.148  
Epoch [216] Batch [0/13] Loss: 0.0157 LR: 0.000100
Epoch [216] Batch [10/13] Loss: 0.0112 LR: 0.000100

Epoch [217/350] - Time: 4.66s
Train Loss: 0.0032 | Val Loss: 10.4126
Train Acc: 1.0000 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.759    Count 2: 0.317    Count 3: 0.287    Count 4: 0.333    Count 5: 0.382  
  Count 6: 0.276    Count 7: 0.010    Count 8: 0.162    Count 9: 0.111    Count 10: 0.080  
Epoch [217] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [217] Batch [10/13] Loss: 0.0405 LR: 0.000100

Epoch [218/350] - Time: 4.38s
Train Loss: 0.0046 | Val Loss: 10.3478
Train Acc: 1.0000 | Val Acc: 0.3091
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.765    Count 2: 0.333    Count 3: 0.259    Count 4: 0.486    Count 5: 0.343  
  Count 6: 0.235    Count 7: 0.000    Count 8: 0.131    Count 9: 0.100    Count 10: 0.080  
Epoch [218] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [218] Batch [10/13] Loss: 0.0002 LR: 0.000100

Epoch [219/350] - Time: 4.44s
Train Loss: 0.0002 | Val Loss: 10.2781
Train Acc: 1.0000 | Val Acc: 0.3035
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.784    Count 2: 0.333    Count 3: 0.296    Count 4: 0.248    Count 5: 0.480  
  Count 6: 0.173    Count 7: 0.010    Count 8: 0.141    Count 9: 0.111    Count 10: 0.091  
Epoch [219] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [219] Batch [10/13] Loss: 0.0001 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [220/350] - Time: 4.41s
Train Loss: 0.0003 | Val Loss: 10.1589
Train Acc: 1.0000 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.325    Count 3: 0.296    Count 4: 0.219    Count 5: 0.559  
  Count 6: 0.122    Count 7: 0.010    Count 8: 0.152    Count 9: 0.111    Count 10: 0.102  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_219.pth
Epoch [220] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [220] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [221/350] - Time: 4.86s
Train Loss: 0.0107 | Val Loss: 10.0041
Train Acc: 0.9948 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.784    Count 2: 0.349    Count 3: 0.231    Count 4: 0.371    Count 5: 0.451  
  Count 6: 0.112    Count 7: 0.010    Count 8: 0.152    Count 9: 0.111    Count 10: 0.125  
Epoch [221] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [221] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [222/350] - Time: 4.46s
Train Loss: 0.0001 | Val Loss: 10.2730
Train Acc: 1.0000 | Val Acc: 0.3035
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.389    Count 3: 0.213    Count 4: 0.486    Count 5: 0.265  
  Count 6: 0.122    Count 7: 0.010    Count 8: 0.141    Count 9: 0.111    Count 10: 0.125  
Epoch [222] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [222] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [223/350] - Time: 4.52s
Train Loss: 0.0001 | Val Loss: 10.1199
Train Acc: 1.0000 | Val Acc: 0.3073
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.262    Count 3: 0.241    Count 4: 0.343    Count 5: 0.392  
  Count 6: 0.112    Count 7: 0.010    Count 8: 0.182    Count 9: 0.133    Count 10: 0.125  
Epoch [223] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [223] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [224/350] - Time: 4.52s
Train Loss: 0.0002 | Val Loss: 9.7546
Train Acc: 1.0000 | Val Acc: 0.3277
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.349    Count 3: 0.194    Count 4: 0.419    Count 5: 0.461  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.192    Count 9: 0.122    Count 10: 0.182  
Epoch [224] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [224] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [225/350] - Time: 4.40s
Train Loss: 0.0125 | Val Loss: 9.9221
Train Acc: 0.9948 | Val Acc: 0.3222
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.852    Count 2: 0.302    Count 3: 0.241    Count 4: 0.238    Count 5: 0.529  
  Count 6: 0.143    Count 7: 0.010    Count 8: 0.202    Count 9: 0.144    Count 10: 0.193  
Epoch [225] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [225] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [226/350] - Time: 4.49s
Train Loss: 0.0003 | Val Loss: 11.0614
Train Acc: 1.0000 | Val Acc: 0.2980
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.802    Count 2: 0.262    Count 3: 0.306    Count 4: 0.181    Count 5: 0.578  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.131    Count 9: 0.122    Count 10: 0.125  
Epoch [226] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [226] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [227/350] - Time: 4.51s
Train Loss: 0.0017 | Val Loss: 11.0338
Train Acc: 1.0000 | Val Acc: 0.2942
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.230    Count 3: 0.333    Count 4: 0.133    Count 5: 0.559  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.162    Count 9: 0.122    Count 10: 0.102  
Epoch [227] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [227] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [228/350] - Time: 4.32s
Train Loss: 0.0015 | Val Loss: 11.2247
Train Acc: 1.0000 | Val Acc: 0.3007
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.802    Count 2: 0.222    Count 3: 0.315    Count 4: 0.143    Count 5: 0.539  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.273    Count 9: 0.122    Count 10: 0.102  
Epoch [228] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [228] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [229/350] - Time: 4.96s
Train Loss: 0.0004 | Val Loss: 11.6847
Train Acc: 1.0000 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.759    Count 2: 0.238    Count 3: 0.324    Count 4: 0.171    Count 5: 0.627  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.273    Count 9: 0.122    Count 10: 0.091  
Epoch [229] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [229] Batch [10/13] Loss: 0.0001 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [230/350] - Time: 4.48s
Train Loss: 0.0004 | Val Loss: 11.1258
Train Acc: 1.0000 | Val Acc: 0.2924
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.778    Count 2: 0.230    Count 3: 0.370    Count 4: 0.248    Count 5: 0.422  
  Count 6: 0.143    Count 7: 0.010    Count 8: 0.172    Count 9: 0.111    Count 10: 0.091  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_229.pth
Epoch [230] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [230] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [231/350] - Time: 4.40s
Train Loss: 0.0001 | Val Loss: 10.7682
Train Acc: 1.0000 | Val Acc: 0.2803
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.175    Count 3: 0.361    Count 4: 0.219    Count 5: 0.343  
  Count 6: 0.143    Count 7: 0.021    Count 8: 0.141    Count 9: 0.111    Count 10: 0.102  
Epoch [231] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [231] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [232/350] - Time: 4.48s
Train Loss: 0.0001 | Val Loss: 11.3391
Train Acc: 1.0000 | Val Acc: 0.2840
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.190    Count 3: 0.370    Count 4: 0.171    Count 5: 0.500  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.131    Count 9: 0.111    Count 10: 0.114  
Epoch [232] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [232] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [233/350] - Time: 4.46s
Train Loss: 0.0003 | Val Loss: 10.8407
Train Acc: 1.0000 | Val Acc: 0.3054
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.302    Count 3: 0.296    Count 4: 0.390    Count 5: 0.382  
  Count 6: 0.122    Count 7: 0.000    Count 8: 0.121    Count 9: 0.111    Count 10: 0.102  
Epoch [233] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [233] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [234/350] - Time: 4.43s
Train Loss: 0.0001 | Val Loss: 10.4224
Train Acc: 1.0000 | Val Acc: 0.2998
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.206    Count 3: 0.324    Count 4: 0.219    Count 5: 0.412  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.121    Count 9: 0.111    Count 10: 0.125  
Epoch [234] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [234] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [235/350] - Time: 4.41s
Train Loss: 0.0157 | Val Loss: 10.0199
Train Acc: 0.9897 | Val Acc: 0.3296
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.278    Count 3: 0.306    Count 4: 0.295    Count 5: 0.549  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.192    Count 9: 0.111    Count 10: 0.125  
Epoch [235] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [235] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [236/350] - Time: 4.40s
Train Loss: 0.0223 | Val Loss: 11.5044
Train Acc: 0.9897 | Val Acc: 0.2905
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.389    Count 3: 0.250    Count 4: 0.390    Count 5: 0.225  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.111    Count 9: 0.111    Count 10: 0.091  
Epoch [236] Batch [0/13] Loss: 0.0850 LR: 0.000100
Epoch [236] Batch [10/13] Loss: 0.0002 LR: 0.000100

Epoch [237/350] - Time: 4.84s
Train Loss: 0.0074 | Val Loss: 10.1046
Train Acc: 0.9948 | Val Acc: 0.3147
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.691    Count 2: 0.302    Count 3: 0.315    Count 4: 0.267    Count 5: 0.588  
  Count 6: 0.286    Count 7: 0.000    Count 8: 0.162    Count 9: 0.122    Count 10: 0.125  
Epoch [237] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [237] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [238/350] - Time: 4.46s
Train Loss: 0.0009 | Val Loss: 10.3610
Train Acc: 1.0000 | Val Acc: 0.3119
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.716    Count 2: 0.254    Count 3: 0.370    Count 4: 0.162    Count 5: 0.657  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.192    Count 9: 0.211    Count 10: 0.159  
Epoch [238] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [238] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [239/350] - Time: 4.34s
Train Loss: 0.0034 | Val Loss: 10.5984
Train Acc: 1.0000 | Val Acc: 0.3045
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.728    Count 2: 0.294    Count 3: 0.324    Count 4: 0.257    Count 5: 0.490  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.172    Count 9: 0.156    Count 10: 0.102  
Epoch [239] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [239] Batch [10/13] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [240/350] - Time: 4.56s
Train Loss: 0.0002 | Val Loss: 11.0766
Train Acc: 1.0000 | Val Acc: 0.3119
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.741    Count 2: 0.286    Count 3: 0.306    Count 4: 0.419    Count 5: 0.441  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.162    Count 9: 0.122    Count 10: 0.034  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_239.pth
Epoch [240] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [240] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [241/350] - Time: 4.34s
Train Loss: 0.0009 | Val Loss: 11.1110
Train Acc: 1.0000 | Val Acc: 0.3166
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.747    Count 2: 0.278    Count 3: 0.343    Count 4: 0.219    Count 5: 0.588  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.212    Count 9: 0.200    Count 10: 0.057  
Epoch [241] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [241] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [242/350] - Time: 4.41s
Train Loss: 0.0001 | Val Loss: 11.8046
Train Acc: 1.0000 | Val Acc: 0.2849
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.852    Count 2: 0.246    Count 3: 0.380    Count 4: 0.114    Count 5: 0.422  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.101    Count 9: 0.178    Count 10: 0.068  
Epoch [242] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [242] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [243/350] - Time: 4.45s
Train Loss: 0.0002 | Val Loss: 11.3495
Train Acc: 1.0000 | Val Acc: 0.2877
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.246    Count 3: 0.407    Count 4: 0.124    Count 5: 0.431  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.101    Count 9: 0.178    Count 10: 0.068  
Epoch [243] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [243] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [244/350] - Time: 4.38s
Train Loss: 0.0023 | Val Loss: 11.0640
Train Acc: 1.0000 | Val Acc: 0.3175
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.778    Count 2: 0.238    Count 3: 0.398    Count 4: 0.190    Count 5: 0.549  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.212    Count 9: 0.211    Count 10: 0.068  
Epoch [244] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [244] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [245/350] - Time: 4.72s
Train Loss: 0.0000 | Val Loss: 11.1905
Train Acc: 1.0000 | Val Acc: 0.3203
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.294    Count 3: 0.306    Count 4: 0.248    Count 5: 0.480  
  Count 6: 0.214    Count 7: 0.000    Count 8: 0.202    Count 9: 0.211    Count 10: 0.057  
Epoch [245] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [245] Batch [10/13] Loss: 0.0002 LR: 0.000100

Epoch [246/350] - Time: 4.40s
Train Loss: 0.0002 | Val Loss: 10.9509
Train Acc: 1.0000 | Val Acc: 0.3222
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.230    Count 3: 0.287    Count 4: 0.210    Count 5: 0.549  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.303    Count 9: 0.233    Count 10: 0.034  
Epoch [246] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [246] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [247/350] - Time: 4.48s
Train Loss: 0.0001 | Val Loss: 10.9579
Train Acc: 1.0000 | Val Acc: 0.3222
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.214    Count 3: 0.324    Count 4: 0.257    Count 5: 0.490  
  Count 6: 0.245    Count 7: 0.000    Count 8: 0.293    Count 9: 0.222    Count 10: 0.057  
Epoch [247] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [247] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [248/350] - Time: 4.45s
Train Loss: 0.0231 | Val Loss: 10.8741
Train Acc: 0.9948 | Val Acc: 0.3277
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.214    Count 3: 0.343    Count 4: 0.257    Count 5: 0.480  
  Count 6: 0.235    Count 7: 0.000    Count 8: 0.293    Count 9: 0.211    Count 10: 0.080  
Epoch [248] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [248] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [249/350] - Time: 4.48s
Train Loss: 0.0059 | Val Loss: 10.6626
Train Acc: 0.9948 | Val Acc: 0.3380
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.230    Count 3: 0.370    Count 4: 0.229    Count 5: 0.549  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.263    Count 9: 0.200    Count 10: 0.080  
Epoch [249] Batch [0/13] Loss: 0.5063 LR: 0.000100
Epoch [249] Batch [10/13] Loss: 0.0001 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [250/350] - Time: 4.42s
Train Loss: 0.0476 | Val Loss: 11.0283
Train Acc: 0.9897 | Val Acc: 0.2868
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.630    Count 2: 0.444    Count 3: 0.287    Count 4: 0.143    Count 5: 0.480  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.202    Count 9: 0.189    Count 10: 0.080  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_249.pth
Epoch [250] Batch [0/13] Loss: 0.0826 LR: 0.000100
Epoch [250] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [251/350] - Time: 4.33s
Train Loss: 0.0073 | Val Loss: 11.9885
Train Acc: 0.9948 | Val Acc: 0.2682
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.753    Count 2: 0.151    Count 3: 0.593    Count 4: 0.076    Count 5: 0.353  
  Count 6: 0.061    Count 7: 0.000    Count 8: 0.101    Count 9: 0.189    Count 10: 0.068  
Epoch [251] Batch [0/13] Loss: 0.0005 LR: 0.000100
Epoch [251] Batch [10/13] Loss: 0.0003 LR: 0.000100

Epoch [252/350] - Time: 4.39s
Train Loss: 0.0002 | Val Loss: 11.0842
Train Acc: 1.0000 | Val Acc: 0.2896
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.765    Count 2: 0.310    Count 3: 0.315    Count 4: 0.314    Count 5: 0.392  
  Count 6: 0.071    Count 7: 0.010    Count 8: 0.081    Count 9: 0.133    Count 10: 0.148  
Epoch [252] Batch [0/13] Loss: 0.0013 LR: 0.000100
Epoch [252] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [253/350] - Time: 4.66s
Train Loss: 0.0008 | Val Loss: 11.1270
Train Acc: 1.0000 | Val Acc: 0.2840
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.214    Count 3: 0.370    Count 4: 0.210    Count 5: 0.304  
  Count 6: 0.082    Count 7: 0.010    Count 8: 0.081    Count 9: 0.144    Count 10: 0.136  
Epoch [253] Batch [0/13] Loss: 0.0280 LR: 0.000100
Epoch [253] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [254/350] - Time: 4.43s
Train Loss: 0.0067 | Val Loss: 10.8483
Train Acc: 0.9948 | Val Acc: 0.3138
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.784    Count 2: 0.468    Count 3: 0.148    Count 4: 0.333    Count 5: 0.461  
  Count 6: 0.204    Count 7: 0.010    Count 8: 0.121    Count 9: 0.122    Count 10: 0.102  
Epoch [254] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [254] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [255/350] - Time: 4.37s
Train Loss: 0.0728 | Val Loss: 11.4434
Train Acc: 0.9948 | Val Acc: 0.3026
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.852    Count 2: 0.167    Count 3: 0.343    Count 4: 0.095    Count 5: 0.647  
  Count 6: 0.122    Count 7: 0.000    Count 8: 0.232    Count 9: 0.156    Count 10: 0.045  
Epoch [255] Batch [0/13] Loss: 0.0980 LR: 0.000100
Epoch [255] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [256/350] - Time: 4.49s
Train Loss: 0.0085 | Val Loss: 12.1613
Train Acc: 0.9948 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.747    Count 2: 0.373    Count 3: 0.213    Count 4: 0.400    Count 5: 0.480  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.101    Count 9: 0.122    Count 10: 0.080  
Epoch [256] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [256] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [257/350] - Time: 4.40s
Train Loss: 0.0660 | Val Loss: 10.7733
Train Acc: 0.9897 | Val Acc: 0.3259
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.753    Count 2: 0.317    Count 3: 0.259    Count 4: 0.267    Count 5: 0.598  
  Count 6: 0.133    Count 7: 0.010    Count 8: 0.303    Count 9: 0.178    Count 10: 0.125  
Epoch [257] Batch [0/13] Loss: 0.0063 LR: 0.000100
Epoch [257] Batch [10/13] Loss: 0.0150 LR: 0.000100

Epoch [258/350] - Time: 4.46s
Train Loss: 0.0050 | Val Loss: 10.6164
Train Acc: 1.0000 | Val Acc: 0.3166
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.190    Count 3: 0.343    Count 4: 0.171    Count 5: 0.549  
  Count 6: 0.204    Count 7: 0.010    Count 8: 0.313    Count 9: 0.189    Count 10: 0.080  
Epoch [258] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [258] Batch [10/13] Loss: 0.0039 LR: 0.000100

Epoch [259/350] - Time: 4.52s
Train Loss: 0.0029 | Val Loss: 12.6682
Train Acc: 1.0000 | Val Acc: 0.2700
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.753    Count 2: 0.302    Count 3: 0.333    Count 4: 0.086    Count 5: 0.510  
  Count 6: 0.020    Count 7: 0.000    Count 8: 0.141    Count 9: 0.156    Count 10: 0.034  
Epoch [259] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [259] Batch [10/13] Loss: 0.0057 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [260/350] - Time: 4.39s
Train Loss: 0.0458 | Val Loss: 11.7145
Train Acc: 0.9948 | Val Acc: 0.2896
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.741    Count 2: 0.238    Count 3: 0.250    Count 4: 0.333    Count 5: 0.520  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.202    Count 9: 0.122    Count 10: 0.023  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_259.pth
Epoch [260] Batch [0/13] Loss: 0.2723 LR: 0.000100
Epoch [260] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [261/350] - Time: 4.69s
Train Loss: 0.0229 | Val Loss: 11.7581
Train Acc: 0.9948 | Val Acc: 0.2840
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.222    Count 3: 0.250    Count 4: 0.352    Count 5: 0.373  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.152    Count 9: 0.133    Count 10: 0.011  
Epoch [261] Batch [0/13] Loss: 0.0004 LR: 0.000100
Epoch [261] Batch [10/13] Loss: 0.0002 LR: 0.000100

Epoch [262/350] - Time: 4.47s
Train Loss: 0.0020 | Val Loss: 10.0075
Train Acc: 1.0000 | Val Acc: 0.3026
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.691    Count 2: 0.238    Count 3: 0.361    Count 4: 0.314    Count 5: 0.549  
  Count 6: 0.102    Count 7: 0.021    Count 8: 0.182    Count 9: 0.133    Count 10: 0.148  
Epoch [262] Batch [0/13] Loss: 0.0226 LR: 0.000100
Epoch [262] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [263/350] - Time: 4.52s
Train Loss: 0.0021 | Val Loss: 10.0340
Train Acc: 1.0000 | Val Acc: 0.2914
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.302    Count 3: 0.333    Count 4: 0.219    Count 5: 0.373  
  Count 6: 0.061    Count 7: 0.021    Count 8: 0.141    Count 9: 0.144    Count 10: 0.125  
Epoch [263] Batch [0/13] Loss: 0.0004 LR: 0.000100
Epoch [263] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [264/350] - Time: 4.42s
Train Loss: 0.0079 | Val Loss: 11.5263
Train Acc: 0.9948 | Val Acc: 0.2924
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.286    Count 3: 0.333    Count 4: 0.305    Count 5: 0.431  
  Count 6: 0.082    Count 7: 0.000    Count 8: 0.121    Count 9: 0.111    Count 10: 0.023  
Epoch [264] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [264] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [265/350] - Time: 4.55s
Train Loss: 0.0002 | Val Loss: 11.6311
Train Acc: 1.0000 | Val Acc: 0.3026
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.278    Count 3: 0.306    Count 4: 0.305    Count 5: 0.500  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.182    Count 9: 0.122    Count 10: 0.068  
Epoch [265] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [265] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [266/350] - Time: 4.60s
Train Loss: 0.0000 | Val Loss: 11.6762
Train Acc: 1.0000 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.270    Count 3: 0.306    Count 4: 0.286    Count 5: 0.520  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.192    Count 9: 0.122    Count 10: 0.091  
Epoch [266] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [266] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [267/350] - Time: 4.38s
Train Loss: 0.1033 | Val Loss: 11.2938
Train Acc: 0.9948 | Val Acc: 0.2998
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.630    Count 2: 0.254    Count 3: 0.259    Count 4: 0.200    Count 5: 0.637  
  Count 6: 0.245    Count 7: 0.000    Count 8: 0.253    Count 9: 0.122    Count 10: 0.159  
Epoch [267] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [267] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [268/350] - Time: 4.45s
Train Loss: 0.0760 | Val Loss: 11.2231
Train Acc: 0.9742 | Val Acc: 0.3091
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.302    Count 3: 0.324    Count 4: 0.362    Count 5: 0.451  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.101    Count 9: 0.111    Count 10: 0.034  
Epoch [268] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [268] Batch [10/13] Loss: 0.0042 LR: 0.000100

Epoch [269/350] - Time: 4.41s
Train Loss: 0.0161 | Val Loss: 10.6531
Train Acc: 0.9948 | Val Acc: 0.3045
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.302    Count 3: 0.352    Count 4: 0.381    Count 5: 0.461  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.111    Count 9: 0.133    Count 10: 0.011  
Epoch [269] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [269] Batch [10/13] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [270/350] - Time: 4.70s
Train Loss: 0.0727 | Val Loss: 11.5274
Train Acc: 0.9845 | Val Acc: 0.2942
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.735    Count 2: 0.302    Count 3: 0.343    Count 4: 0.314    Count 5: 0.461  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.202    Count 9: 0.122    Count 10: 0.000  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_269.pth
Epoch [270] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [270] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [271/350] - Time: 4.54s
Train Loss: 0.0113 | Val Loss: 11.7210
Train Acc: 0.9897 | Val Acc: 0.2886
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.698    Count 2: 0.381    Count 3: 0.231    Count 4: 0.505    Count 5: 0.353  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.131    Count 9: 0.122    Count 10: 0.023  
Epoch [271] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [271] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [272/350] - Time: 4.63s
Train Loss: 0.0010 | Val Loss: 11.1948
Train Acc: 1.0000 | Val Acc: 0.2924
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.214    Count 3: 0.435    Count 4: 0.190    Count 5: 0.392  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.202    Count 9: 0.133    Count 10: 0.068  
Epoch [272] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [272] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [273/350] - Time: 4.71s
Train Loss: 0.0084 | Val Loss: 10.7407
Train Acc: 0.9948 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.704    Count 2: 0.397    Count 3: 0.204    Count 4: 0.457    Count 5: 0.441  
  Count 6: 0.214    Count 7: 0.010    Count 8: 0.131    Count 9: 0.122    Count 10: 0.045  
Epoch [273] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [273] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [274/350] - Time: 4.48s
Train Loss: 0.0026 | Val Loss: 10.3291
Train Acc: 1.0000 | Val Acc: 0.3119
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.294    Count 3: 0.352    Count 4: 0.229    Count 5: 0.559  
  Count 6: 0.163    Count 7: 0.010    Count 8: 0.172    Count 9: 0.133    Count 10: 0.057  
Epoch [274] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [274] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [275/350] - Time: 4.68s
Train Loss: 0.0404 | Val Loss: 10.5112
Train Acc: 0.9948 | Val Acc: 0.3101
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.747    Count 2: 0.325    Count 3: 0.315    Count 4: 0.286    Count 5: 0.529  
  Count 6: 0.173    Count 7: 0.010    Count 8: 0.162    Count 9: 0.144    Count 10: 0.068  
Epoch [275] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [275] Batch [10/13] Loss: 0.0002 LR: 0.000100

Epoch [276/350] - Time: 4.62s
Train Loss: 0.0067 | Val Loss: 11.1639
Train Acc: 0.9948 | Val Acc: 0.2896
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.716    Count 2: 0.302    Count 3: 0.204    Count 4: 0.238    Count 5: 0.559  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.192    Count 9: 0.122    Count 10: 0.034  
Epoch [276] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [276] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [277/350] - Time: 4.55s
Train Loss: 0.0093 | Val Loss: 11.2715
Train Acc: 0.9948 | Val Acc: 0.2840
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.294    Count 3: 0.269    Count 4: 0.229    Count 5: 0.382  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.111    Count 9: 0.133    Count 10: 0.068  
Epoch [277] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [277] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [278/350] - Time: 4.91s
Train Loss: 0.0002 | Val Loss: 11.5836
Train Acc: 1.0000 | Val Acc: 0.2905
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.278    Count 3: 0.315    Count 4: 0.314    Count 5: 0.402  
  Count 6: 0.122    Count 7: 0.010    Count 8: 0.111    Count 9: 0.133    Count 10: 0.057  
Epoch [278] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [278] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [279/350] - Time: 4.41s
Train Loss: 0.0000 | Val Loss: 11.4988
Train Acc: 1.0000 | Val Acc: 0.2980
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.230    Count 3: 0.352    Count 4: 0.314    Count 5: 0.441  
  Count 6: 0.143    Count 7: 0.010    Count 8: 0.131    Count 9: 0.122    Count 10: 0.080  
Epoch [279] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [279] Batch [10/13] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [280/350] - Time: 4.40s
Train Loss: 0.0000 | Val Loss: 11.7388
Train Acc: 1.0000 | Val Acc: 0.2989
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.784    Count 2: 0.262    Count 3: 0.333    Count 4: 0.305    Count 5: 0.451  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.141    Count 9: 0.122    Count 10: 0.068  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_279.pth
Epoch [280] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [280] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [281/350] - Time: 4.52s
Train Loss: 0.0000 | Val Loss: 11.4894
Train Acc: 1.0000 | Val Acc: 0.2970
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.809    Count 2: 0.222    Count 3: 0.361    Count 4: 0.324    Count 5: 0.422  
  Count 6: 0.143    Count 7: 0.010    Count 8: 0.131    Count 9: 0.122    Count 10: 0.057  
Epoch [281] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [281] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [282/350] - Time: 4.52s
Train Loss: 0.0000 | Val Loss: 11.6625
Train Acc: 1.0000 | Val Acc: 0.2961
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.784    Count 2: 0.230    Count 3: 0.343    Count 4: 0.324    Count 5: 0.441  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.131    Count 9: 0.122    Count 10: 0.068  
Epoch [282] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [282] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [283/350] - Time: 4.50s
Train Loss: 0.0000 | Val Loss: 11.5673
Train Acc: 1.0000 | Val Acc: 0.2970
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.238    Count 3: 0.333    Count 4: 0.333    Count 5: 0.441  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.121    Count 9: 0.122    Count 10: 0.068  
Epoch [283] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [283] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [284/350] - Time: 4.38s
Train Loss: 0.0000 | Val Loss: 11.4291
Train Acc: 1.0000 | Val Acc: 0.2998
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.246    Count 3: 0.343    Count 4: 0.324    Count 5: 0.441  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.131    Count 9: 0.122    Count 10: 0.080  
Epoch [284] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [284] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [285/350] - Time: 4.37s
Train Loss: 0.0000 | Val Loss: 11.6654
Train Acc: 1.0000 | Val Acc: 0.2998
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.222    Count 3: 0.361    Count 4: 0.314    Count 5: 0.461  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.131    Count 9: 0.122    Count 10: 0.068  
Epoch [285] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [285] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [286/350] - Time: 4.73s
Train Loss: 0.0004 | Val Loss: 11.6613
Train Acc: 1.0000 | Val Acc: 0.2970
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.230    Count 3: 0.333    Count 4: 0.305    Count 5: 0.422  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.131    Count 9: 0.122    Count 10: 0.068  
Epoch [286] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [286] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [287/350] - Time: 4.47s
Train Loss: 0.0478 | Val Loss: 11.7811
Train Acc: 0.9897 | Val Acc: 0.2803
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.230    Count 3: 0.352    Count 4: 0.210    Count 5: 0.402  
  Count 6: 0.122    Count 7: 0.000    Count 8: 0.141    Count 9: 0.122    Count 10: 0.057  
Epoch [287] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [287] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [288/350] - Time: 4.46s
Train Loss: 0.0134 | Val Loss: 11.0373
Train Acc: 0.9948 | Val Acc: 0.3017
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.593    Count 2: 0.373    Count 3: 0.259    Count 4: 0.410    Count 5: 0.480  
  Count 6: 0.265    Count 7: 0.010    Count 8: 0.162    Count 9: 0.133    Count 10: 0.068  
Epoch [288] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [288] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [289/350] - Time: 4.45s
Train Loss: 0.0001 | Val Loss: 11.4752
Train Acc: 1.0000 | Val Acc: 0.2961
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.759    Count 2: 0.143    Count 3: 0.463    Count 4: 0.105    Count 5: 0.559  
  Count 6: 0.163    Count 7: 0.000    Count 8: 0.202    Count 9: 0.167    Count 10: 0.091  
Epoch [289] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [289] Batch [10/13] Loss: 0.0002 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [290/350] - Time: 4.32s
Train Loss: 0.0019 | Val Loss: 11.3153
Train Acc: 1.0000 | Val Acc: 0.2933
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.648    Count 2: 0.357    Count 3: 0.250    Count 4: 0.590    Count 5: 0.265  
  Count 6: 0.204    Count 7: 0.010    Count 8: 0.101    Count 9: 0.133    Count 10: 0.068  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_289.pth
Epoch [290] Batch [0/13] Loss: 0.4228 LR: 0.000100
Epoch [290] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [291/350] - Time: 4.42s
Train Loss: 0.0349 | Val Loss: 11.6563
Train Acc: 0.9948 | Val Acc: 0.2858
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.747    Count 2: 0.238    Count 3: 0.444    Count 4: 0.248    Count 5: 0.461  
  Count 6: 0.102    Count 7: 0.000    Count 8: 0.091    Count 9: 0.122    Count 10: 0.057  
Epoch [291] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [291] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [292/350] - Time: 4.48s
Train Loss: 0.0003 | Val Loss: 11.6329
Train Acc: 1.0000 | Val Acc: 0.2877
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.642    Count 2: 0.405    Count 3: 0.269    Count 4: 0.552    Count 5: 0.294  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.081    Count 9: 0.122    Count 10: 0.057  
Epoch [292] Batch [0/13] Loss: 0.0103 LR: 0.000100
Epoch [292] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [293/350] - Time: 4.36s
Train Loss: 0.0396 | Val Loss: 11.8086
Train Acc: 0.9948 | Val Acc: 0.2914
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.753    Count 2: 0.310    Count 3: 0.361    Count 4: 0.390    Count 5: 0.373  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.091    Count 9: 0.122    Count 10: 0.057  
Epoch [293] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [293] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [294/350] - Time: 4.86s
Train Loss: 0.1988 | Val Loss: 11.6553
Train Acc: 0.9897 | Val Acc: 0.2905
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.753    Count 2: 0.286    Count 3: 0.296    Count 4: 0.229    Count 5: 0.480  
  Count 6: 0.112    Count 7: 0.010    Count 8: 0.182    Count 9: 0.122    Count 10: 0.091  
Epoch [294] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [294] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [295/350] - Time: 4.38s
Train Loss: 0.0025 | Val Loss: 10.1009
Train Acc: 1.0000 | Val Acc: 0.3175
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.784    Count 2: 0.270    Count 3: 0.231    Count 4: 0.343    Count 5: 0.451  
  Count 6: 0.296    Count 7: 0.010    Count 8: 0.212    Count 9: 0.144    Count 10: 0.102  
Epoch [295] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [295] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [296/350] - Time: 4.40s
Train Loss: 0.0153 | Val Loss: 11.1820
Train Acc: 0.9948 | Val Acc: 0.2737
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.784    Count 2: 0.357    Count 3: 0.361    Count 4: 0.257    Count 5: 0.304  
  Count 6: 0.031    Count 7: 0.000    Count 8: 0.051    Count 9: 0.122    Count 10: 0.068  
Epoch [296] Batch [0/13] Loss: 0.0008 LR: 0.000100
Epoch [296] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [297/350] - Time: 4.44s
Train Loss: 0.0200 | Val Loss: 10.7370
Train Acc: 0.9948 | Val Acc: 0.2784
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.543    Count 2: 0.333    Count 3: 0.213    Count 4: 0.352    Count 5: 0.422  
  Count 6: 0.347    Count 7: 0.010    Count 8: 0.131    Count 9: 0.122    Count 10: 0.080  
Epoch [297] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [297] Batch [10/13] Loss: 0.0864 LR: 0.000100

Epoch [298/350] - Time: 4.39s
Train Loss: 0.0567 | Val Loss: 10.8878
Train Acc: 0.9897 | Val Acc: 0.2952
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.735    Count 2: 0.357    Count 3: 0.204    Count 4: 0.305    Count 5: 0.422  
  Count 6: 0.235    Count 7: 0.010    Count 8: 0.121    Count 9: 0.122    Count 10: 0.102  
Epoch [298] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [298] Batch [10/13] Loss: 0.0006 LR: 0.000100

Epoch [299/350] - Time: 4.43s
Train Loss: 0.0708 | Val Loss: 9.8128
Train Acc: 0.9948 | Val Acc: 0.3054
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.735    Count 2: 0.325    Count 3: 0.315    Count 4: 0.210    Count 5: 0.539  
  Count 6: 0.235    Count 7: 0.010    Count 8: 0.101    Count 9: 0.122    Count 10: 0.136  
Epoch [299] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [299] Batch [10/13] Loss: 0.0019 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [300/350] - Time: 4.39s
Train Loss: 0.0121 | Val Loss: 10.6649
Train Acc: 0.9948 | Val Acc: 0.2840
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.698    Count 2: 0.302    Count 3: 0.352    Count 4: 0.190    Count 5: 0.520  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.091    Count 9: 0.122    Count 10: 0.102  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_299.pth
Epoch [300] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [300] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [301/350] - Time: 4.44s
Train Loss: 0.0191 | Val Loss: 11.1961
Train Acc: 0.9948 | Val Acc: 0.2700
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.630    Count 2: 0.333    Count 3: 0.287    Count 4: 0.381    Count 5: 0.373  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.081    Count 9: 0.122    Count 10: 0.080  
Epoch [301] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [301] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [302/350] - Time: 4.90s
Train Loss: 0.0099 | Val Loss: 11.3910
Train Acc: 0.9948 | Val Acc: 0.2924
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.852    Count 2: 0.270    Count 3: 0.241    Count 4: 0.390    Count 5: 0.324  
  Count 6: 0.143    Count 7: 0.000    Count 8: 0.091    Count 9: 0.133    Count 10: 0.080  
Epoch [302] Batch [0/13] Loss: 0.0102 LR: 0.000100
Epoch [302] Batch [10/13] Loss: 0.0027 LR: 0.000100

Epoch [303/350] - Time: 4.47s
Train Loss: 0.0193 | Val Loss: 11.2760
Train Acc: 0.9948 | Val Acc: 0.2961
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.778    Count 2: 0.214    Count 3: 0.417    Count 4: 0.276    Count 5: 0.588  
  Count 6: 0.082    Count 7: 0.000    Count 8: 0.091    Count 9: 0.122    Count 10: 0.034  
Epoch [303] Batch [0/13] Loss: 0.1248 LR: 0.000100
Epoch [303] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [304/350] - Time: 4.40s
Train Loss: 0.0105 | Val Loss: 10.9636
Train Acc: 0.9948 | Val Acc: 0.3101
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.735    Count 2: 0.429    Count 3: 0.167    Count 4: 0.495    Count 5: 0.490  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.111    Count 9: 0.122    Count 10: 0.080  
Epoch [304] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [304] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [305/350] - Time: 4.49s
Train Loss: 0.0163 | Val Loss: 10.1220
Train Acc: 0.9897 | Val Acc: 0.3380
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.198    Count 3: 0.287    Count 4: 0.229    Count 5: 0.598  
  Count 6: 0.306    Count 7: 0.000    Count 8: 0.273    Count 9: 0.156    Count 10: 0.193  
Epoch [305] Batch [0/13] Loss: 0.0004 LR: 0.000100
Epoch [305] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [306/350] - Time: 4.42s
Train Loss: 0.0047 | Val Loss: 11.5792
Train Acc: 0.9948 | Val Acc: 0.3054
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.198    Count 3: 0.380    Count 4: 0.305    Count 5: 0.441  
  Count 6: 0.204    Count 7: 0.000    Count 8: 0.192    Count 9: 0.122    Count 10: 0.034  
Epoch [306] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [306] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [307/350] - Time: 4.48s
Train Loss: 0.0010 | Val Loss: 9.9592
Train Acc: 1.0000 | Val Acc: 0.3231
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.809    Count 2: 0.294    Count 3: 0.333    Count 4: 0.362    Count 5: 0.363  
  Count 6: 0.112    Count 7: 0.010    Count 8: 0.242    Count 9: 0.156    Count 10: 0.205  
Epoch [307] Batch [0/13] Loss: 0.0006 LR: 0.000100
Epoch [307] Batch [10/13] Loss: 0.0014 LR: 0.000100

Epoch [308/350] - Time: 4.48s
Train Loss: 0.0010 | Val Loss: 10.9415
Train Acc: 1.0000 | Val Acc: 0.3175
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.294    Count 3: 0.361    Count 4: 0.333    Count 5: 0.412  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.202    Count 9: 0.122    Count 10: 0.159  
Epoch [308] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [308] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [309/350] - Time: 4.41s
Train Loss: 0.0002 | Val Loss: 11.0044
Train Acc: 1.0000 | Val Acc: 0.3166
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.778    Count 2: 0.286    Count 3: 0.315    Count 4: 0.410    Count 5: 0.461  
  Count 6: 0.122    Count 7: 0.000    Count 8: 0.222    Count 9: 0.133    Count 10: 0.091  
Epoch [309] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [309] Batch [10/13] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [310/350] - Time: 4.99s
Train Loss: 0.0002 | Val Loss: 10.7705
Train Acc: 1.0000 | Val Acc: 0.3026
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.759    Count 2: 0.310    Count 3: 0.324    Count 4: 0.352    Count 5: 0.431  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.152    Count 9: 0.133    Count 10: 0.102  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_309.pth
Epoch [310] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [310] Batch [10/13] Loss: 0.0002 LR: 0.000100

Epoch [311/350] - Time: 4.45s
Train Loss: 0.0002 | Val Loss: 11.1636
Train Acc: 1.0000 | Val Acc: 0.3110
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.765    Count 2: 0.254    Count 3: 0.417    Count 4: 0.152    Count 5: 0.627  
  Count 6: 0.061    Count 7: 0.000    Count 8: 0.212    Count 9: 0.133    Count 10: 0.159  
Epoch [311] Batch [0/13] Loss: 0.0011 LR: 0.000100
Epoch [311] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [312/350] - Time: 4.46s
Train Loss: 0.0002 | Val Loss: 11.0421
Train Acc: 1.0000 | Val Acc: 0.3138
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.270    Count 3: 0.444    Count 4: 0.210    Count 5: 0.549  
  Count 6: 0.071    Count 7: 0.000    Count 8: 0.182    Count 9: 0.133    Count 10: 0.125  
Epoch [312] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [312] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [313/350] - Time: 4.33s
Train Loss: 0.0192 | Val Loss: 11.2014
Train Acc: 0.9948 | Val Acc: 0.3156
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.294    Count 3: 0.370    Count 4: 0.305    Count 5: 0.441  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.162    Count 9: 0.133    Count 10: 0.091  
Epoch [313] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [313] Batch [10/13] Loss: 0.0143 LR: 0.000100

Epoch [314/350] - Time: 4.48s
Train Loss: 0.0439 | Val Loss: 10.7230
Train Acc: 0.9948 | Val Acc: 0.3119
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.270    Count 3: 0.296    Count 4: 0.381    Count 5: 0.304  
  Count 6: 0.173    Count 7: 0.010    Count 8: 0.101    Count 9: 0.111    Count 10: 0.148  
Epoch [314] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [314] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [315/350] - Time: 4.41s
Train Loss: 0.0109 | Val Loss: 10.8231
Train Acc: 0.9948 | Val Acc: 0.3035
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.230    Count 3: 0.407    Count 4: 0.210    Count 5: 0.520  
  Count 6: 0.153    Count 7: 0.000    Count 8: 0.152    Count 9: 0.111    Count 10: 0.057  
Epoch [315] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [315] Batch [10/13] Loss: 0.0024 LR: 0.000100

Epoch [316/350] - Time: 4.48s
Train Loss: 0.0007 | Val Loss: 11.0441
Train Acc: 1.0000 | Val Acc: 0.3017
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.349    Count 3: 0.296    Count 4: 0.362    Count 5: 0.412  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.101    Count 9: 0.111    Count 10: 0.080  
Epoch [316] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [316] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [317/350] - Time: 4.40s
Train Loss: 0.0017 | Val Loss: 9.7961
Train Acc: 1.0000 | Val Acc: 0.3250
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.246    Count 3: 0.435    Count 4: 0.171    Count 5: 0.529  
  Count 6: 0.112    Count 7: 0.010    Count 8: 0.242    Count 9: 0.133    Count 10: 0.182  
Epoch [317] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [317] Batch [10/13] Loss: 0.0037 LR: 0.000100

Epoch [318/350] - Time: 4.88s
Train Loss: 0.0014 | Val Loss: 11.5852
Train Acc: 1.0000 | Val Acc: 0.2840
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.246    Count 3: 0.324    Count 4: 0.314    Count 5: 0.176  
  Count 6: 0.092    Count 7: 0.010    Count 8: 0.131    Count 9: 0.111    Count 10: 0.125  
Epoch [318] Batch [0/13] Loss: 0.0536 LR: 0.000100
Epoch [318] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [319/350] - Time: 4.40s
Train Loss: 0.0151 | Val Loss: 12.2809
Train Acc: 0.9897 | Val Acc: 0.3166
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.175    Count 3: 0.435    Count 4: 0.105    Count 5: 0.500  
  Count 6: 0.061    Count 7: 0.000    Count 8: 0.263    Count 9: 0.144    Count 10: 0.193  
Epoch [319] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [319] Batch [10/13] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [320/350] - Time: 4.46s
Train Loss: 0.0515 | Val Loss: 11.5935
Train Acc: 0.9948 | Val Acc: 0.3166
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.206    Count 3: 0.370    Count 4: 0.257    Count 5: 0.402  
  Count 6: 0.224    Count 7: 0.010    Count 8: 0.263    Count 9: 0.144    Count 10: 0.102  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_319.pth
Epoch [320] Batch [0/13] Loss: 0.0015 LR: 0.000100
Epoch [320] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [321/350] - Time: 4.48s
Train Loss: 0.0002 | Val Loss: 11.5019
Train Acc: 1.0000 | Val Acc: 0.3119
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.753    Count 2: 0.190    Count 3: 0.269    Count 4: 0.305    Count 5: 0.422  
  Count 6: 0.316    Count 7: 0.010    Count 8: 0.273    Count 9: 0.156    Count 10: 0.136  
Epoch [321] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [321] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [322/350] - Time: 4.45s
Train Loss: 0.0000 | Val Loss: 11.5068
Train Acc: 1.0000 | Val Acc: 0.3147
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.765    Count 2: 0.222    Count 3: 0.306    Count 4: 0.371    Count 5: 0.431  
  Count 6: 0.245    Count 7: 0.010    Count 8: 0.232    Count 9: 0.144    Count 10: 0.102  
Epoch [322] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [322] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [323/350] - Time: 4.40s
Train Loss: 0.0000 | Val Loss: 11.5950
Train Acc: 1.0000 | Val Acc: 0.3166
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.759    Count 2: 0.238    Count 3: 0.278    Count 4: 0.371    Count 5: 0.431  
  Count 6: 0.255    Count 7: 0.010    Count 8: 0.232    Count 9: 0.167    Count 10: 0.114  
Epoch [323] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [323] Batch [10/13] Loss: 0.0011 LR: 0.000100

Epoch [324/350] - Time: 4.43s
Train Loss: 0.0007 | Val Loss: 11.6402
Train Acc: 1.0000 | Val Acc: 0.3138
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.778    Count 2: 0.317    Count 3: 0.296    Count 4: 0.238    Count 5: 0.480  
  Count 6: 0.143    Count 7: 0.010    Count 8: 0.232    Count 9: 0.167    Count 10: 0.136  
Epoch [324] Batch [0/13] Loss: 0.0015 LR: 0.000100
Epoch [324] Batch [10/13] Loss: 0.0038 LR: 0.000100

Epoch [325/350] - Time: 4.38s
Train Loss: 0.0008 | Val Loss: 11.4857
Train Acc: 1.0000 | Val Acc: 0.3156
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.691    Count 2: 0.230    Count 3: 0.287    Count 4: 0.124    Count 5: 0.588  
  Count 6: 0.224    Count 7: 0.010    Count 8: 0.394    Count 9: 0.189    Count 10: 0.170  
Epoch [325] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [325] Batch [10/13] Loss: 0.0099 LR: 0.000100

Epoch [326/350] - Time: 4.54s
Train Loss: 0.0657 | Val Loss: 12.8676
Train Acc: 0.9845 | Val Acc: 0.3045
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.735    Count 2: 0.294    Count 3: 0.259    Count 4: 0.457    Count 5: 0.275  
  Count 6: 0.224    Count 7: 0.010    Count 8: 0.263    Count 9: 0.122    Count 10: 0.080  
Epoch [326] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [326] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [327/350] - Time: 4.76s
Train Loss: 0.0004 | Val Loss: 12.5465
Train Acc: 1.0000 | Val Acc: 0.3045
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.111    Count 3: 0.361    Count 4: 0.095    Count 5: 0.461  
  Count 6: 0.204    Count 7: 0.010    Count 8: 0.465    Count 9: 0.156    Count 10: 0.091  
Epoch [327] Batch [0/13] Loss: 0.0021 LR: 0.000100
Epoch [327] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [328/350] - Time: 4.54s
Train Loss: 0.0007 | Val Loss: 11.4673
Train Acc: 1.0000 | Val Acc: 0.3240
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.759    Count 2: 0.389    Count 3: 0.278    Count 4: 0.238    Count 5: 0.471  
  Count 6: 0.122    Count 7: 0.010    Count 8: 0.343    Count 9: 0.122    Count 10: 0.170  
Epoch [328] Batch [0/13] Loss: 0.0005 LR: 0.000100
Epoch [328] Batch [10/13] Loss: 0.0471 LR: 0.000100

Epoch [329/350] - Time: 4.58s
Train Loss: 0.0578 | Val Loss: 11.7258
Train Acc: 0.9897 | Val Acc: 0.3063
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.716    Count 2: 0.270    Count 3: 0.426    Count 4: 0.095    Count 5: 0.490  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.303    Count 9: 0.167    Count 10: 0.136  
Epoch [329] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [329] Batch [10/13] Loss: 0.0002 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [330/350] - Time: 4.36s
Train Loss: 0.0516 | Val Loss: 11.4541
Train Acc: 0.9948 | Val Acc: 0.2989
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.735    Count 2: 0.286    Count 3: 0.426    Count 4: 0.219    Count 5: 0.373  
  Count 6: 0.133    Count 7: 0.010    Count 8: 0.212    Count 9: 0.133    Count 10: 0.136  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_329.pth
Epoch [330] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [330] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [331/350] - Time: 4.49s
Train Loss: 0.0005 | Val Loss: 12.7841
Train Acc: 1.0000 | Val Acc: 0.2821
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.716    Count 2: 0.492    Count 3: 0.222    Count 4: 0.324    Count 5: 0.275  
  Count 6: 0.112    Count 7: 0.000    Count 8: 0.091    Count 9: 0.122    Count 10: 0.091  
Epoch [331] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [331] Batch [10/13] Loss: 0.0039 LR: 0.000100

Epoch [332/350] - Time: 4.42s
Train Loss: 0.0007 | Val Loss: 13.3464
Train Acc: 1.0000 | Val Acc: 0.2663
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.741    Count 2: 0.175    Count 3: 0.491    Count 4: 0.095    Count 5: 0.480  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.091    Count 9: 0.122    Count 10: 0.034  
Epoch [332] Batch [0/13] Loss: 0.0034 LR: 0.000100
Epoch [332] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [333/350] - Time: 4.51s
Train Loss: 0.0205 | Val Loss: 12.7096
Train Acc: 0.9948 | Val Acc: 0.2905
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.333    Count 3: 0.231    Count 4: 0.333    Count 5: 0.373  
  Count 6: 0.071    Count 7: 0.000    Count 8: 0.051    Count 9: 0.122    Count 10: 0.068  
Epoch [333] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [333] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [334/350] - Time: 4.42s
Train Loss: 0.0953 | Val Loss: 11.7373
Train Acc: 0.9845 | Val Acc: 0.3054
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.741    Count 2: 0.429    Count 3: 0.287    Count 4: 0.343    Count 5: 0.314  
  Count 6: 0.133    Count 7: 0.021    Count 8: 0.172    Count 9: 0.133    Count 10: 0.125  
Epoch [334] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [334] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [335/350] - Time: 4.69s
Train Loss: 0.0988 | Val Loss: 11.6837
Train Acc: 0.9845 | Val Acc: 0.3194
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.735    Count 2: 0.246    Count 3: 0.370    Count 4: 0.152    Count 5: 0.461  
  Count 6: 0.184    Count 7: 0.021    Count 8: 0.414    Count 9: 0.189    Count 10: 0.136  
Epoch [335] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [335] Batch [10/13] Loss: 0.0004 LR: 0.000100

Epoch [336/350] - Time: 4.42s
Train Loss: 0.0353 | Val Loss: 11.3765
Train Acc: 0.9948 | Val Acc: 0.3007
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.246    Count 3: 0.287    Count 4: 0.238    Count 5: 0.304  
  Count 6: 0.143    Count 7: 0.010    Count 8: 0.202    Count 9: 0.122    Count 10: 0.114  
Epoch [336] Batch [0/13] Loss: 0.0014 LR: 0.000100
Epoch [336] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [337/350] - Time: 4.42s
Train Loss: 0.0020 | Val Loss: 10.7603
Train Acc: 1.0000 | Val Acc: 0.3240
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.772    Count 2: 0.444    Count 3: 0.241    Count 4: 0.286    Count 5: 0.549  
  Count 6: 0.143    Count 7: 0.010    Count 8: 0.212    Count 9: 0.111    Count 10: 0.102  
Epoch [337] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [337] Batch [10/13] Loss: 0.0011 LR: 0.000100

Epoch [338/350] - Time: 4.54s
Train Loss: 0.0140 | Val Loss: 10.8739
Train Acc: 0.9948 | Val Acc: 0.3091
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.858    Count 2: 0.270    Count 3: 0.407    Count 4: 0.343    Count 5: 0.314  
  Count 6: 0.112    Count 7: 0.021    Count 8: 0.152    Count 9: 0.111    Count 10: 0.102  
Epoch [338] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [338] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [339/350] - Time: 4.47s
Train Loss: 0.0424 | Val Loss: 10.7380
Train Acc: 0.9897 | Val Acc: 0.3054
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.691    Count 2: 0.302    Count 3: 0.204    Count 4: 0.543    Count 5: 0.294  
  Count 6: 0.337    Count 7: 0.031    Count 8: 0.162    Count 9: 0.089    Count 10: 0.102  
Epoch [339] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [339] Batch [10/13] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [340/350] - Time: 4.50s
Train Loss: 0.0012 | Val Loss: 11.7326
Train Acc: 1.0000 | Val Acc: 0.2719
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.222    Count 3: 0.500    Count 4: 0.200    Count 5: 0.294  
  Count 6: 0.051    Count 7: 0.010    Count 8: 0.020    Count 9: 0.111    Count 10: 0.091  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_339.pth
Epoch [340] Batch [0/13] Loss: 0.0015 LR: 0.000100
Epoch [340] Batch [10/13] Loss: 0.0003 LR: 0.000100

Epoch [341/350] - Time: 4.47s
Train Loss: 0.0014 | Val Loss: 12.1610
Train Acc: 1.0000 | Val Acc: 0.3082
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.716    Count 2: 0.222    Count 3: 0.370    Count 4: 0.162    Count 5: 0.490  
  Count 6: 0.204    Count 7: 0.010    Count 8: 0.434    Count 9: 0.122    Count 10: 0.057  
Epoch [341] Batch [0/13] Loss: 0.0001 LR: 0.000100
Epoch [341] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [342/350] - Time: 4.43s
Train Loss: 0.0010 | Val Loss: 11.4168
Train Acc: 1.0000 | Val Acc: 0.3175
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.753    Count 2: 0.222    Count 3: 0.472    Count 4: 0.257    Count 5: 0.431  
  Count 6: 0.143    Count 7: 0.010    Count 8: 0.384    Count 9: 0.100    Count 10: 0.080  
Epoch [342] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [342] Batch [10/13] Loss: 0.0002 LR: 0.000100

Epoch [343/350] - Time: 4.83s
Train Loss: 0.0013 | Val Loss: 11.6953
Train Acc: 1.0000 | Val Acc: 0.2886
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.722    Count 2: 0.214    Count 3: 0.491    Count 4: 0.286    Count 5: 0.235  
  Count 6: 0.143    Count 7: 0.031    Count 8: 0.253    Count 9: 0.111    Count 10: 0.080  
Epoch [343] Batch [0/13] Loss: 0.0000 LR: 0.000100
Epoch [343] Batch [10/13] Loss: 0.0490 LR: 0.000100

Epoch [344/350] - Time: 4.38s
Train Loss: 0.1265 | Val Loss: 10.3067
Train Acc: 0.9794 | Val Acc: 0.3026
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.957    Count 2: 0.206    Count 3: 0.398    Count 4: 0.305    Count 5: 0.196  
  Count 6: 0.112    Count 7: 0.021    Count 8: 0.182    Count 9: 0.100    Count 10: 0.102  
Epoch [344] Batch [0/13] Loss: 0.0485 LR: 0.000100
Epoch [344] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [345/350] - Time: 4.50s
Train Loss: 0.1243 | Val Loss: 10.4457
Train Acc: 0.9588 | Val Acc: 0.3156
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.691    Count 2: 0.294    Count 3: 0.204    Count 4: 0.048    Count 5: 0.578  
  Count 6: 0.194    Count 7: 0.010    Count 8: 0.515    Count 9: 0.122    Count 10: 0.250  
Epoch [345] Batch [0/13] Loss: 0.0127 LR: 0.000100
Epoch [345] Batch [10/13] Loss: 0.1076 LR: 0.000100

Epoch [346/350] - Time: 4.51s
Train Loss: 0.0166 | Val Loss: 11.2946
Train Acc: 0.9897 | Val Acc: 0.3277
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.294    Count 3: 0.444    Count 4: 0.238    Count 5: 0.382  
  Count 6: 0.061    Count 7: 0.010    Count 8: 0.343    Count 9: 0.133    Count 10: 0.102  
Epoch [346] Batch [0/13] Loss: 0.0003 LR: 0.000100
Epoch [346] Batch [10/13] Loss: 0.0004 LR: 0.000100

Epoch [347/350] - Time: 4.48s
Train Loss: 0.0161 | Val Loss: 11.9380
Train Acc: 0.9897 | Val Acc: 0.3035
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.765    Count 2: 0.183    Count 3: 0.250    Count 4: 0.152    Count 5: 0.569  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.414    Count 9: 0.100    Count 10: 0.034  
Epoch [347] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [347] Batch [10/13] Loss: 0.0001 LR: 0.000100

Epoch [348/350] - Time: 4.59s
Train Loss: 0.1157 | Val Loss: 11.8284
Train Acc: 0.9794 | Val Acc: 0.3110
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.476    Count 3: 0.185    Count 4: 0.248    Count 5: 0.559  
  Count 6: 0.092    Count 7: 0.000    Count 8: 0.182    Count 9: 0.111    Count 10: 0.023  
Epoch [348] Batch [0/13] Loss: 0.0002 LR: 0.000100
Epoch [348] Batch [10/13] Loss: 0.0000 LR: 0.000100

Epoch [349/350] - Time: 4.49s
Train Loss: 0.0015 | Val Loss: 11.1717
Train Acc: 1.0000 | Val Acc: 0.2933
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.190    Count 3: 0.380    Count 4: 0.229    Count 5: 0.480  
  Count 6: 0.153    Count 7: 0.021    Count 8: 0.141    Count 9: 0.089    Count 10: 0.045  
Epoch [349] Batch [0/13] Loss: 0.0059 LR: 0.000100
Epoch [349] Batch [10/13] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [350/350] - Time: 4.45s
Train Loss: 0.0263 | Val Loss: 11.3144
Train Acc: 0.9948 | Val Acc: 0.3250
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.858    Count 2: 0.302    Count 3: 0.324    Count 4: 0.086    Count 5: 0.696  
  Count 6: 0.082    Count 7: 0.000    Count 8: 0.273    Count 9: 0.133    Count 10: 0.114  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/single_image_checkpoint_epoch_349.pth
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/final_single_image_model.pth

训练完成!
最佳验证准确率: 0.3780
最佳验证损失: 2.2731
最终混淆矩阵保存到: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/final_confusion_matrix.png
详细报告保存到: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/5data/check_points/classification_report.txt

训练成功完成！
程序结束。
=== 完成 ===
结束时间: Sun  3 Aug 19:20:52 BST 2025
