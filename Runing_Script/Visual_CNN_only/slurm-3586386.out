=== 作业信息 ===
节点: node802
GPU: 1 (ID: 0)
CPU核心: 4
内存: 20480 MB
开始时间: Sun 20 Jul 17:44:32 BST 2025
=== 激活环境 ===
/var/spool/slurmd/job3586386/slurm_script: line 25: --version: command not found
Python版本: 
当前环境: cgtest
=== 开始训练 ===
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:279: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(test_path, map_location=self.device)
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')
============================================================
单图像分类模型训练配置
============================================================
基础配置:
  device: cuda
  batch_size: 16
  learning_rate: 0.0001
  total_epochs: 350
  image_mode: rgb

数据配置:
  data_root: /mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/Ball_counting_CNN/ball_data_collection
  train_csv: scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_train_10.csv
  val_csv: scratch/Ball_counting_CNN/Tools_script/ball_counting_dataset_val.csv

模型配置:
  use_attention: True
  cnn_layers: 3
  cnn_channels: [64, 128, 256]
  feature_dim: 256
  attention_heads: 1
  dropout: 0.1

训练配置:
  scheduler_type: none
  label_smoothing: 0.0
  grad_clip_norm: 1.0

保存配置:
  save_dir: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points
  log_dir: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/logs
  save_every: 10
============================================================
所有路径验证通过
配置保存到: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_config.json

正在初始化单图像分类模型训练器...
图像模式: RGB
使用注意力机制: True
标签范围: 1-10 (对应10个类别)
SingleImageClassifier初始化:
  CNN层数: 3
  CNN通道: [64, 128, 256]
  输入通道: 3
  输出类别: 10 (对应标签1-10)
  特征维度: 256
  隐藏维度: 256
  使用注意力: True
  注意力头数: 1
创建带注意力机制的单图像分类模型 (标签1-10)
✓ Model initialization validation passed
=== 创建单图像数据加载器 - 图像模式: RGB ===
标签: 直接使用ball_count
单图像数据集构建完成:
  原始序列数: 94
  提取的单图像样本数: 408
  图像模式: rgb
  标签: 直接使用ball_count
单图像数据集构建完成:
  原始序列数: 242
  提取的单图像样本数: 1074
  图像模式: rgb
  标签: 直接使用ball_count

训练集类别分布:
  球数 1: 66 样本
  球数 2: 48 样本
  球数 3: 44 样本
  球数 4: 40 样本
  球数 5: 36 样本
  球数 6: 35 样本
  球数 7: 40 样本
  球数 8: 36 样本
  球数 9: 30 样本
  球数 10: 33 样本

验证集类别分布:
  球数 1: 162 样本
  球数 2: 126 样本
  球数 3: 108 样本
  球数 4: 105 样本
  球数 5: 102 样本
  球数 6: 98 样本
  球数 7: 96 样本
  球数 8: 99 样本
  球数 9: 90 样本
  球数 10: 88 样本
SingleImageTrainer initialized:
  Model parameters: 734,858
  Training samples: 408
  Validation samples: 1,074
  Image mode: RGB
  Use attention: True
  Label mapping: 1-10 -> 0-9 (for loss calculation)

开始训练单图像分类模型...
目标: 作为具身计数模型的对比基线
使用所有帧图像，标签为对应序列的ball_count

开始训练单图像分类模型
总计 350 个epoch
设备: cuda
图像模式: rgb
Testing model save/load functionality...
✓ Model save/load test passed
Saving initial model state...
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/initial_single_image_model.pth

Performing initial validation...
Initial validation - Loss: 2.3060, Accuracy: 0.1006
Epoch [0] Batch [0/26] Loss: 2.2917 LR: 0.000100
Epoch [0] Batch [10/26] Loss: 2.2757 LR: 0.000100
Epoch [0] Batch [20/26] Loss: 2.2514 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [1/350] - Time: 4.55s
Train Loss: 2.2628 | Val Loss: 2.2586
Train Acc: 0.1838 | Val Acc: 0.1229
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.031    Count 2: 1.000    Count 3: 0.009    Count 4: 0.000    Count 5: 0.000  
  Count 6: 0.000    Count 7: 0.000    Count 8: 0.000    Count 9: 0.000    Count 10: 0.000  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.1229
新的最佳模型! 验证准确率: 0.1229
Epoch [1] Batch [0/26] Loss: 2.1814 LR: 0.000100
Epoch [1] Batch [10/26] Loss: 2.2001 LR: 0.000100
Epoch [1] Batch [20/26] Loss: 1.9914 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [2/350] - Time: 4.33s
Train Loss: 2.1264 | Val Loss: 2.0593
Train Acc: 0.3284 | Val Acc: 0.2607
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.988    Count 2: 0.000    Count 3: 0.000    Count 4: 0.000    Count 5: 0.000  
  Count 6: 0.000    Count 7: 0.406    Count 8: 0.000    Count 9: 0.000    Count 10: 0.920  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.2607
新的最佳模型! 验证准确率: 0.2607
Epoch [2] Batch [0/26] Loss: 1.8041 LR: 0.000100
Epoch [2] Batch [10/26] Loss: 1.7980 LR: 0.000100
Epoch [2] Batch [20/26] Loss: 1.7976 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [3/350] - Time: 4.09s
Train Loss: 1.8755 | Val Loss: 1.8174
Train Acc: 0.2990 | Val Acc: 0.2849
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 1.000    Count 2: 0.000    Count 3: 0.000    Count 4: 0.048    Count 5: 0.000  
  Count 6: 0.000    Count 7: 0.542    Count 8: 0.000    Count 9: 0.000    Count 10: 0.989  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.2849
新的最佳模型! 验证准确率: 0.2849
Epoch [3] Batch [0/26] Loss: 1.9807 LR: 0.000100
Epoch [3] Batch [10/26] Loss: 1.9230 LR: 0.000100
Epoch [3] Batch [20/26] Loss: 1.5883 LR: 0.000100

Epoch [4/350] - Time: 4.07s
Train Loss: 1.7320 | Val Loss: 1.7709
Train Acc: 0.2941 | Val Acc: 0.2421
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 1.000    Count 2: 0.008    Count 3: 0.000    Count 4: 0.010    Count 5: 0.000  
  Count 6: 0.020    Count 7: 0.344    Count 8: 0.051    Count 9: 0.000    Count 10: 0.636  
Epoch [4] Batch [0/26] Loss: 1.7130 LR: 0.000100
Epoch [4] Batch [10/26] Loss: 1.5361 LR: 0.000100
Epoch [4] Batch [20/26] Loss: 1.5094 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [5/350] - Time: 4.08s
Train Loss: 1.5871 | Val Loss: 1.5549
Train Acc: 0.3260 | Val Acc: 0.3529
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.975    Count 2: 0.175    Count 3: 0.102    Count 4: 0.562    Count 5: 0.020  
  Count 6: 0.143    Count 7: 0.135    Count 8: 0.253    Count 9: 0.000    Count 10: 0.852  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.3529
新的最佳模型! 验证准确率: 0.3529
Epoch [5] Batch [0/26] Loss: 1.5976 LR: 0.000100
Epoch [5] Batch [10/26] Loss: 1.5430 LR: 0.000100
Epoch [5] Batch [20/26] Loss: 1.5852 LR: 0.000100

Epoch [6/350] - Time: 4.07s
Train Loss: 1.4924 | Val Loss: 1.6250
Train Acc: 0.3775 | Val Acc: 0.2467
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.988    Count 2: 0.063    Count 3: 0.037    Count 4: 0.105    Count 5: 0.029  
  Count 6: 0.082    Count 7: 0.135    Count 8: 0.162    Count 9: 0.000    Count 10: 0.477  
Epoch [6] Batch [0/26] Loss: 1.2738 LR: 0.000100
Epoch [6] Batch [10/26] Loss: 1.2942 LR: 0.000100
Epoch [6] Batch [20/26] Loss: 1.1729 LR: 0.000100

Epoch [7/350] - Time: 4.23s
Train Loss: 1.3943 | Val Loss: 1.5760
Train Acc: 0.4020 | Val Acc: 0.2952
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.994    Count 2: 0.024    Count 3: 0.185    Count 4: 0.048    Count 5: 0.284  
  Count 6: 0.133    Count 7: 0.083    Count 8: 0.253    Count 9: 0.022    Count 10: 0.580  
Epoch [7] Batch [0/26] Loss: 1.6866 LR: 0.000100
Epoch [7] Batch [10/26] Loss: 1.1319 LR: 0.000100
Epoch [7] Batch [20/26] Loss: 1.3596 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [8/350] - Time: 4.10s
Train Loss: 1.3401 | Val Loss: 1.4496
Train Acc: 0.4167 | Val Acc: 0.4041
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.975    Count 2: 0.405    Count 3: 0.120    Count 4: 0.695    Count 5: 0.029  
  Count 6: 0.582    Count 7: 0.104    Count 8: 0.101    Count 9: 0.156    Count 10: 0.511  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.4041
新的最佳模型! 验证准确率: 0.4041
Epoch [8] Batch [0/26] Loss: 1.2059 LR: 0.000100
Epoch [8] Batch [10/26] Loss: 1.2855 LR: 0.000100
Epoch [8] Batch [20/26] Loss: 1.6205 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [9/350] - Time: 4.16s
Train Loss: 1.3043 | Val Loss: 1.4758
Train Acc: 0.4485 | Val Acc: 0.4218
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.516    Count 3: 0.130    Count 4: 0.886    Count 5: 0.000  
  Count 6: 0.245    Count 7: 0.083    Count 8: 0.333    Count 9: 0.411    Count 10: 0.307  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.4218
新的最佳模型! 验证准确率: 0.4218
Epoch [9] Batch [0/26] Loss: 1.2199 LR: 0.000100
Epoch [9] Batch [10/26] Loss: 1.4129 LR: 0.000100
Epoch [9] Batch [20/26] Loss: 0.8526 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [10/350] - Time: 4.53s
Train Loss: 1.2272 | Val Loss: 1.4347
Train Acc: 0.4706 | Val Acc: 0.4488
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.444    Count 3: 0.352    Count 4: 0.676    Count 5: 0.480  
  Count 6: 0.204    Count 7: 0.073    Count 8: 0.121    Count 9: 0.422    Count 10: 0.443  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.4488
新的最佳模型! 验证准确率: 0.4488
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_9.pth
Epoch [10] Batch [0/26] Loss: 1.0448 LR: 0.000100
Epoch [10] Batch [10/26] Loss: 1.0597 LR: 0.000100
Epoch [10] Batch [20/26] Loss: 0.8166 LR: 0.000100

Epoch [11/350] - Time: 4.14s
Train Loss: 1.1644 | Val Loss: 1.4526
Train Acc: 0.5245 | Val Acc: 0.4358
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.365    Count 3: 0.398    Count 4: 0.600    Count 5: 0.471  
  Count 6: 0.235    Count 7: 0.115    Count 8: 0.253    Count 9: 0.189    Count 10: 0.432  
Epoch [11] Batch [0/26] Loss: 1.0991 LR: 0.000100
Epoch [11] Batch [10/26] Loss: 1.2527 LR: 0.000100
Epoch [11] Batch [20/26] Loss: 0.9696 LR: 0.000100

Epoch [12/350] - Time: 4.24s
Train Loss: 1.1169 | Val Loss: 1.7437
Train Acc: 0.5368 | Val Acc: 0.3389
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.772    Count 2: 0.333    Count 3: 0.185    Count 4: 0.000    Count 5: 0.176  
  Count 6: 0.306    Count 7: 0.250    Count 8: 0.404    Count 9: 0.356    Count 10: 0.375  
Epoch [12] Batch [0/26] Loss: 1.1241 LR: 0.000100
Epoch [12] Batch [10/26] Loss: 1.0897 LR: 0.000100
Epoch [12] Batch [20/26] Loss: 1.0854 LR: 0.000100

Epoch [13/350] - Time: 4.21s
Train Loss: 1.0690 | Val Loss: 1.5712
Train Acc: 0.5417 | Val Acc: 0.3445
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.183    Count 3: 0.102    Count 4: 0.086    Count 5: 0.480  
  Count 6: 0.541    Count 7: 0.083    Count 8: 0.182    Count 9: 0.411    Count 10: 0.284  
Epoch [13] Batch [0/26] Loss: 1.9463 LR: 0.000100
Epoch [13] Batch [10/26] Loss: 1.0706 LR: 0.000100
Epoch [13] Batch [20/26] Loss: 0.9772 LR: 0.000100

Epoch [14/350] - Time: 4.20s
Train Loss: 1.0581 | Val Loss: 1.5840
Train Acc: 0.5539 | Val Acc: 0.4246
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.437    Count 3: 0.352    Count 4: 0.829    Count 5: 0.441  
  Count 6: 0.031    Count 7: 0.073    Count 8: 0.141    Count 9: 0.344    Count 10: 0.261  
Epoch [14] Batch [0/26] Loss: 0.8747 LR: 0.000100
Epoch [14] Batch [10/26] Loss: 0.9096 LR: 0.000100
Epoch [14] Batch [20/26] Loss: 1.2482 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [15/350] - Time: 4.25s
Train Loss: 0.9714 | Val Loss: 1.5581
Train Acc: 0.5662 | Val Acc: 0.4581
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.333    Count 3: 0.648    Count 4: 0.314    Count 5: 0.422  
  Count 6: 0.582    Count 7: 0.083    Count 8: 0.131    Count 9: 0.444    Count 10: 0.341  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.4581
新的最佳模型! 验证准确率: 0.4581
Epoch [15] Batch [0/26] Loss: 0.8516 LR: 0.000100
Epoch [15] Batch [10/26] Loss: 0.7847 LR: 0.000100
Epoch [15] Batch [20/26] Loss: 0.8476 LR: 0.000100

Epoch [16/350] - Time: 4.24s
Train Loss: 0.8354 | Val Loss: 1.5702
Train Acc: 0.6814 | Val Acc: 0.4423
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.571    Count 3: 0.426    Count 4: 0.429    Count 5: 0.529  
  Count 6: 0.245    Count 7: 0.094    Count 8: 0.162    Count 9: 0.289    Count 10: 0.341  
Epoch [16] Batch [0/26] Loss: 0.9067 LR: 0.000100
Epoch [16] Batch [10/26] Loss: 0.6488 LR: 0.000100
Epoch [16] Batch [20/26] Loss: 0.5794 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [17/350] - Time: 4.23s
Train Loss: 0.7904 | Val Loss: 1.6851
Train Acc: 0.6716 | Val Acc: 0.4786
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.722    Count 3: 0.574    Count 4: 0.543    Count 5: 0.529  
  Count 6: 0.235    Count 7: 0.104    Count 8: 0.111    Count 9: 0.467    Count 10: 0.216  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.4786
新的最佳模型! 验证准确率: 0.4786
Epoch [17] Batch [0/26] Loss: 0.6263 LR: 0.000100
Epoch [17] Batch [10/26] Loss: 1.0312 LR: 0.000100
Epoch [17] Batch [20/26] Loss: 0.6319 LR: 0.000100

Epoch [18/350] - Time: 4.36s
Train Loss: 0.7780 | Val Loss: 1.7648
Train Acc: 0.6961 | Val Acc: 0.4153
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.988    Count 2: 0.548    Count 3: 0.352    Count 4: 0.295    Count 5: 0.304  
  Count 6: 0.153    Count 7: 0.104    Count 8: 0.040    Count 9: 0.544    Count 10: 0.443  
Epoch [18] Batch [0/26] Loss: 0.9557 LR: 0.000100
Epoch [18] Batch [10/26] Loss: 1.1739 LR: 0.000100
Epoch [18] Batch [20/26] Loss: 0.9862 LR: 0.000100

Epoch [19/350] - Time: 4.12s
Train Loss: 0.7718 | Val Loss: 2.2400
Train Acc: 0.6789 | Val Acc: 0.3315
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.988    Count 2: 0.532    Count 3: 0.111    Count 4: 0.286    Count 5: 0.098  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.101    Count 9: 0.444    Count 10: 0.125  
Epoch [19] Batch [0/26] Loss: 0.6091 LR: 0.000100
Epoch [19] Batch [10/26] Loss: 0.8190 LR: 0.000100
Epoch [19] Batch [20/26] Loss: 0.6665 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [20/350] - Time: 4.16s
Train Loss: 0.7887 | Val Loss: 1.9152
Train Acc: 0.6642 | Val Acc: 0.4916
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.762    Count 3: 0.509    Count 4: 0.676    Count 5: 0.392  
  Count 6: 0.398    Count 7: 0.083    Count 8: 0.071    Count 9: 0.411    Count 10: 0.273  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.4916
新的最佳模型! 验证准确率: 0.4916
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_19.pth
Epoch [20] Batch [0/26] Loss: 1.1188 LR: 0.000100
Epoch [20] Batch [10/26] Loss: 0.3320 LR: 0.000100
Epoch [20] Batch [20/26] Loss: 1.0234 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [21/350] - Time: 4.13s
Train Loss: 0.6390 | Val Loss: 1.9451
Train Acc: 0.7598 | Val Acc: 0.4944
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.722    Count 3: 0.611    Count 4: 0.543    Count 5: 0.461  
  Count 6: 0.388    Count 7: 0.104    Count 8: 0.121    Count 9: 0.511    Count 10: 0.227  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.4944
新的最佳模型! 验证准确率: 0.4944
Epoch [21] Batch [0/26] Loss: 0.6205 LR: 0.000100
Epoch [21] Batch [10/26] Loss: 0.4071 LR: 0.000100
Epoch [21] Batch [20/26] Loss: 0.6852 LR: 0.000100

Epoch [22/350] - Time: 4.18s
Train Loss: 0.6058 | Val Loss: 2.0148
Train Acc: 0.7279 | Val Acc: 0.4330
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.988    Count 2: 0.698    Count 3: 0.509    Count 4: 0.400    Count 5: 0.167  
  Count 6: 0.163    Count 7: 0.083    Count 8: 0.101    Count 9: 0.400    Count 10: 0.375  
Epoch [22] Batch [0/26] Loss: 0.5444 LR: 0.000100
Epoch [22] Batch [10/26] Loss: 1.1178 LR: 0.000100
Epoch [22] Batch [20/26] Loss: 0.6186 LR: 0.000100

Epoch [23/350] - Time: 4.14s
Train Loss: 0.6688 | Val Loss: 2.0831
Train Acc: 0.7132 | Val Acc: 0.4637
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.635    Count 3: 0.583    Count 4: 0.724    Count 5: 0.373  
  Count 6: 0.296    Count 7: 0.104    Count 8: 0.081    Count 9: 0.278    Count 10: 0.239  
Epoch [23] Batch [0/26] Loss: 0.5064 LR: 0.000100
Epoch [23] Batch [10/26] Loss: 0.5521 LR: 0.000100
Epoch [23] Batch [20/26] Loss: 0.5924 LR: 0.000100

Epoch [24/350] - Time: 4.17s
Train Loss: 0.5358 | Val Loss: 1.9724
Train Acc: 0.7941 | Val Acc: 0.4916
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.897    Count 3: 0.407    Count 4: 0.819    Count 5: 0.510  
  Count 6: 0.092    Count 7: 0.146    Count 8: 0.091    Count 9: 0.256    Count 10: 0.364  
Epoch [24] Batch [0/26] Loss: 0.6739 LR: 0.000100
Epoch [24] Batch [10/26] Loss: 0.4498 LR: 0.000100
Epoch [24] Batch [20/26] Loss: 0.4422 LR: 0.000100

Epoch [25/350] - Time: 4.18s
Train Loss: 0.5007 | Val Loss: 2.0842
Train Acc: 0.7966 | Val Acc: 0.4804
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.603    Count 3: 0.574    Count 4: 0.495    Count 5: 0.608  
  Count 6: 0.306    Count 7: 0.146    Count 8: 0.101    Count 9: 0.289    Count 10: 0.307  
Epoch [25] Batch [0/26] Loss: 0.4820 LR: 0.000100
Epoch [25] Batch [10/26] Loss: 0.7265 LR: 0.000100
Epoch [25] Batch [20/26] Loss: 0.5374 LR: 0.000100

Epoch [26/350] - Time: 4.43s
Train Loss: 0.5231 | Val Loss: 2.5534
Train Acc: 0.7696 | Val Acc: 0.3994
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.994    Count 2: 0.730    Count 3: 0.565    Count 4: 0.467    Count 5: 0.137  
  Count 6: 0.143    Count 7: 0.010    Count 8: 0.081    Count 9: 0.233    Count 10: 0.091  
Epoch [26] Batch [0/26] Loss: 0.2774 LR: 0.000100
Epoch [26] Batch [10/26] Loss: 0.4876 LR: 0.000100
Epoch [26] Batch [20/26] Loss: 0.3452 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [27/350] - Time: 4.14s
Train Loss: 0.4671 | Val Loss: 2.1258
Train Acc: 0.7990 | Val Acc: 0.5158
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.841    Count 3: 0.546    Count 4: 0.552    Count 5: 0.618  
  Count 6: 0.194    Count 7: 0.094    Count 8: 0.242    Count 9: 0.289    Count 10: 0.375  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.5158
新的最佳模型! 验证准确率: 0.5158
Epoch [27] Batch [0/26] Loss: 0.2599 LR: 0.000100
Epoch [27] Batch [10/26] Loss: 0.2066 LR: 0.000100
Epoch [27] Batch [20/26] Loss: 0.3159 LR: 0.000100

Epoch [28/350] - Time: 4.18s
Train Loss: 0.4420 | Val Loss: 2.5353
Train Acc: 0.8333 | Val Acc: 0.4255
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.994    Count 2: 0.603    Count 3: 0.556    Count 4: 0.667    Count 5: 0.294  
  Count 6: 0.153    Count 7: 0.042    Count 8: 0.071    Count 9: 0.244    Count 10: 0.136  
Epoch [28] Batch [0/26] Loss: 0.6745 LR: 0.000100
Epoch [28] Batch [10/26] Loss: 0.3305 LR: 0.000100
Epoch [28] Batch [20/26] Loss: 0.3485 LR: 0.000100

Epoch [29/350] - Time: 4.15s
Train Loss: 0.4959 | Val Loss: 1.9774
Train Acc: 0.8162 | Val Acc: 0.5112
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.714    Count 3: 0.620    Count 4: 0.619    Count 5: 0.539  
  Count 6: 0.378    Count 7: 0.062    Count 8: 0.141    Count 9: 0.456    Count 10: 0.307  
Epoch [29] Batch [0/26] Loss: 0.3841 LR: 0.000100
Epoch [29] Batch [10/26] Loss: 0.3375 LR: 0.000100
Epoch [29] Batch [20/26] Loss: 0.4958 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [30/350] - Time: 4.27s
Train Loss: 0.3998 | Val Loss: 2.3055
Train Acc: 0.8554 | Val Acc: 0.4665
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.619    Count 3: 0.361    Count 4: 0.400    Count 5: 0.353  
  Count 6: 0.704    Count 7: 0.156    Count 8: 0.283    Count 9: 0.467    Count 10: 0.193  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_29.pth
Epoch [30] Batch [0/26] Loss: 0.6198 LR: 0.000100
Epoch [30] Batch [10/26] Loss: 0.1560 LR: 0.000100
Epoch [30] Batch [20/26] Loss: 0.4721 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [31/350] - Time: 4.27s
Train Loss: 0.3919 | Val Loss: 2.4137
Train Acc: 0.8431 | Val Acc: 0.5242
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.889    Count 3: 0.583    Count 4: 0.762    Count 5: 0.412  
  Count 6: 0.398    Count 7: 0.094    Count 8: 0.162    Count 9: 0.422    Count 10: 0.159  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/best_single_image_model.pth
  → New best model! Validation accuracy: 0.5242
新的最佳模型! 验证准确率: 0.5242
Epoch [31] Batch [0/26] Loss: 0.2981 LR: 0.000100
Epoch [31] Batch [10/26] Loss: 0.6919 LR: 0.000100
Epoch [31] Batch [20/26] Loss: 0.4525 LR: 0.000100

Epoch [32/350] - Time: 4.20s
Train Loss: 0.4192 | Val Loss: 2.4036
Train Acc: 0.8113 | Val Acc: 0.4572
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.548    Count 3: 0.454    Count 4: 0.352    Count 5: 0.471  
  Count 6: 0.439    Count 7: 0.167    Count 8: 0.141    Count 9: 0.444    Count 10: 0.352  
Epoch [32] Batch [0/26] Loss: 0.2373 LR: 0.000100
Epoch [32] Batch [10/26] Loss: 0.2775 LR: 0.000100
Epoch [32] Batch [20/26] Loss: 0.3261 LR: 0.000100

Epoch [33/350] - Time: 4.15s
Train Loss: 0.5554 | Val Loss: 3.4480
Train Acc: 0.7647 | Val Acc: 0.3734
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.981    Count 2: 0.778    Count 3: 0.407    Count 4: 0.352    Count 5: 0.206  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.081    Count 9: 0.222    Count 10: 0.011  
Epoch [33] Batch [0/26] Loss: 0.2739 LR: 0.000100
Epoch [33] Batch [10/26] Loss: 0.5217 LR: 0.000100
Epoch [33] Batch [20/26] Loss: 0.7434 LR: 0.000100

Epoch [34/350] - Time: 4.35s
Train Loss: 0.5585 | Val Loss: 2.4052
Train Acc: 0.7500 | Val Acc: 0.5000
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.754    Count 3: 0.741    Count 4: 0.590    Count 5: 0.422  
  Count 6: 0.214    Count 7: 0.083    Count 8: 0.101    Count 9: 0.556    Count 10: 0.136  
Epoch [34] Batch [0/26] Loss: 0.2119 LR: 0.000100
Epoch [34] Batch [10/26] Loss: 0.3061 LR: 0.000100
Epoch [34] Batch [20/26] Loss: 0.3025 LR: 0.000100

Epoch [35/350] - Time: 4.14s
Train Loss: 0.3465 | Val Loss: 2.9700
Train Acc: 0.8578 | Val Acc: 0.4553
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.849    Count 3: 0.630    Count 4: 0.581    Count 5: 0.373  
  Count 6: 0.133    Count 7: 0.021    Count 8: 0.141    Count 9: 0.200    Count 10: 0.125  
Epoch [35] Batch [0/26] Loss: 0.2304 LR: 0.000100
Epoch [35] Batch [10/26] Loss: 0.4529 LR: 0.000100
Epoch [35] Batch [20/26] Loss: 0.3706 LR: 0.000100

Epoch [36/350] - Time: 4.17s
Train Loss: 0.3289 | Val Loss: 2.9281
Train Acc: 0.8725 | Val Acc: 0.4823
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.690    Count 3: 0.676    Count 4: 0.562    Count 5: 0.657  
  Count 6: 0.173    Count 7: 0.135    Count 8: 0.071    Count 9: 0.322    Count 10: 0.159  
Epoch [36] Batch [0/26] Loss: 0.2061 LR: 0.000100
Epoch [36] Batch [10/26] Loss: 0.3540 LR: 0.000100
Epoch [36] Batch [20/26] Loss: 0.3795 LR: 0.000100

Epoch [37/350] - Time: 4.18s
Train Loss: 0.4166 | Val Loss: 3.3084
Train Acc: 0.8137 | Val Acc: 0.4358
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.563    Count 3: 0.657    Count 4: 0.667    Count 5: 0.412  
  Count 6: 0.245    Count 7: 0.000    Count 8: 0.111    Count 9: 0.289    Count 10: 0.193  
Epoch [37] Batch [0/26] Loss: 0.4579 LR: 0.000100
Epoch [37] Batch [10/26] Loss: 0.9412 LR: 0.000100
Epoch [37] Batch [20/26] Loss: 0.2568 LR: 0.000100

Epoch [38/350] - Time: 4.23s
Train Loss: 0.3387 | Val Loss: 2.6258
Train Acc: 0.8750 | Val Acc: 0.4823
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.746    Count 3: 0.639    Count 4: 0.695    Count 5: 0.412  
  Count 6: 0.184    Count 7: 0.031    Count 8: 0.141    Count 9: 0.300    Count 10: 0.250  
Epoch [38] Batch [0/26] Loss: 0.1861 LR: 0.000100
Epoch [38] Batch [10/26] Loss: 0.4748 LR: 0.000100
Epoch [38] Batch [20/26] Loss: 0.2418 LR: 0.000100

Epoch [39/350] - Time: 4.23s
Train Loss: 0.2638 | Val Loss: 3.0608
Train Acc: 0.8873 | Val Acc: 0.4711
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.738    Count 3: 0.611    Count 4: 0.657    Count 5: 0.422  
  Count 6: 0.184    Count 7: 0.031    Count 8: 0.101    Count 9: 0.344    Count 10: 0.193  
Epoch [39] Batch [0/26] Loss: 0.2751 LR: 0.000100
Epoch [39] Batch [10/26] Loss: 0.2874 LR: 0.000100
Epoch [39] Batch [20/26] Loss: 0.2096 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [40/350] - Time: 4.17s
Train Loss: 0.2746 | Val Loss: 3.0657
Train Acc: 0.9020 | Val Acc: 0.4711
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.730    Count 3: 0.519    Count 4: 0.810    Count 5: 0.539  
  Count 6: 0.184    Count 7: 0.135    Count 8: 0.081    Count 9: 0.322    Count 10: 0.148  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_39.pth
Epoch [40] Batch [0/26] Loss: 0.1392 LR: 0.000100
Epoch [40] Batch [10/26] Loss: 0.1036 LR: 0.000100
Epoch [40] Batch [20/26] Loss: 0.0478 LR: 0.000100

Epoch [41/350] - Time: 4.20s
Train Loss: 0.2173 | Val Loss: 2.9839
Train Acc: 0.9314 | Val Acc: 0.4898
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.957    Count 2: 0.690    Count 3: 0.556    Count 4: 0.724    Count 5: 0.471  
  Count 6: 0.184    Count 7: 0.104    Count 8: 0.101    Count 9: 0.400    Count 10: 0.295  
Epoch [41] Batch [0/26] Loss: 0.0511 LR: 0.000100
Epoch [41] Batch [10/26] Loss: 0.4463 LR: 0.000100
Epoch [41] Batch [20/26] Loss: 0.1463 LR: 0.000100

Epoch [42/350] - Time: 4.23s
Train Loss: 0.2681 | Val Loss: 3.1188
Train Acc: 0.9069 | Val Acc: 0.4944
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.975    Count 2: 0.706    Count 3: 0.546    Count 4: 0.733    Count 5: 0.725  
  Count 6: 0.112    Count 7: 0.062    Count 8: 0.081    Count 9: 0.322    Count 10: 0.227  
Epoch [42] Batch [0/26] Loss: 0.0728 LR: 0.000100
Epoch [42] Batch [10/26] Loss: 0.0972 LR: 0.000100
Epoch [42] Batch [20/26] Loss: 0.1100 LR: 0.000100

Epoch [43/350] - Time: 4.36s
Train Loss: 0.2406 | Val Loss: 3.2971
Train Acc: 0.9093 | Val Acc: 0.4572
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.815    Count 2: 0.667    Count 3: 0.435    Count 4: 0.448    Count 5: 0.451  
  Count 6: 0.347    Count 7: 0.188    Count 8: 0.162    Count 9: 0.422    Count 10: 0.330  
Epoch [43] Batch [0/26] Loss: 0.1618 LR: 0.000100
Epoch [43] Batch [10/26] Loss: 0.1198 LR: 0.000100
Epoch [43] Batch [20/26] Loss: 0.4736 LR: 0.000100

Epoch [44/350] - Time: 4.17s
Train Loss: 0.1898 | Val Loss: 3.6134
Train Acc: 0.9314 | Val Acc: 0.4525
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.994    Count 2: 0.484    Count 3: 0.630    Count 4: 0.610    Count 5: 0.382  
  Count 6: 0.306    Count 7: 0.000    Count 8: 0.111    Count 9: 0.478    Count 10: 0.102  
Epoch [44] Batch [0/26] Loss: 0.2747 LR: 0.000100
Epoch [44] Batch [10/26] Loss: 0.2006 LR: 0.000100
Epoch [44] Batch [20/26] Loss: 0.0516 LR: 0.000100

Epoch [45/350] - Time: 4.22s
Train Loss: 0.1757 | Val Loss: 3.1571
Train Acc: 0.9412 | Val Acc: 0.4981
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.667    Count 3: 0.676    Count 4: 0.667    Count 5: 0.549  
  Count 6: 0.224    Count 7: 0.073    Count 8: 0.131    Count 9: 0.367    Count 10: 0.295  
Epoch [45] Batch [0/26] Loss: 0.0541 LR: 0.000100
Epoch [45] Batch [10/26] Loss: 0.0516 LR: 0.000100
Epoch [45] Batch [20/26] Loss: 0.3153 LR: 0.000100

Epoch [46/350] - Time: 4.30s
Train Loss: 0.1719 | Val Loss: 3.7821
Train Acc: 0.9387 | Val Acc: 0.4525
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.981    Count 2: 0.683    Count 3: 0.602    Count 4: 0.495    Count 5: 0.363  
  Count 6: 0.276    Count 7: 0.010    Count 8: 0.081    Count 9: 0.411    Count 10: 0.159  
Epoch [46] Batch [0/26] Loss: 0.0596 LR: 0.000100
Epoch [46] Batch [10/26] Loss: 0.1525 LR: 0.000100
Epoch [46] Batch [20/26] Loss: 0.1719 LR: 0.000100

Epoch [47/350] - Time: 4.24s
Train Loss: 0.1359 | Val Loss: 4.0997
Train Acc: 0.9583 | Val Acc: 0.4544
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.746    Count 3: 0.565    Count 4: 0.733    Count 5: 0.490  
  Count 6: 0.143    Count 7: 0.052    Count 8: 0.081    Count 9: 0.189    Count 10: 0.182  
Epoch [47] Batch [0/26] Loss: 0.0817 LR: 0.000100
Epoch [47] Batch [10/26] Loss: 0.2024 LR: 0.000100
Epoch [47] Batch [20/26] Loss: 0.7791 LR: 0.000100

Epoch [48/350] - Time: 4.15s
Train Loss: 0.1927 | Val Loss: 3.2588
Train Acc: 0.9191 | Val Acc: 0.4963
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.667    Count 3: 0.546    Count 4: 0.686    Count 5: 0.441  
  Count 6: 0.327    Count 7: 0.010    Count 8: 0.283    Count 9: 0.389    Count 10: 0.227  
Epoch [48] Batch [0/26] Loss: 0.1233 LR: 0.000100
Epoch [48] Batch [10/26] Loss: 0.0398 LR: 0.000100
Epoch [48] Batch [20/26] Loss: 0.4908 LR: 0.000100

Epoch [49/350] - Time: 4.25s
Train Loss: 0.1951 | Val Loss: 3.7105
Train Acc: 0.9216 | Val Acc: 0.4814
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.667    Count 3: 0.519    Count 4: 0.676    Count 5: 0.608  
  Count 6: 0.214    Count 7: 0.021    Count 8: 0.131    Count 9: 0.333    Count 10: 0.250  
Epoch [49] Batch [0/26] Loss: 0.1117 LR: 0.000100
Epoch [49] Batch [10/26] Loss: 0.1477 LR: 0.000100
Epoch [49] Batch [20/26] Loss: 0.1716 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [50/350] - Time: 4.16s
Train Loss: 0.1809 | Val Loss: 3.5074
Train Acc: 0.9240 | Val Acc: 0.4702
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.611    Count 3: 0.509    Count 4: 0.571    Count 5: 0.412  
  Count 6: 0.378    Count 7: 0.146    Count 8: 0.162    Count 9: 0.422    Count 10: 0.227  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_49.pth
Epoch [50] Batch [0/26] Loss: 0.0507 LR: 0.000100
Epoch [50] Batch [10/26] Loss: 0.0784 LR: 0.000100
Epoch [50] Batch [20/26] Loss: 0.0337 LR: 0.000100

Epoch [51/350] - Time: 4.50s
Train Loss: 0.1097 | Val Loss: 4.2458
Train Acc: 0.9632 | Val Acc: 0.4236
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.957    Count 2: 0.619    Count 3: 0.676    Count 4: 0.429    Count 5: 0.216  
  Count 6: 0.214    Count 7: 0.000    Count 8: 0.101    Count 9: 0.378    Count 10: 0.193  
Epoch [51] Batch [0/26] Loss: 0.1773 LR: 0.000100
Epoch [51] Batch [10/26] Loss: 0.1095 LR: 0.000100
Epoch [51] Batch [20/26] Loss: 0.1323 LR: 0.000100

Epoch [52/350] - Time: 4.18s
Train Loss: 0.1697 | Val Loss: 4.1229
Train Acc: 0.9412 | Val Acc: 0.4534
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.651    Count 3: 0.454    Count 4: 0.686    Count 5: 0.569  
  Count 6: 0.255    Count 7: 0.010    Count 8: 0.152    Count 9: 0.244    Count 10: 0.159  
Epoch [52] Batch [0/26] Loss: 0.0330 LR: 0.000100
Epoch [52] Batch [10/26] Loss: 0.1039 LR: 0.000100
Epoch [52] Batch [20/26] Loss: 0.0410 LR: 0.000100

Epoch [53/350] - Time: 4.31s
Train Loss: 0.0934 | Val Loss: 4.4056
Train Acc: 0.9657 | Val Acc: 0.4413
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.809    Count 2: 0.619    Count 3: 0.491    Count 4: 0.581    Count 5: 0.539  
  Count 6: 0.255    Count 7: 0.073    Count 8: 0.232    Count 9: 0.267    Count 10: 0.193  
Epoch [53] Batch [0/26] Loss: 0.0246 LR: 0.000100
Epoch [53] Batch [10/26] Loss: 0.1879 LR: 0.000100
Epoch [53] Batch [20/26] Loss: 0.0866 LR: 0.000100

Epoch [54/350] - Time: 4.28s
Train Loss: 0.1346 | Val Loss: 5.0266
Train Acc: 0.9485 | Val Acc: 0.4404
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.532    Count 3: 0.537    Count 4: 0.524    Count 5: 0.363  
  Count 6: 0.408    Count 7: 0.052    Count 8: 0.162    Count 9: 0.278    Count 10: 0.284  
Epoch [54] Batch [0/26] Loss: 0.0716 LR: 0.000100
Epoch [54] Batch [10/26] Loss: 0.0202 LR: 0.000100
Epoch [54] Batch [20/26] Loss: 0.1066 LR: 0.000100

Epoch [55/350] - Time: 4.11s
Train Loss: 0.1239 | Val Loss: 4.3261
Train Acc: 0.9510 | Val Acc: 0.4683
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.627    Count 3: 0.509    Count 4: 0.705    Count 5: 0.559  
  Count 6: 0.184    Count 7: 0.042    Count 8: 0.162    Count 9: 0.322    Count 10: 0.205  
Epoch [55] Batch [0/26] Loss: 0.0599 LR: 0.000100
Epoch [55] Batch [10/26] Loss: 0.3458 LR: 0.000100
Epoch [55] Batch [20/26] Loss: 0.1729 LR: 0.000100

Epoch [56/350] - Time: 4.26s
Train Loss: 0.1234 | Val Loss: 4.9867
Train Acc: 0.9583 | Val Acc: 0.4488
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.667    Count 3: 0.565    Count 4: 0.667    Count 5: 0.520  
  Count 6: 0.194    Count 7: 0.031    Count 8: 0.101    Count 9: 0.222    Count 10: 0.148  
Epoch [56] Batch [0/26] Loss: 0.1518 LR: 0.000100
Epoch [56] Batch [10/26] Loss: 0.0792 LR: 0.000100
Epoch [56] Batch [20/26] Loss: 0.0657 LR: 0.000100

Epoch [57/350] - Time: 4.23s
Train Loss: 0.0582 | Val Loss: 4.5055
Train Acc: 0.9755 | Val Acc: 0.4916
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.659    Count 3: 0.611    Count 4: 0.600    Count 5: 0.412  
  Count 6: 0.327    Count 7: 0.073    Count 8: 0.141    Count 9: 0.422    Count 10: 0.341  
Epoch [57] Batch [0/26] Loss: 0.0554 LR: 0.000100
Epoch [57] Batch [10/26] Loss: 0.1568 LR: 0.000100
Epoch [57] Batch [20/26] Loss: 0.0130 LR: 0.000100

Epoch [58/350] - Time: 4.27s
Train Loss: 0.0665 | Val Loss: 5.0651
Train Acc: 0.9632 | Val Acc: 0.4283
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.619    Count 3: 0.491    Count 4: 0.457    Count 5: 0.324  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.141    Count 9: 0.311    Count 10: 0.284  
Epoch [58] Batch [0/26] Loss: 0.0160 LR: 0.000100
Epoch [58] Batch [10/26] Loss: 0.0524 LR: 0.000100
Epoch [58] Batch [20/26] Loss: 0.0516 LR: 0.000100

Epoch [59/350] - Time: 4.35s
Train Loss: 0.1246 | Val Loss: 5.1616
Train Acc: 0.9681 | Val Acc: 0.4497
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.587    Count 3: 0.676    Count 4: 0.562    Count 5: 0.265  
  Count 6: 0.388    Count 7: 0.010    Count 8: 0.131    Count 9: 0.322    Count 10: 0.250  
Epoch [59] Batch [0/26] Loss: 0.1946 LR: 0.000100
Epoch [59] Batch [10/26] Loss: 0.0592 LR: 0.000100
Epoch [59] Batch [20/26] Loss: 0.0273 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [60/350] - Time: 4.15s
Train Loss: 0.0799 | Val Loss: 4.2341
Train Acc: 0.9657 | Val Acc: 0.5028
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.683    Count 3: 0.519    Count 4: 0.590    Count 5: 0.588  
  Count 6: 0.286    Count 7: 0.115    Count 8: 0.232    Count 9: 0.422    Count 10: 0.295  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_59.pth
Epoch [60] Batch [0/26] Loss: 0.0562 LR: 0.000100
Epoch [60] Batch [10/26] Loss: 0.0232 LR: 0.000100
Epoch [60] Batch [20/26] Loss: 0.0093 LR: 0.000100

Epoch [61/350] - Time: 4.21s
Train Loss: 0.0878 | Val Loss: 5.3270
Train Acc: 0.9779 | Val Acc: 0.4507
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.643    Count 3: 0.472    Count 4: 0.676    Count 5: 0.431  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.141    Count 9: 0.289    Count 10: 0.307  
Epoch [61] Batch [0/26] Loss: 0.2438 LR: 0.000100
Epoch [61] Batch [10/26] Loss: 0.1389 LR: 0.000100
Epoch [61] Batch [20/26] Loss: 0.0194 LR: 0.000100

Epoch [62/350] - Time: 4.20s
Train Loss: 0.1029 | Val Loss: 4.7751
Train Acc: 0.9583 | Val Acc: 0.4553
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.603    Count 3: 0.648    Count 4: 0.524    Count 5: 0.343  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.152    Count 9: 0.433    Count 10: 0.205  
Epoch [62] Batch [0/26] Loss: 0.0441 LR: 0.000100
Epoch [62] Batch [10/26] Loss: 0.2752 LR: 0.000100
Epoch [62] Batch [20/26] Loss: 0.0126 LR: 0.000100

Epoch [63/350] - Time: 4.25s
Train Loss: 0.1368 | Val Loss: 5.3691
Train Acc: 0.9559 | Val Acc: 0.4637
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.981    Count 2: 0.627    Count 3: 0.667    Count 4: 0.571    Count 5: 0.382  
  Count 6: 0.245    Count 7: 0.010    Count 8: 0.040    Count 9: 0.344    Count 10: 0.330  
Epoch [63] Batch [0/26] Loss: 0.0081 LR: 0.000100
Epoch [63] Batch [10/26] Loss: 0.2613 LR: 0.000100
Epoch [63] Batch [20/26] Loss: 0.0512 LR: 0.000100

Epoch [64/350] - Time: 4.17s
Train Loss: 0.0954 | Val Loss: 5.3156
Train Acc: 0.9681 | Val Acc: 0.4255
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.858    Count 2: 0.492    Count 3: 0.241    Count 4: 0.305    Count 5: 0.500  
  Count 6: 0.286    Count 7: 0.240    Count 8: 0.333    Count 9: 0.411    Count 10: 0.295  
Epoch [64] Batch [0/26] Loss: 0.0087 LR: 0.000100
Epoch [64] Batch [10/26] Loss: 0.0075 LR: 0.000100
Epoch [64] Batch [20/26] Loss: 0.0023 LR: 0.000100

Epoch [65/350] - Time: 4.18s
Train Loss: 0.1243 | Val Loss: 5.5692
Train Acc: 0.9608 | Val Acc: 0.4348
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.548    Count 3: 0.519    Count 4: 0.667    Count 5: 0.265  
  Count 6: 0.255    Count 7: 0.010    Count 8: 0.141    Count 9: 0.367    Count 10: 0.216  
Epoch [65] Batch [0/26] Loss: 0.0132 LR: 0.000100
Epoch [65] Batch [10/26] Loss: 0.0221 LR: 0.000100
Epoch [65] Batch [20/26] Loss: 0.2598 LR: 0.000100

Epoch [66/350] - Time: 4.13s
Train Loss: 0.0462 | Val Loss: 6.0433
Train Acc: 0.9902 | Val Acc: 0.4581
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.619    Count 3: 0.657    Count 4: 0.590    Count 5: 0.363  
  Count 6: 0.327    Count 7: 0.031    Count 8: 0.111    Count 9: 0.322    Count 10: 0.227  
Epoch [66] Batch [0/26] Loss: 0.2151 LR: 0.000100
Epoch [66] Batch [10/26] Loss: 0.6644 LR: 0.000100
Epoch [66] Batch [20/26] Loss: 0.0153 LR: 0.000100

Epoch [67/350] - Time: 4.48s
Train Loss: 0.1124 | Val Loss: 5.2075
Train Acc: 0.9681 | Val Acc: 0.4795
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.651    Count 3: 0.565    Count 4: 0.657    Count 5: 0.363  
  Count 6: 0.316    Count 7: 0.000    Count 8: 0.162    Count 9: 0.478    Count 10: 0.227  
Epoch [67] Batch [0/26] Loss: 0.1704 LR: 0.000100
Epoch [67] Batch [10/26] Loss: 0.0049 LR: 0.000100
Epoch [67] Batch [20/26] Loss: 0.0215 LR: 0.000100

Epoch [68/350] - Time: 4.29s
Train Loss: 0.0701 | Val Loss: 5.7908
Train Acc: 0.9804 | Val Acc: 0.4767
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.714    Count 3: 0.556    Count 4: 0.648    Count 5: 0.490  
  Count 6: 0.143    Count 7: 0.073    Count 8: 0.131    Count 9: 0.356    Count 10: 0.398  
Epoch [68] Batch [0/26] Loss: 0.3154 LR: 0.000100
Epoch [68] Batch [10/26] Loss: 0.2271 LR: 0.000100
Epoch [68] Batch [20/26] Loss: 0.0021 LR: 0.000100

Epoch [69/350] - Time: 4.17s
Train Loss: 0.0871 | Val Loss: 5.4961
Train Acc: 0.9730 | Val Acc: 0.4562
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.635    Count 3: 0.546    Count 4: 0.733    Count 5: 0.284  
  Count 6: 0.367    Count 7: 0.021    Count 8: 0.131    Count 9: 0.278    Count 10: 0.307  
Epoch [69] Batch [0/26] Loss: 0.1781 LR: 0.000100
Epoch [69] Batch [10/26] Loss: 0.2230 LR: 0.000100
Epoch [69] Batch [20/26] Loss: 0.0127 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [70/350] - Time: 4.31s
Train Loss: 0.0581 | Val Loss: 7.0005
Train Acc: 0.9706 | Val Acc: 0.4376
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.714    Count 3: 0.602    Count 4: 0.733    Count 5: 0.343  
  Count 6: 0.214    Count 7: 0.000    Count 8: 0.101    Count 9: 0.222    Count 10: 0.091  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_69.pth
Epoch [70] Batch [0/26] Loss: 0.0085 LR: 0.000100
Epoch [70] Batch [10/26] Loss: 0.0169 LR: 0.000100
Epoch [70] Batch [20/26] Loss: 0.0785 LR: 0.000100

Epoch [71/350] - Time: 4.22s
Train Loss: 0.1519 | Val Loss: 6.7277
Train Acc: 0.9461 | Val Acc: 0.3948
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.532    Count 3: 0.602    Count 4: 0.448    Count 5: 0.108  
  Count 6: 0.214    Count 7: 0.000    Count 8: 0.071    Count 9: 0.356    Count 10: 0.193  
Epoch [71] Batch [0/26] Loss: 0.6269 LR: 0.000100
Epoch [71] Batch [10/26] Loss: 0.0074 LR: 0.000100
Epoch [71] Batch [20/26] Loss: 0.2022 LR: 0.000100

Epoch [72/350] - Time: 4.18s
Train Loss: 0.0779 | Val Loss: 5.6151
Train Acc: 0.9706 | Val Acc: 0.4730
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.667    Count 3: 0.611    Count 4: 0.676    Count 5: 0.255  
  Count 6: 0.255    Count 7: 0.073    Count 8: 0.152    Count 9: 0.356    Count 10: 0.409  
Epoch [72] Batch [0/26] Loss: 0.0047 LR: 0.000100
Epoch [72] Batch [10/26] Loss: 0.1770 LR: 0.000100
Epoch [72] Batch [20/26] Loss: 0.0117 LR: 0.000100

Epoch [73/350] - Time: 4.12s
Train Loss: 0.1106 | Val Loss: 6.0913
Train Acc: 0.9632 | Val Acc: 0.4451
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.603    Count 3: 0.611    Count 4: 0.619    Count 5: 0.265  
  Count 6: 0.327    Count 7: 0.000    Count 8: 0.141    Count 9: 0.400    Count 10: 0.205  
Epoch [73] Batch [0/26] Loss: 0.0270 LR: 0.000100
Epoch [73] Batch [10/26] Loss: 0.0012 LR: 0.000100
Epoch [73] Batch [20/26] Loss: 0.0346 LR: 0.000100

Epoch [74/350] - Time: 4.15s
Train Loss: 0.0680 | Val Loss: 6.0477
Train Acc: 0.9804 | Val Acc: 0.4451
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.643    Count 3: 0.611    Count 4: 0.438    Count 5: 0.392  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.111    Count 9: 0.256    Count 10: 0.330  
Epoch [74] Batch [0/26] Loss: 0.0588 LR: 0.000100
Epoch [74] Batch [10/26] Loss: 0.0005 LR: 0.000100
Epoch [74] Batch [20/26] Loss: 0.0193 LR: 0.000100

Epoch [75/350] - Time: 4.47s
Train Loss: 0.1659 | Val Loss: 6.1187
Train Acc: 0.9412 | Val Acc: 0.3836
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.741    Count 2: 0.460    Count 3: 0.241    Count 4: 0.486    Count 5: 0.373  
  Count 6: 0.337    Count 7: 0.062    Count 8: 0.162    Count 9: 0.400    Count 10: 0.318  
Epoch [75] Batch [0/26] Loss: 1.8998 LR: 0.000100
Epoch [75] Batch [10/26] Loss: 0.0058 LR: 0.000100
Epoch [75] Batch [20/26] Loss: 0.0803 LR: 0.000100

Epoch [76/350] - Time: 4.22s
Train Loss: 0.1561 | Val Loss: 5.9270
Train Acc: 0.9608 | Val Acc: 0.4572
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.706    Count 3: 0.435    Count 4: 0.590    Count 5: 0.471  
  Count 6: 0.347    Count 7: 0.083    Count 8: 0.152    Count 9: 0.244    Count 10: 0.295  
Epoch [76] Batch [0/26] Loss: 0.0244 LR: 0.000100
Epoch [76] Batch [10/26] Loss: 0.0089 LR: 0.000100
Epoch [76] Batch [20/26] Loss: 0.0008 LR: 0.000100

Epoch [77/350] - Time: 4.19s
Train Loss: 0.0670 | Val Loss: 6.2374
Train Acc: 0.9804 | Val Acc: 0.4581
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.683    Count 3: 0.463    Count 4: 0.686    Count 5: 0.539  
  Count 6: 0.163    Count 7: 0.010    Count 8: 0.141    Count 9: 0.233    Count 10: 0.273  
Epoch [77] Batch [0/26] Loss: 0.3417 LR: 0.000100
Epoch [77] Batch [10/26] Loss: 0.0319 LR: 0.000100
Epoch [77] Batch [20/26] Loss: 0.0352 LR: 0.000100

Epoch [78/350] - Time: 4.25s
Train Loss: 0.0437 | Val Loss: 6.2348
Train Acc: 0.9877 | Val Acc: 0.4395
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.858    Count 2: 0.468    Count 3: 0.426    Count 4: 0.505    Count 5: 0.490  
  Count 6: 0.357    Count 7: 0.115    Count 8: 0.172    Count 9: 0.400    Count 10: 0.295  
Epoch [78] Batch [0/26] Loss: 0.0202 LR: 0.000100
Epoch [78] Batch [10/26] Loss: 0.0238 LR: 0.000100
Epoch [78] Batch [20/26] Loss: 0.0146 LR: 0.000100

Epoch [79/350] - Time: 4.17s
Train Loss: 0.0331 | Val Loss: 6.2043
Train Acc: 0.9877 | Val Acc: 0.4311
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.579    Count 3: 0.472    Count 4: 0.657    Count 5: 0.245  
  Count 6: 0.204    Count 7: 0.052    Count 8: 0.101    Count 9: 0.378    Count 10: 0.295  
Epoch [79] Batch [0/26] Loss: 0.0048 LR: 0.000100
Epoch [79] Batch [10/26] Loss: 0.0012 LR: 0.000100
Epoch [79] Batch [20/26] Loss: 0.0514 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [80/350] - Time: 4.22s
Train Loss: 0.0701 | Val Loss: 6.7381
Train Acc: 0.9853 | Val Acc: 0.4330
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.603    Count 3: 0.417    Count 4: 0.505    Count 5: 0.569  
  Count 6: 0.224    Count 7: 0.062    Count 8: 0.172    Count 9: 0.278    Count 10: 0.295  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_79.pth
Epoch [80] Batch [0/26] Loss: 0.2487 LR: 0.000100
Epoch [80] Batch [10/26] Loss: 0.2328 LR: 0.000100
Epoch [80] Batch [20/26] Loss: 0.4103 LR: 0.000100

Epoch [81/350] - Time: 4.10s
Train Loss: 0.0945 | Val Loss: 5.8353
Train Acc: 0.9681 | Val Acc: 0.4907
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.698    Count 3: 0.611    Count 4: 0.657    Count 5: 0.431  
  Count 6: 0.265    Count 7: 0.052    Count 8: 0.152    Count 9: 0.322    Count 10: 0.364  
Epoch [81] Batch [0/26] Loss: 0.0485 LR: 0.000100
Epoch [81] Batch [10/26] Loss: 0.0023 LR: 0.000100
Epoch [81] Batch [20/26] Loss: 0.0071 LR: 0.000100

Epoch [82/350] - Time: 4.18s
Train Loss: 0.0184 | Val Loss: 6.4758
Train Acc: 0.9975 | Val Acc: 0.4693
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.683    Count 3: 0.528    Count 4: 0.562    Count 5: 0.353  
  Count 6: 0.378    Count 7: 0.073    Count 8: 0.131    Count 9: 0.400    Count 10: 0.341  
Epoch [82] Batch [0/26] Loss: 0.0042 LR: 0.000100
Epoch [82] Batch [10/26] Loss: 0.0003 LR: 0.000100
Epoch [82] Batch [20/26] Loss: 0.0096 LR: 0.000100

Epoch [83/350] - Time: 4.12s
Train Loss: 0.0724 | Val Loss: 6.0070
Train Acc: 0.9853 | Val Acc: 0.4655
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.714    Count 3: 0.472    Count 4: 0.648    Count 5: 0.402  
  Count 6: 0.245    Count 7: 0.042    Count 8: 0.131    Count 9: 0.356    Count 10: 0.364  
Epoch [83] Batch [0/26] Loss: 0.0004 LR: 0.000100
Epoch [83] Batch [10/26] Loss: 0.0003 LR: 0.000100
Epoch [83] Batch [20/26] Loss: 0.0033 LR: 0.000100

Epoch [84/350] - Time: 4.44s
Train Loss: 0.0059 | Val Loss: 6.9019
Train Acc: 0.9975 | Val Acc: 0.4264
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.675    Count 3: 0.315    Count 4: 0.733    Count 5: 0.294  
  Count 6: 0.153    Count 7: 0.042    Count 8: 0.051    Count 9: 0.300    Count 10: 0.364  
Epoch [84] Batch [0/26] Loss: 0.2020 LR: 0.000100
Epoch [84] Batch [10/26] Loss: 0.1006 LR: 0.000100
Epoch [84] Batch [20/26] Loss: 0.0006 LR: 0.000100

Epoch [85/350] - Time: 4.23s
Train Loss: 0.0857 | Val Loss: 6.7059
Train Acc: 0.9657 | Val Acc: 0.4469
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.975    Count 2: 0.603    Count 3: 0.519    Count 4: 0.619    Count 5: 0.392  
  Count 6: 0.224    Count 7: 0.042    Count 8: 0.131    Count 9: 0.256    Count 10: 0.261  
Epoch [85] Batch [0/26] Loss: 0.1305 LR: 0.000100
Epoch [85] Batch [10/26] Loss: 0.0005 LR: 0.000100
Epoch [85] Batch [20/26] Loss: 0.1282 LR: 0.000100

Epoch [86/350] - Time: 4.14s
Train Loss: 0.0624 | Val Loss: 6.0018
Train Acc: 0.9853 | Val Acc: 0.4674
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.643    Count 3: 0.556    Count 4: 0.619    Count 5: 0.245  
  Count 6: 0.245    Count 7: 0.042    Count 8: 0.172    Count 9: 0.456    Count 10: 0.409  
Epoch [86] Batch [0/26] Loss: 0.0003 LR: 0.000100
Epoch [86] Batch [10/26] Loss: 0.1210 LR: 0.000100
Epoch [86] Batch [20/26] Loss: 0.0075 LR: 0.000100

Epoch [87/350] - Time: 4.16s
Train Loss: 0.0749 | Val Loss: 6.3685
Train Acc: 0.9804 | Val Acc: 0.4423
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.651    Count 3: 0.407    Count 4: 0.686    Count 5: 0.353  
  Count 6: 0.224    Count 7: 0.042    Count 8: 0.212    Count 9: 0.333    Count 10: 0.239  
Epoch [87] Batch [0/26] Loss: 0.0126 LR: 0.000100
Epoch [87] Batch [10/26] Loss: 0.0019 LR: 0.000100
Epoch [87] Batch [20/26] Loss: 0.0005 LR: 0.000100

Epoch [88/350] - Time: 4.21s
Train Loss: 0.0322 | Val Loss: 6.0789
Train Acc: 0.9877 | Val Acc: 0.4609
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.571    Count 3: 0.528    Count 4: 0.648    Count 5: 0.569  
  Count 6: 0.204    Count 7: 0.052    Count 8: 0.202    Count 9: 0.222    Count 10: 0.216  
Epoch [88] Batch [0/26] Loss: 0.2006 LR: 0.000100
Epoch [88] Batch [10/26] Loss: 0.0843 LR: 0.000100
Epoch [88] Batch [20/26] Loss: 0.0072 LR: 0.000100

Epoch [89/350] - Time: 4.08s
Train Loss: 0.0655 | Val Loss: 6.9735
Train Acc: 0.9755 | Val Acc: 0.4395
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.651    Count 3: 0.500    Count 4: 0.657    Count 5: 0.392  
  Count 6: 0.153    Count 7: 0.000    Count 8: 0.061    Count 9: 0.367    Count 10: 0.227  
Epoch [89] Batch [0/26] Loss: 0.0111 LR: 0.000100
Epoch [89] Batch [10/26] Loss: 0.0017 LR: 0.000100
Epoch [89] Batch [20/26] Loss: 0.0005 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [90/350] - Time: 4.19s
Train Loss: 0.0395 | Val Loss: 8.1776
Train Acc: 0.9853 | Val Acc: 0.4320
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.706    Count 3: 0.639    Count 4: 0.648    Count 5: 0.284  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.040    Count 9: 0.256    Count 10: 0.239  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_89.pth
Epoch [90] Batch [0/26] Loss: 0.0004 LR: 0.000100
Epoch [90] Batch [10/26] Loss: 0.1747 LR: 0.000100
Epoch [90] Batch [20/26] Loss: 0.0003 LR: 0.000100

Epoch [91/350] - Time: 4.06s
Train Loss: 0.0291 | Val Loss: 7.4715
Train Acc: 0.9902 | Val Acc: 0.4236
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.690    Count 3: 0.398    Count 4: 0.686    Count 5: 0.373  
  Count 6: 0.245    Count 7: 0.000    Count 8: 0.111    Count 9: 0.178    Count 10: 0.205  
Epoch [91] Batch [0/26] Loss: 0.0189 LR: 0.000100
Epoch [91] Batch [10/26] Loss: 0.0039 LR: 0.000100
Epoch [91] Batch [20/26] Loss: 0.0547 LR: 0.000100

Epoch [92/350] - Time: 4.40s
Train Loss: 0.0352 | Val Loss: 7.0842
Train Acc: 0.9926 | Val Acc: 0.4255
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.563    Count 3: 0.491    Count 4: 0.619    Count 5: 0.324  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.141    Count 9: 0.300    Count 10: 0.216  
Epoch [92] Batch [0/26] Loss: 0.0010 LR: 0.000100
Epoch [92] Batch [10/26] Loss: 0.0010 LR: 0.000100
Epoch [92] Batch [20/26] Loss: 0.0101 LR: 0.000100

Epoch [93/350] - Time: 4.20s
Train Loss: 0.0176 | Val Loss: 7.5653
Train Acc: 0.9926 | Val Acc: 0.4525
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.714    Count 3: 0.481    Count 4: 0.657    Count 5: 0.373  
  Count 6: 0.224    Count 7: 0.000    Count 8: 0.081    Count 9: 0.322    Count 10: 0.318  
Epoch [93] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [93] Batch [10/26] Loss: 0.0034 LR: 0.000100
Epoch [93] Batch [20/26] Loss: 0.0016 LR: 0.000100

Epoch [94/350] - Time: 4.15s
Train Loss: 0.0075 | Val Loss: 7.5957
Train Acc: 0.9975 | Val Acc: 0.4432
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.667    Count 3: 0.435    Count 4: 0.648    Count 5: 0.480  
  Count 6: 0.224    Count 7: 0.010    Count 8: 0.131    Count 9: 0.322    Count 10: 0.227  
Epoch [94] Batch [0/26] Loss: 0.0017 LR: 0.000100
Epoch [94] Batch [10/26] Loss: 0.0696 LR: 0.000100
Epoch [94] Batch [20/26] Loss: 0.0002 LR: 0.000100

Epoch [95/350] - Time: 4.19s
Train Loss: 0.0052 | Val Loss: 7.8546
Train Acc: 0.9975 | Val Acc: 0.4358
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.603    Count 3: 0.324    Count 4: 0.571    Count 5: 0.608  
  Count 6: 0.224    Count 7: 0.031    Count 8: 0.172    Count 9: 0.289    Count 10: 0.250  
Epoch [95] Batch [0/26] Loss: 0.2810 LR: 0.000100
Epoch [95] Batch [10/26] Loss: 0.0011 LR: 0.000100
Epoch [95] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [96/350] - Time: 4.26s
Train Loss: 0.0283 | Val Loss: 8.0794
Train Acc: 0.9926 | Val Acc: 0.4236
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.611    Count 3: 0.444    Count 4: 0.705    Count 5: 0.431  
  Count 6: 0.224    Count 7: 0.000    Count 8: 0.141    Count 9: 0.200    Count 10: 0.193  
Epoch [96] Batch [0/26] Loss: 0.0004 LR: 0.000100
Epoch [96] Batch [10/26] Loss: 0.0004 LR: 0.000100
Epoch [96] Batch [20/26] Loss: 0.0177 LR: 0.000100

Epoch [97/350] - Time: 4.22s
Train Loss: 0.0381 | Val Loss: 8.2594
Train Acc: 0.9804 | Val Acc: 0.4097
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.571    Count 3: 0.565    Count 4: 0.429    Count 5: 0.245  
  Count 6: 0.337    Count 7: 0.000    Count 8: 0.121    Count 9: 0.233    Count 10: 0.216  
Epoch [97] Batch [0/26] Loss: 0.0117 LR: 0.000100
Epoch [97] Batch [10/26] Loss: 0.5251 LR: 0.000100
Epoch [97] Batch [20/26] Loss: 0.0253 LR: 0.000100

Epoch [98/350] - Time: 4.23s
Train Loss: 0.0639 | Val Loss: 7.1800
Train Acc: 0.9902 | Val Acc: 0.4553
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.635    Count 3: 0.444    Count 4: 0.733    Count 5: 0.363  
  Count 6: 0.265    Count 7: 0.000    Count 8: 0.152    Count 9: 0.278    Count 10: 0.364  
Epoch [98] Batch [0/26] Loss: 0.0016 LR: 0.000100
Epoch [98] Batch [10/26] Loss: 0.0017 LR: 0.000100
Epoch [98] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [99/350] - Time: 4.07s
Train Loss: 0.0293 | Val Loss: 7.4368
Train Acc: 0.9877 | Val Acc: 0.4348
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.579    Count 3: 0.333    Count 4: 0.695    Count 5: 0.480  
  Count 6: 0.214    Count 7: 0.010    Count 8: 0.131    Count 9: 0.300    Count 10: 0.273  
Epoch [99] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [99] Batch [10/26] Loss: 0.0006 LR: 0.000100
Epoch [99] Batch [20/26] Loss: 0.0448 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [100/350] - Time: 4.42s
Train Loss: 0.0215 | Val Loss: 7.4049
Train Acc: 0.9902 | Val Acc: 0.4600
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.556    Count 3: 0.509    Count 4: 0.657    Count 5: 0.382  
  Count 6: 0.235    Count 7: 0.104    Count 8: 0.131    Count 9: 0.322    Count 10: 0.420  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_99.pth
Epoch [100] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [100] Batch [10/26] Loss: 0.0046 LR: 0.000100
Epoch [100] Batch [20/26] Loss: 0.0037 LR: 0.000100

Epoch [101/350] - Time: 4.13s
Train Loss: 0.0226 | Val Loss: 7.8638
Train Acc: 0.9902 | Val Acc: 0.4292
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.659    Count 3: 0.537    Count 4: 0.600    Count 5: 0.216  
  Count 6: 0.265    Count 7: 0.000    Count 8: 0.172    Count 9: 0.256    Count 10: 0.250  
Epoch [101] Batch [0/26] Loss: 0.0044 LR: 0.000100
Epoch [101] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [101] Batch [20/26] Loss: 0.0726 LR: 0.000100

Epoch [102/350] - Time: 4.20s
Train Loss: 0.0199 | Val Loss: 7.1958
Train Acc: 0.9951 | Val Acc: 0.4404
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.571    Count 3: 0.546    Count 4: 0.629    Count 5: 0.235  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.182    Count 9: 0.367    Count 10: 0.273  
Epoch [102] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [102] Batch [10/26] Loss: 0.0018 LR: 0.000100
Epoch [102] Batch [20/26] Loss: 0.0009 LR: 0.000100

Epoch [103/350] - Time: 4.21s
Train Loss: 0.0214 | Val Loss: 8.1750
Train Acc: 0.9926 | Val Acc: 0.4199
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.595    Count 3: 0.509    Count 4: 0.590    Count 5: 0.314  
  Count 6: 0.235    Count 7: 0.000    Count 8: 0.121    Count 9: 0.167    Count 10: 0.227  
Epoch [103] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [103] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [103] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [104/350] - Time: 4.19s
Train Loss: 0.0114 | Val Loss: 7.3752
Train Acc: 0.9951 | Val Acc: 0.4264
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.524    Count 3: 0.472    Count 4: 0.543    Count 5: 0.206  
  Count 6: 0.224    Count 7: 0.083    Count 8: 0.111    Count 9: 0.344    Count 10: 0.420  
Epoch [104] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [104] Batch [10/26] Loss: 0.0006 LR: 0.000100
Epoch [104] Batch [20/26] Loss: 0.0003 LR: 0.000100

Epoch [105/350] - Time: 4.22s
Train Loss: 0.0253 | Val Loss: 7.7066
Train Acc: 0.9951 | Val Acc: 0.4469
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.595    Count 3: 0.574    Count 4: 0.629    Count 5: 0.343  
  Count 6: 0.306    Count 7: 0.010    Count 8: 0.152    Count 9: 0.300    Count 10: 0.295  
Epoch [105] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [105] Batch [10/26] Loss: 0.0005 LR: 0.000100
Epoch [105] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [106/350] - Time: 4.16s
Train Loss: 0.0029 | Val Loss: 8.5265
Train Acc: 1.0000 | Val Acc: 0.4143
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.619    Count 3: 0.546    Count 4: 0.590    Count 5: 0.275  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.121    Count 9: 0.167    Count 10: 0.216  
Epoch [106] Batch [0/26] Loss: 0.0004 LR: 0.000100
Epoch [106] Batch [10/26] Loss: 0.0019 LR: 0.000100
Epoch [106] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [107/350] - Time: 4.25s
Train Loss: 0.0125 | Val Loss: 7.4830
Train Acc: 0.9951 | Val Acc: 0.4469
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.603    Count 3: 0.519    Count 4: 0.610    Count 5: 0.500  
  Count 6: 0.245    Count 7: 0.000    Count 8: 0.162    Count 9: 0.267    Count 10: 0.250  
Epoch [107] Batch [0/26] Loss: 0.0033 LR: 0.000100
Epoch [107] Batch [10/26] Loss: 0.0036 LR: 0.000100
Epoch [107] Batch [20/26] Loss: 0.0877 LR: 0.000100

Epoch [108/350] - Time: 4.45s
Train Loss: 0.0119 | Val Loss: 8.8018
Train Acc: 0.9926 | Val Acc: 0.4153
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.579    Count 3: 0.537    Count 4: 0.581    Count 5: 0.245  
  Count 6: 0.327    Count 7: 0.000    Count 8: 0.141    Count 9: 0.200    Count 10: 0.159  
Epoch [108] Batch [0/26] Loss: 0.0033 LR: 0.000100
Epoch [108] Batch [10/26] Loss: 0.1194 LR: 0.000100
Epoch [108] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [109/350] - Time: 4.18s
Train Loss: 0.0184 | Val Loss: 7.7671
Train Acc: 0.9926 | Val Acc: 0.4311
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.563    Count 3: 0.398    Count 4: 0.648    Count 5: 0.304  
  Count 6: 0.214    Count 7: 0.052    Count 8: 0.162    Count 9: 0.333    Count 10: 0.284  
Epoch [109] Batch [0/26] Loss: 0.0009 LR: 0.000100
Epoch [109] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [109] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [110/350] - Time: 4.24s
Train Loss: 0.0040 | Val Loss: 8.9498
Train Acc: 1.0000 | Val Acc: 0.3827
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.571    Count 3: 0.481    Count 4: 0.495    Count 5: 0.186  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.091    Count 9: 0.144    Count 10: 0.159  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_109.pth
Epoch [110] Batch [0/26] Loss: 0.0039 LR: 0.000100
Epoch [110] Batch [10/26] Loss: 0.0003 LR: 0.000100
Epoch [110] Batch [20/26] Loss: 0.5389 LR: 0.000100

Epoch [111/350] - Time: 4.27s
Train Loss: 0.0454 | Val Loss: 7.9107
Train Acc: 0.9877 | Val Acc: 0.4497
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.587    Count 3: 0.454    Count 4: 0.771    Count 5: 0.412  
  Count 6: 0.194    Count 7: 0.031    Count 8: 0.081    Count 9: 0.311    Count 10: 0.364  
Epoch [111] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [111] Batch [10/26] Loss: 0.0080 LR: 0.000100
Epoch [111] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [112/350] - Time: 4.18s
Train Loss: 0.0303 | Val Loss: 8.0209
Train Acc: 0.9926 | Val Acc: 0.4637
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.651    Count 3: 0.500    Count 4: 0.724    Count 5: 0.363  
  Count 6: 0.286    Count 7: 0.021    Count 8: 0.111    Count 9: 0.311    Count 10: 0.409  
Epoch [112] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [112] Batch [10/26] Loss: 0.0003 LR: 0.000100
Epoch [112] Batch [20/26] Loss: 0.0009 LR: 0.000100

Epoch [113/350] - Time: 4.17s
Train Loss: 0.0169 | Val Loss: 7.5934
Train Acc: 0.9951 | Val Acc: 0.4674
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.667    Count 3: 0.398    Count 4: 0.686    Count 5: 0.402  
  Count 6: 0.245    Count 7: 0.094    Count 8: 0.162    Count 9: 0.389    Count 10: 0.375  
Epoch [113] Batch [0/26] Loss: 0.0014 LR: 0.000100
Epoch [113] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [113] Batch [20/26] Loss: 0.0016 LR: 0.000100

Epoch [114/350] - Time: 4.11s
Train Loss: 0.0012 | Val Loss: 8.5694
Train Acc: 1.0000 | Val Acc: 0.4376
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.675    Count 3: 0.463    Count 4: 0.667    Count 5: 0.245  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.101    Count 9: 0.289    Count 10: 0.295  
Epoch [114] Batch [0/26] Loss: 0.0008 LR: 0.000100
Epoch [114] Batch [10/26] Loss: 0.0363 LR: 0.000100
Epoch [114] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [115/350] - Time: 4.12s
Train Loss: 0.0530 | Val Loss: 7.5791
Train Acc: 0.9853 | Val Acc: 0.4469
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.852    Count 2: 0.556    Count 3: 0.407    Count 4: 0.562    Count 5: 0.422  
  Count 6: 0.327    Count 7: 0.062    Count 8: 0.212    Count 9: 0.456    Count 10: 0.295  
Epoch [115] Batch [0/26] Loss: 0.0053 LR: 0.000100
Epoch [115] Batch [10/26] Loss: 0.0005 LR: 0.000100
Epoch [115] Batch [20/26] Loss: 0.0039 LR: 0.000100

Epoch [116/350] - Time: 4.21s
Train Loss: 0.0669 | Val Loss: 7.6877
Train Acc: 0.9804 | Val Acc: 0.4385
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.975    Count 2: 0.611    Count 3: 0.528    Count 4: 0.581    Count 5: 0.245  
  Count 6: 0.224    Count 7: 0.010    Count 8: 0.141    Count 9: 0.256    Count 10: 0.375  
Epoch [116] Batch [0/26] Loss: 0.4952 LR: 0.000100
Epoch [116] Batch [10/26] Loss: 0.0095 LR: 0.000100
Epoch [116] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [117/350] - Time: 4.43s
Train Loss: 0.1058 | Val Loss: 8.0279
Train Acc: 0.9828 | Val Acc: 0.4469
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.627    Count 3: 0.407    Count 4: 0.638    Count 5: 0.373  
  Count 6: 0.255    Count 7: 0.021    Count 8: 0.121    Count 9: 0.433    Count 10: 0.295  
Epoch [117] Batch [0/26] Loss: 0.0004 LR: 0.000100
Epoch [117] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [117] Batch [20/26] Loss: 0.0004 LR: 0.000100

Epoch [118/350] - Time: 4.31s
Train Loss: 0.0143 | Val Loss: 9.3237
Train Acc: 0.9975 | Val Acc: 0.4115
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.796    Count 2: 0.690    Count 3: 0.380    Count 4: 0.629    Count 5: 0.392  
  Count 6: 0.214    Count 7: 0.000    Count 8: 0.111    Count 9: 0.300    Count 10: 0.227  
Epoch [118] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [118] Batch [10/26] Loss: 0.0298 LR: 0.000100
Epoch [118] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [119/350] - Time: 4.31s
Train Loss: 0.0097 | Val Loss: 9.7748
Train Acc: 0.9951 | Val Acc: 0.3976
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.548    Count 3: 0.500    Count 4: 0.629    Count 5: 0.176  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.111    Count 9: 0.189    Count 10: 0.148  
Epoch [119] Batch [0/26] Loss: 0.0012 LR: 0.000100
Epoch [119] Batch [10/26] Loss: 0.0028 LR: 0.000100
Epoch [119] Batch [20/26] Loss: 0.0001 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [120/350] - Time: 4.14s
Train Loss: 0.0456 | Val Loss: 9.1074
Train Acc: 0.9877 | Val Acc: 0.4264
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.579    Count 3: 0.537    Count 4: 0.695    Count 5: 0.324  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.040    Count 9: 0.278    Count 10: 0.250  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_119.pth
Epoch [120] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [120] Batch [10/26] Loss: 0.0300 LR: 0.000100
Epoch [120] Batch [20/26] Loss: 0.0087 LR: 0.000100

Epoch [121/350] - Time: 4.19s
Train Loss: 0.0135 | Val Loss: 9.5614
Train Acc: 0.9926 | Val Acc: 0.4032
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.476    Count 3: 0.556    Count 4: 0.648    Count 5: 0.147  
  Count 6: 0.276    Count 7: 0.010    Count 8: 0.121    Count 9: 0.300    Count 10: 0.216  
Epoch [121] Batch [0/26] Loss: 0.0040 LR: 0.000100
Epoch [121] Batch [10/26] Loss: 0.0008 LR: 0.000100
Epoch [121] Batch [20/26] Loss: 0.0206 LR: 0.000100

Epoch [122/350] - Time: 4.10s
Train Loss: 0.0747 | Val Loss: 7.3077
Train Acc: 0.9877 | Val Acc: 0.4730
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.651    Count 3: 0.454    Count 4: 0.629    Count 5: 0.422  
  Count 6: 0.255    Count 7: 0.031    Count 8: 0.222    Count 9: 0.378    Count 10: 0.443  
Epoch [122] Batch [0/26] Loss: 0.6943 LR: 0.000100
Epoch [122] Batch [10/26] Loss: 0.0328 LR: 0.000100
Epoch [122] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [123/350] - Time: 4.18s
Train Loss: 0.1232 | Val Loss: 7.7240
Train Acc: 0.9779 | Val Acc: 0.4441
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.516    Count 3: 0.481    Count 4: 0.543    Count 5: 0.363  
  Count 6: 0.265    Count 7: 0.062    Count 8: 0.131    Count 9: 0.411    Count 10: 0.477  
Epoch [123] Batch [0/26] Loss: 0.0241 LR: 0.000100
Epoch [123] Batch [10/26] Loss: 0.0032 LR: 0.000100
Epoch [123] Batch [20/26] Loss: 0.0027 LR: 0.000100

Epoch [124/350] - Time: 4.19s
Train Loss: 0.0280 | Val Loss: 7.6955
Train Acc: 0.9926 | Val Acc: 0.4758
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.643    Count 3: 0.556    Count 4: 0.648    Count 5: 0.284  
  Count 6: 0.204    Count 7: 0.208    Count 8: 0.121    Count 9: 0.378    Count 10: 0.466  
Epoch [124] Batch [0/26] Loss: 0.0007 LR: 0.000100
Epoch [124] Batch [10/26] Loss: 0.0002 LR: 0.000100
Epoch [124] Batch [20/26] Loss: 0.0569 LR: 0.000100

Epoch [125/350] - Time: 4.51s
Train Loss: 0.0681 | Val Loss: 9.8656
Train Acc: 0.9828 | Val Acc: 0.4162
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.548    Count 3: 0.583    Count 4: 0.476    Count 5: 0.127  
  Count 6: 0.316    Count 7: 0.000    Count 8: 0.131    Count 9: 0.489    Count 10: 0.091  
Epoch [125] Batch [0/26] Loss: 0.0275 LR: 0.000100
Epoch [125] Batch [10/26] Loss: 0.1252 LR: 0.000100
Epoch [125] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [126/350] - Time: 4.21s
Train Loss: 0.0393 | Val Loss: 8.6474
Train Acc: 0.9853 | Val Acc: 0.4451
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.659    Count 3: 0.398    Count 4: 0.695    Count 5: 0.402  
  Count 6: 0.224    Count 7: 0.000    Count 8: 0.131    Count 9: 0.411    Count 10: 0.239  
Epoch [126] Batch [0/26] Loss: 0.0005 LR: 0.000100
Epoch [126] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [126] Batch [20/26] Loss: 0.0002 LR: 0.000100

Epoch [127/350] - Time: 4.18s
Train Loss: 0.0013 | Val Loss: 7.9434
Train Acc: 1.0000 | Val Acc: 0.4507
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.595    Count 3: 0.519    Count 4: 0.705    Count 5: 0.382  
  Count 6: 0.214    Count 7: 0.031    Count 8: 0.141    Count 9: 0.311    Count 10: 0.318  
Epoch [127] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [127] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [127] Batch [20/26] Loss: 0.0077 LR: 0.000100

Epoch [128/350] - Time: 4.10s
Train Loss: 0.0013 | Val Loss: 8.1324
Train Acc: 1.0000 | Val Acc: 0.4385
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.500    Count 3: 0.519    Count 4: 0.600    Count 5: 0.216  
  Count 6: 0.408    Count 7: 0.000    Count 8: 0.182    Count 9: 0.422    Count 10: 0.250  
Epoch [128] Batch [0/26] Loss: 0.1713 LR: 0.000100
Epoch [128] Batch [10/26] Loss: 0.2769 LR: 0.000100
Epoch [128] Batch [20/26] Loss: 0.3209 LR: 0.000100

Epoch [129/350] - Time: 4.16s
Train Loss: 0.0371 | Val Loss: 8.5182
Train Acc: 0.9877 | Val Acc: 0.4590
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.603    Count 3: 0.630    Count 4: 0.590    Count 5: 0.392  
  Count 6: 0.316    Count 7: 0.000    Count 8: 0.141    Count 9: 0.322    Count 10: 0.330  
Epoch [129] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [129] Batch [10/26] Loss: 0.0275 LR: 0.000100
Epoch [129] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [130/350] - Time: 4.12s
Train Loss: 0.0047 | Val Loss: 8.1470
Train Acc: 0.9975 | Val Acc: 0.4618
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.635    Count 3: 0.528    Count 4: 0.657    Count 5: 0.324  
  Count 6: 0.245    Count 7: 0.000    Count 8: 0.222    Count 9: 0.344    Count 10: 0.295  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_129.pth
Epoch [130] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [130] Batch [10/26] Loss: 0.1801 LR: 0.000100
Epoch [130] Batch [20/26] Loss: 0.3711 LR: 0.000100

Epoch [131/350] - Time: 4.23s
Train Loss: 0.0381 | Val Loss: 7.8784
Train Acc: 0.9853 | Val Acc: 0.4488
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.858    Count 2: 0.643    Count 3: 0.324    Count 4: 0.629    Count 5: 0.382  
  Count 6: 0.173    Count 7: 0.094    Count 8: 0.152    Count 9: 0.489    Count 10: 0.420  
Epoch [131] Batch [0/26] Loss: 0.0014 LR: 0.000100
Epoch [131] Batch [10/26] Loss: 0.0002 LR: 0.000100
Epoch [131] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [132/350] - Time: 4.22s
Train Loss: 0.0539 | Val Loss: 8.5390
Train Acc: 0.9853 | Val Acc: 0.4572
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.659    Count 3: 0.352    Count 4: 0.724    Count 5: 0.314  
  Count 6: 0.296    Count 7: 0.021    Count 8: 0.121    Count 9: 0.433    Count 10: 0.307  
Epoch [132] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [132] Batch [10/26] Loss: 0.0006 LR: 0.000100
Epoch [132] Batch [20/26] Loss: 0.0010 LR: 0.000100

Epoch [133/350] - Time: 4.42s
Train Loss: 0.0031 | Val Loss: 8.5780
Train Acc: 1.0000 | Val Acc: 0.4367
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.690    Count 3: 0.343    Count 4: 0.590    Count 5: 0.363  
  Count 6: 0.214    Count 7: 0.000    Count 8: 0.111    Count 9: 0.522    Count 10: 0.261  
Epoch [133] Batch [0/26] Loss: 0.0014 LR: 0.000100
Epoch [133] Batch [10/26] Loss: 0.3105 LR: 0.000100
Epoch [133] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [134/350] - Time: 4.20s
Train Loss: 0.0131 | Val Loss: 8.9240
Train Acc: 0.9975 | Val Acc: 0.4413
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.659    Count 3: 0.444    Count 4: 0.619    Count 5: 0.382  
  Count 6: 0.214    Count 7: 0.010    Count 8: 0.121    Count 9: 0.344    Count 10: 0.261  
Epoch [134] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [134] Batch [10/26] Loss: 0.0007 LR: 0.000100
Epoch [134] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [135/350] - Time: 4.21s
Train Loss: 0.0478 | Val Loss: 9.0997
Train Acc: 0.9902 | Val Acc: 0.4451
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.548    Count 3: 0.500    Count 4: 0.619    Count 5: 0.275  
  Count 6: 0.316    Count 7: 0.010    Count 8: 0.141    Count 9: 0.489    Count 10: 0.284  
Epoch [135] Batch [0/26] Loss: 0.4607 LR: 0.000100
Epoch [135] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [135] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [136/350] - Time: 4.17s
Train Loss: 0.0359 | Val Loss: 9.8056
Train Acc: 0.9902 | Val Acc: 0.4320
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.540    Count 3: 0.500    Count 4: 0.590    Count 5: 0.235  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.131    Count 9: 0.467    Count 10: 0.227  
Epoch [136] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [136] Batch [10/26] Loss: 0.0009 LR: 0.000100
Epoch [136] Batch [20/26] Loss: 0.0002 LR: 0.000100

Epoch [137/350] - Time: 4.15s
Train Loss: 0.0025 | Val Loss: 9.3051
Train Acc: 1.0000 | Val Acc: 0.4209
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.651    Count 3: 0.491    Count 4: 0.657    Count 5: 0.314  
  Count 6: 0.184    Count 7: 0.010    Count 8: 0.091    Count 9: 0.256    Count 10: 0.205  
Epoch [137] Batch [0/26] Loss: 0.0003 LR: 0.000100
Epoch [137] Batch [10/26] Loss: 0.0003 LR: 0.000100
Epoch [137] Batch [20/26] Loss: 0.0011 LR: 0.000100

Epoch [138/350] - Time: 4.26s
Train Loss: 0.0027 | Val Loss: 10.4613
Train Acc: 1.0000 | Val Acc: 0.4078
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.957    Count 2: 0.524    Count 3: 0.519    Count 4: 0.533    Count 5: 0.127  
  Count 6: 0.316    Count 7: 0.000    Count 8: 0.152    Count 9: 0.467    Count 10: 0.045  
Epoch [138] Batch [0/26] Loss: 0.0016 LR: 0.000100
Epoch [138] Batch [10/26] Loss: 0.0008 LR: 0.000100
Epoch [138] Batch [20/26] Loss: 0.0004 LR: 0.000100

Epoch [139/350] - Time: 4.33s
Train Loss: 0.0079 | Val Loss: 9.8474
Train Acc: 0.9975 | Val Acc: 0.4320
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.706    Count 3: 0.398    Count 4: 0.705    Count 5: 0.157  
  Count 6: 0.265    Count 7: 0.021    Count 8: 0.101    Count 9: 0.356    Count 10: 0.295  
Epoch [139] Batch [0/26] Loss: 0.0013 LR: 0.000100
Epoch [139] Batch [10/26] Loss: 0.0136 LR: 0.000100
Epoch [139] Batch [20/26] Loss: 0.0001 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [140/350] - Time: 4.21s
Train Loss: 0.0123 | Val Loss: 8.8828
Train Acc: 0.9975 | Val Acc: 0.4609
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.595    Count 3: 0.519    Count 4: 0.648    Count 5: 0.324  
  Count 6: 0.316    Count 7: 0.073    Count 8: 0.141    Count 9: 0.422    Count 10: 0.364  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_139.pth
Epoch [140] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [140] Batch [10/26] Loss: 0.1982 LR: 0.000100
Epoch [140] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [141/350] - Time: 4.47s
Train Loss: 0.0147 | Val Loss: 9.0039
Train Acc: 0.9951 | Val Acc: 0.4451
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.548    Count 3: 0.583    Count 4: 0.619    Count 5: 0.333  
  Count 6: 0.276    Count 7: 0.031    Count 8: 0.162    Count 9: 0.389    Count 10: 0.330  
Epoch [141] Batch [0/26] Loss: 0.0004 LR: 0.000100
Epoch [141] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [141] Batch [20/26] Loss: 0.0107 LR: 0.000100

Epoch [142/350] - Time: 4.23s
Train Loss: 0.0053 | Val Loss: 9.3913
Train Acc: 0.9975 | Val Acc: 0.4358
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.706    Count 3: 0.296    Count 4: 0.695    Count 5: 0.343  
  Count 6: 0.194    Count 7: 0.052    Count 8: 0.192    Count 9: 0.311    Count 10: 0.250  
Epoch [142] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [142] Batch [10/26] Loss: 0.0013 LR: 0.000100
Epoch [142] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [143/350] - Time: 4.11s
Train Loss: 0.0393 | Val Loss: 9.7247
Train Acc: 0.9926 | Val Acc: 0.4339
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.556    Count 3: 0.546    Count 4: 0.714    Count 5: 0.304  
  Count 6: 0.184    Count 7: 0.000    Count 8: 0.202    Count 9: 0.267    Count 10: 0.205  
Epoch [143] Batch [0/26] Loss: 0.0004 LR: 0.000100
Epoch [143] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [143] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [144/350] - Time: 4.15s
Train Loss: 0.0219 | Val Loss: 8.6246
Train Acc: 0.9951 | Val Acc: 0.4581
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.587    Count 3: 0.454    Count 4: 0.657    Count 5: 0.255  
  Count 6: 0.245    Count 7: 0.073    Count 8: 0.303    Count 9: 0.422    Count 10: 0.318  
Epoch [144] Batch [0/26] Loss: 0.0141 LR: 0.000100
Epoch [144] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [144] Batch [20/26] Loss: 0.0063 LR: 0.000100

Epoch [145/350] - Time: 4.10s
Train Loss: 0.0280 | Val Loss: 9.2094
Train Acc: 0.9926 | Val Acc: 0.4460
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.563    Count 3: 0.435    Count 4: 0.724    Count 5: 0.451  
  Count 6: 0.184    Count 7: 0.031    Count 8: 0.162    Count 9: 0.289    Count 10: 0.330  
Epoch [145] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [145] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [145] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [146/350] - Time: 4.19s
Train Loss: 0.0074 | Val Loss: 10.0625
Train Acc: 0.9975 | Val Acc: 0.4134
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.500    Count 3: 0.398    Count 4: 0.590    Count 5: 0.314  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.131    Count 9: 0.367    Count 10: 0.205  
Epoch [146] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [146] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [146] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [147/350] - Time: 4.22s
Train Loss: 0.0408 | Val Loss: 10.0695
Train Acc: 0.9877 | Val Acc: 0.4367
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.659    Count 3: 0.343    Count 4: 0.714    Count 5: 0.294  
  Count 6: 0.286    Count 7: 0.010    Count 8: 0.101    Count 9: 0.367    Count 10: 0.295  
Epoch [147] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [147] Batch [10/26] Loss: 0.0573 LR: 0.000100
Epoch [147] Batch [20/26] Loss: 0.0002 LR: 0.000100

Epoch [148/350] - Time: 4.20s
Train Loss: 0.0491 | Val Loss: 9.7507
Train Acc: 0.9853 | Val Acc: 0.4106
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.413    Count 3: 0.454    Count 4: 0.686    Count 5: 0.314  
  Count 6: 0.378    Count 7: 0.000    Count 8: 0.141    Count 9: 0.322    Count 10: 0.023  
Epoch [148] Batch [0/26] Loss: 0.0113 LR: 0.000100
Epoch [148] Batch [10/26] Loss: 0.0132 LR: 0.000100
Epoch [148] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [149/350] - Time: 4.16s
Train Loss: 0.0587 | Val Loss: 9.4417
Train Acc: 0.9902 | Val Acc: 0.4451
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.476    Count 3: 0.676    Count 4: 0.629    Count 5: 0.196  
  Count 6: 0.265    Count 7: 0.021    Count 8: 0.192    Count 9: 0.467    Count 10: 0.205  
Epoch [149] Batch [0/26] Loss: 0.0011 LR: 0.000100
Epoch [149] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [149] Batch [20/26] Loss: 0.0004 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [150/350] - Time: 4.46s
Train Loss: 0.0338 | Val Loss: 10.2626
Train Acc: 0.9926 | Val Acc: 0.4181
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.579    Count 3: 0.565    Count 4: 0.676    Count 5: 0.275  
  Count 6: 0.255    Count 7: 0.010    Count 8: 0.071    Count 9: 0.289    Count 10: 0.273  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_149.pth
Epoch [150] Batch [0/26] Loss: 0.2565 LR: 0.000100
Epoch [150] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [150] Batch [20/26] Loss: 0.0003 LR: 0.000100

Epoch [151/350] - Time: 4.06s
Train Loss: 0.0151 | Val Loss: 8.9727
Train Acc: 0.9951 | Val Acc: 0.4516
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.651    Count 3: 0.509    Count 4: 0.562    Count 5: 0.284  
  Count 6: 0.255    Count 7: 0.010    Count 8: 0.141    Count 9: 0.422    Count 10: 0.341  
Epoch [151] Batch [0/26] Loss: 0.0015 LR: 0.000100
Epoch [151] Batch [10/26] Loss: 0.0002 LR: 0.000100
Epoch [151] Batch [20/26] Loss: 0.1803 LR: 0.000100

Epoch [152/350] - Time: 4.25s
Train Loss: 0.0114 | Val Loss: 9.9631
Train Acc: 0.9951 | Val Acc: 0.4106
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.858    Count 2: 0.587    Count 3: 0.435    Count 4: 0.705    Count 5: 0.373  
  Count 6: 0.214    Count 7: 0.000    Count 8: 0.141    Count 9: 0.167    Count 10: 0.216  
Epoch [152] Batch [0/26] Loss: 0.0011 LR: 0.000100
Epoch [152] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [152] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [153/350] - Time: 4.22s
Train Loss: 0.0075 | Val Loss: 9.6591
Train Acc: 0.9975 | Val Acc: 0.4423
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.667    Count 3: 0.333    Count 4: 0.705    Count 5: 0.294  
  Count 6: 0.235    Count 7: 0.000    Count 8: 0.202    Count 9: 0.467    Count 10: 0.170  
Epoch [153] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [153] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [153] Batch [20/26] Loss: 0.0013 LR: 0.000100

Epoch [154/350] - Time: 4.20s
Train Loss: 0.0090 | Val Loss: 9.2352
Train Acc: 0.9951 | Val Acc: 0.4544
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.556    Count 3: 0.537    Count 4: 0.600    Count 5: 0.284  
  Count 6: 0.367    Count 7: 0.000    Count 8: 0.192    Count 9: 0.478    Count 10: 0.182  
Epoch [154] Batch [0/26] Loss: 0.0400 LR: 0.000100
Epoch [154] Batch [10/26] Loss: 0.0019 LR: 0.000100
Epoch [154] Batch [20/26] Loss: 0.0031 LR: 0.000100

Epoch [155/350] - Time: 4.17s
Train Loss: 0.0501 | Val Loss: 9.3142
Train Acc: 0.9902 | Val Acc: 0.4358
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.619    Count 3: 0.296    Count 4: 0.686    Count 5: 0.559  
  Count 6: 0.153    Count 7: 0.042    Count 8: 0.141    Count 9: 0.289    Count 10: 0.330  
Epoch [155] Batch [0/26] Loss: 0.6229 LR: 0.000100
Epoch [155] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [155] Batch [20/26] Loss: 0.0002 LR: 0.000100

Epoch [156/350] - Time: 4.17s
Train Loss: 0.0254 | Val Loss: 9.7953
Train Acc: 0.9975 | Val Acc: 0.4236
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.981    Count 2: 0.540    Count 3: 0.472    Count 4: 0.552    Count 5: 0.216  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.111    Count 9: 0.433    Count 10: 0.205  
Epoch [156] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [156] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [156] Batch [20/26] Loss: 0.0017 LR: 0.000100

Epoch [157/350] - Time: 4.18s
Train Loss: 0.0541 | Val Loss: 9.2076
Train Acc: 0.9853 | Val Acc: 0.4376
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.468    Count 3: 0.407    Count 4: 0.657    Count 5: 0.373  
  Count 6: 0.296    Count 7: 0.031    Count 8: 0.192    Count 9: 0.411    Count 10: 0.227  
Epoch [157] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [157] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [157] Batch [20/26] Loss: 0.3587 LR: 0.000100

Epoch [158/350] - Time: 4.47s
Train Loss: 0.1192 | Val Loss: 9.8404
Train Acc: 0.9779 | Val Acc: 0.4060
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.975    Count 2: 0.532    Count 3: 0.417    Count 4: 0.590    Count 5: 0.225  
  Count 6: 0.184    Count 7: 0.000    Count 8: 0.121    Count 9: 0.333    Count 10: 0.239  
Epoch [158] Batch [0/26] Loss: 0.2690 LR: 0.000100
Epoch [158] Batch [10/26] Loss: 0.0018 LR: 0.000100
Epoch [158] Batch [20/26] Loss: 0.0002 LR: 0.000100

Epoch [159/350] - Time: 4.12s
Train Loss: 0.0398 | Val Loss: 9.3720
Train Acc: 0.9902 | Val Acc: 0.4320
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.571    Count 3: 0.574    Count 4: 0.638    Count 5: 0.314  
  Count 6: 0.286    Count 7: 0.000    Count 8: 0.121    Count 9: 0.322    Count 10: 0.125  
Epoch [159] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [159] Batch [10/26] Loss: 0.0353 LR: 0.000100
Epoch [159] Batch [20/26] Loss: 0.0015 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [160/350] - Time: 4.25s
Train Loss: 0.0445 | Val Loss: 9.8953
Train Acc: 0.9902 | Val Acc: 0.4330
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.556    Count 3: 0.407    Count 4: 0.667    Count 5: 0.343  
  Count 6: 0.255    Count 7: 0.010    Count 8: 0.172    Count 9: 0.467    Count 10: 0.205  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_159.pth
Epoch [160] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [160] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [160] Batch [20/26] Loss: 0.0036 LR: 0.000100

Epoch [161/350] - Time: 4.25s
Train Loss: 0.0116 | Val Loss: 11.9885
Train Acc: 0.9975 | Val Acc: 0.3780
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.667    Count 3: 0.417    Count 4: 0.486    Count 5: 0.245  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.101    Count 9: 0.122    Count 10: 0.148  
Epoch [161] Batch [0/26] Loss: 0.5895 LR: 0.000100
Epoch [161] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [161] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [162/350] - Time: 4.19s
Train Loss: 0.0310 | Val Loss: 10.0282
Train Acc: 0.9951 | Val Acc: 0.4134
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.667    Count 3: 0.398    Count 4: 0.657    Count 5: 0.363  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.111    Count 9: 0.200    Count 10: 0.239  
Epoch [162] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [162] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [162] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [163/350] - Time: 4.30s
Train Loss: 0.0066 | Val Loss: 9.9157
Train Acc: 0.9975 | Val Acc: 0.4134
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.611    Count 3: 0.444    Count 4: 0.667    Count 5: 0.333  
  Count 6: 0.276    Count 7: 0.010    Count 8: 0.152    Count 9: 0.167    Count 10: 0.193  
Epoch [163] Batch [0/26] Loss: 0.0005 LR: 0.000100
Epoch [163] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [163] Batch [20/26] Loss: 0.0008 LR: 0.000100

Epoch [164/350] - Time: 4.16s
Train Loss: 0.0130 | Val Loss: 9.6907
Train Acc: 0.9951 | Val Acc: 0.4367
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.643    Count 3: 0.444    Count 4: 0.676    Count 5: 0.373  
  Count 6: 0.194    Count 7: 0.010    Count 8: 0.141    Count 9: 0.256    Count 10: 0.318  
Epoch [164] Batch [0/26] Loss: 0.0012 LR: 0.000100
Epoch [164] Batch [10/26] Loss: 0.0002 LR: 0.000100
Epoch [164] Batch [20/26] Loss: 0.0006 LR: 0.000100

Epoch [165/350] - Time: 4.21s
Train Loss: 0.0003 | Val Loss: 9.0709
Train Acc: 1.0000 | Val Acc: 0.4358
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.619    Count 3: 0.398    Count 4: 0.619    Count 5: 0.373  
  Count 6: 0.173    Count 7: 0.000    Count 8: 0.253    Count 9: 0.333    Count 10: 0.250  
Epoch [165] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [165] Batch [10/26] Loss: 0.0570 LR: 0.000100
Epoch [165] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [166/350] - Time: 4.46s
Train Loss: 0.0024 | Val Loss: 9.8365
Train Acc: 0.9975 | Val Acc: 0.4199
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.635    Count 3: 0.407    Count 4: 0.571    Count 5: 0.314  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.091    Count 9: 0.333    Count 10: 0.330  
Epoch [166] Batch [0/26] Loss: 0.3005 LR: 0.000100
Epoch [166] Batch [10/26] Loss: 0.0002 LR: 0.000100
Epoch [166] Batch [20/26] Loss: 0.0003 LR: 0.000100

Epoch [167/350] - Time: 4.20s
Train Loss: 0.0119 | Val Loss: 9.2937
Train Acc: 0.9975 | Val Acc: 0.4702
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.587    Count 3: 0.574    Count 4: 0.571    Count 5: 0.284  
  Count 6: 0.347    Count 7: 0.010    Count 8: 0.333    Count 9: 0.367    Count 10: 0.341  
Epoch [167] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [167] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [167] Batch [20/26] Loss: 0.0003 LR: 0.000100

Epoch [168/350] - Time: 4.12s
Train Loss: 0.0001 | Val Loss: 9.5025
Train Acc: 1.0000 | Val Acc: 0.4562
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.611    Count 3: 0.537    Count 4: 0.590    Count 5: 0.343  
  Count 6: 0.296    Count 7: 0.010    Count 8: 0.182    Count 9: 0.367    Count 10: 0.341  
Epoch [168] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [168] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [168] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [169/350] - Time: 4.17s
Train Loss: 0.0001 | Val Loss: 9.6739
Train Acc: 1.0000 | Val Acc: 0.4320
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.587    Count 3: 0.454    Count 4: 0.562    Count 5: 0.304  
  Count 6: 0.245    Count 7: 0.000    Count 8: 0.162    Count 9: 0.367    Count 10: 0.273  
Epoch [169] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [169] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [169] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [170/350] - Time: 4.14s
Train Loss: 0.0000 | Val Loss: 9.6874
Train Acc: 1.0000 | Val Acc: 0.4562
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.643    Count 3: 0.454    Count 4: 0.705    Count 5: 0.412  
  Count 6: 0.245    Count 7: 0.000    Count 8: 0.162    Count 9: 0.356    Count 10: 0.273  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_169.pth
Epoch [170] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [170] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [170] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [171/350] - Time: 4.23s
Train Loss: 0.0002 | Val Loss: 9.5998
Train Acc: 1.0000 | Val Acc: 0.4497
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.508    Count 3: 0.537    Count 4: 0.667    Count 5: 0.412  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.192    Count 9: 0.367    Count 10: 0.273  
Epoch [171] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [171] Batch [10/26] Loss: 0.0032 LR: 0.000100
Epoch [171] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [172/350] - Time: 4.24s
Train Loss: 0.0247 | Val Loss: 10.0613
Train Acc: 0.9975 | Val Acc: 0.4367
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.556    Count 3: 0.380    Count 4: 0.657    Count 5: 0.382  
  Count 6: 0.265    Count 7: 0.010    Count 8: 0.172    Count 9: 0.378    Count 10: 0.250  
Epoch [172] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [172] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [172] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [173/350] - Time: 4.21s
Train Loss: 0.0073 | Val Loss: 10.5235
Train Acc: 0.9975 | Val Acc: 0.4246
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.722    Count 3: 0.370    Count 4: 0.571    Count 5: 0.353  
  Count 6: 0.194    Count 7: 0.010    Count 8: 0.131    Count 9: 0.289    Count 10: 0.295  
Epoch [173] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [173] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [173] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [174/350] - Time: 4.36s
Train Loss: 0.0107 | Val Loss: 10.5632
Train Acc: 0.9951 | Val Acc: 0.4274
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.500    Count 3: 0.593    Count 4: 0.486    Count 5: 0.225  
  Count 6: 0.337    Count 7: 0.000    Count 8: 0.121    Count 9: 0.356    Count 10: 0.307  
Epoch [174] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [174] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [174] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [175/350] - Time: 4.32s
Train Loss: 0.0157 | Val Loss: 10.5342
Train Acc: 0.9951 | Val Acc: 0.4274
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.579    Count 3: 0.444    Count 4: 0.714    Count 5: 0.402  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.162    Count 9: 0.222    Count 10: 0.239  
Epoch [175] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [175] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [175] Batch [20/26] Loss: 0.0003 LR: 0.000100

Epoch [176/350] - Time: 4.16s
Train Loss: 0.0058 | Val Loss: 9.9375
Train Acc: 0.9975 | Val Acc: 0.4358
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.540    Count 3: 0.463    Count 4: 0.686    Count 5: 0.363  
  Count 6: 0.224    Count 7: 0.000    Count 8: 0.152    Count 9: 0.300    Count 10: 0.284  
Epoch [176] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [176] Batch [10/26] Loss: 0.3042 LR: 0.000100
Epoch [176] Batch [20/26] Loss: 0.0002 LR: 0.000100

Epoch [177/350] - Time: 4.18s
Train Loss: 0.0147 | Val Loss: 9.4389
Train Acc: 0.9975 | Val Acc: 0.4302
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.975    Count 2: 0.532    Count 3: 0.435    Count 4: 0.638    Count 5: 0.255  
  Count 6: 0.265    Count 7: 0.000    Count 8: 0.141    Count 9: 0.356    Count 10: 0.284  
Epoch [177] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [177] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [177] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [178/350] - Time: 4.13s
Train Loss: 0.0054 | Val Loss: 9.0532
Train Acc: 0.9975 | Val Acc: 0.4534
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.563    Count 3: 0.324    Count 4: 0.667    Count 5: 0.412  
  Count 6: 0.265    Count 7: 0.010    Count 8: 0.253    Count 9: 0.422    Count 10: 0.295  
Epoch [178] Batch [0/26] Loss: 0.0102 LR: 0.000100
Epoch [178] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [178] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [179/350] - Time: 4.30s
Train Loss: 0.0093 | Val Loss: 9.9659
Train Acc: 0.9975 | Val Acc: 0.4404
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.690    Count 3: 0.519    Count 4: 0.629    Count 5: 0.265  
  Count 6: 0.214    Count 7: 0.000    Count 8: 0.162    Count 9: 0.356    Count 10: 0.295  
Epoch [179] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [179] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [179] Batch [20/26] Loss: 0.0005 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [180/350] - Time: 4.19s
Train Loss: 0.0195 | Val Loss: 8.8348
Train Acc: 0.9926 | Val Acc: 0.4618
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.595    Count 3: 0.481    Count 4: 0.562    Count 5: 0.353  
  Count 6: 0.276    Count 7: 0.083    Count 8: 0.313    Count 9: 0.356    Count 10: 0.273  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_179.pth
Epoch [180] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [180] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [180] Batch [20/26] Loss: 0.0009 LR: 0.000100

Epoch [181/350] - Time: 4.15s
Train Loss: 0.0937 | Val Loss: 9.9980
Train Acc: 0.9926 | Val Acc: 0.4255
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.698    Count 3: 0.315    Count 4: 0.695    Count 5: 0.304  
  Count 6: 0.153    Count 7: 0.000    Count 8: 0.141    Count 9: 0.267    Count 10: 0.341  
Epoch [181] Batch [0/26] Loss: 0.3694 LR: 0.000100
Epoch [181] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [181] Batch [20/26] Loss: 0.0006 LR: 0.000100

Epoch [182/350] - Time: 4.39s
Train Loss: 0.0289 | Val Loss: 10.3734
Train Acc: 0.9951 | Val Acc: 0.4106
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.611    Count 3: 0.389    Count 4: 0.648    Count 5: 0.235  
  Count 6: 0.235    Count 7: 0.000    Count 8: 0.111    Count 9: 0.300    Count 10: 0.273  
Epoch [182] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [182] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [182] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [183/350] - Time: 4.19s
Train Loss: 0.0415 | Val Loss: 10.0645
Train Acc: 0.9951 | Val Acc: 0.4348
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.635    Count 3: 0.556    Count 4: 0.667    Count 5: 0.245  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.152    Count 9: 0.300    Count 10: 0.250  
Epoch [183] Batch [0/26] Loss: 0.0005 LR: 0.000100
Epoch [183] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [183] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [184/350] - Time: 4.23s
Train Loss: 0.0138 | Val Loss: 10.0365
Train Acc: 0.9951 | Val Acc: 0.4507
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.587    Count 3: 0.537    Count 4: 0.581    Count 5: 0.304  
  Count 6: 0.337    Count 7: 0.021    Count 8: 0.162    Count 9: 0.322    Count 10: 0.273  
Epoch [184] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [184] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [184] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [185/350] - Time: 4.21s
Train Loss: 0.0099 | Val Loss: 10.5942
Train Acc: 0.9951 | Val Acc: 0.4246
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.619    Count 3: 0.509    Count 4: 0.486    Count 5: 0.275  
  Count 6: 0.429    Count 7: 0.000    Count 8: 0.202    Count 9: 0.333    Count 10: 0.034  
Epoch [185] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [185] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [185] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [186/350] - Time: 4.20s
Train Loss: 0.0811 | Val Loss: 9.8537
Train Acc: 0.9779 | Val Acc: 0.4302
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.627    Count 3: 0.435    Count 4: 0.552    Count 5: 0.382  
  Count 6: 0.224    Count 7: 0.031    Count 8: 0.081    Count 9: 0.300    Count 10: 0.295  
Epoch [186] Batch [0/26] Loss: 0.0368 LR: 0.000100
Epoch [186] Batch [10/26] Loss: 0.0009 LR: 0.000100
Epoch [186] Batch [20/26] Loss: 0.0082 LR: 0.000100

Epoch [187/350] - Time: 4.25s
Train Loss: 0.0042 | Val Loss: 10.3776
Train Acc: 1.0000 | Val Acc: 0.4236
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.548    Count 3: 0.444    Count 4: 0.781    Count 5: 0.225  
  Count 6: 0.224    Count 7: 0.000    Count 8: 0.040    Count 9: 0.411    Count 10: 0.182  
Epoch [187] Batch [0/26] Loss: 0.1438 LR: 0.000100
Epoch [187] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [187] Batch [20/26] Loss: 0.0003 LR: 0.000100

Epoch [188/350] - Time: 4.18s
Train Loss: 0.0616 | Val Loss: 10.1531
Train Acc: 0.9902 | Val Acc: 0.4553
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.957    Count 2: 0.571    Count 3: 0.435    Count 4: 0.657    Count 5: 0.294  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.212    Count 9: 0.556    Count 10: 0.205  
Epoch [188] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [188] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [188] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [189/350] - Time: 4.14s
Train Loss: 0.0031 | Val Loss: 10.0330
Train Acc: 0.9975 | Val Acc: 0.4413
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.548    Count 3: 0.528    Count 4: 0.590    Count 5: 0.186  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.222    Count 9: 0.567    Count 10: 0.205  
Epoch [189] Batch [0/26] Loss: 0.0080 LR: 0.000100
Epoch [189] Batch [10/26] Loss: 0.0010 LR: 0.000100
Epoch [189] Batch [20/26] Loss: 0.0003 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [190/350] - Time: 4.17s
Train Loss: 0.0222 | Val Loss: 11.1709
Train Acc: 0.9951 | Val Acc: 0.4302
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.690    Count 3: 0.472    Count 4: 0.771    Count 5: 0.275  
  Count 6: 0.163    Count 7: 0.000    Count 8: 0.121    Count 9: 0.311    Count 10: 0.205  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_189.pth
Epoch [190] Batch [0/26] Loss: 0.1249 LR: 0.000100
Epoch [190] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [190] Batch [20/26] Loss: 0.0260 LR: 0.000100

Epoch [191/350] - Time: 4.36s
Train Loss: 0.0165 | Val Loss: 9.9865
Train Acc: 0.9951 | Val Acc: 0.4600
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.975    Count 2: 0.579    Count 3: 0.444    Count 4: 0.648    Count 5: 0.363  
  Count 6: 0.316    Count 7: 0.031    Count 8: 0.202    Count 9: 0.444    Count 10: 0.182  
Epoch [191] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [191] Batch [10/26] Loss: 0.0006 LR: 0.000100
Epoch [191] Batch [20/26] Loss: 0.0003 LR: 0.000100

Epoch [192/350] - Time: 4.21s
Train Loss: 0.0053 | Val Loss: 10.7208
Train Acc: 0.9975 | Val Acc: 0.4320
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.563    Count 3: 0.583    Count 4: 0.657    Count 5: 0.314  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.111    Count 9: 0.322    Count 10: 0.148  
Epoch [192] Batch [0/26] Loss: 0.0304 LR: 0.000100
Epoch [192] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [192] Batch [20/26] Loss: 0.0003 LR: 0.000100

Epoch [193/350] - Time: 4.42s
Train Loss: 0.0042 | Val Loss: 11.8129
Train Acc: 1.0000 | Val Acc: 0.4264
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.651    Count 3: 0.574    Count 4: 0.505    Count 5: 0.206  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.131    Count 9: 0.422    Count 10: 0.148  
Epoch [193] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [193] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [193] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [194/350] - Time: 4.22s
Train Loss: 0.0858 | Val Loss: 9.8405
Train Acc: 0.9877 | Val Acc: 0.4544
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.698    Count 3: 0.352    Count 4: 0.705    Count 5: 0.196  
  Count 6: 0.316    Count 7: 0.000    Count 8: 0.192    Count 9: 0.467    Count 10: 0.284  
Epoch [194] Batch [0/26] Loss: 0.0236 LR: 0.000100
Epoch [194] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [194] Batch [20/26] Loss: 0.0327 LR: 0.000100

Epoch [195/350] - Time: 4.19s
Train Loss: 0.0031 | Val Loss: 9.5989
Train Acc: 1.0000 | Val Acc: 0.4488
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.611    Count 3: 0.509    Count 4: 0.610    Count 5: 0.157  
  Count 6: 0.316    Count 7: 0.010    Count 8: 0.313    Count 9: 0.289    Count 10: 0.364  
Epoch [195] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [195] Batch [10/26] Loss: 0.0086 LR: 0.000100
Epoch [195] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [196/350] - Time: 4.22s
Train Loss: 0.0016 | Val Loss: 10.7918
Train Acc: 1.0000 | Val Acc: 0.4376
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.619    Count 3: 0.454    Count 4: 0.533    Count 5: 0.255  
  Count 6: 0.378    Count 7: 0.021    Count 8: 0.141    Count 9: 0.500    Count 10: 0.182  
Epoch [196] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [196] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [196] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [197/350] - Time: 4.12s
Train Loss: 0.0752 | Val Loss: 9.9426
Train Acc: 0.9877 | Val Acc: 0.4534
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.556    Count 3: 0.537    Count 4: 0.648    Count 5: 0.422  
  Count 6: 0.265    Count 7: 0.000    Count 8: 0.222    Count 9: 0.289    Count 10: 0.273  
Epoch [197] Batch [0/26] Loss: 0.0004 LR: 0.000100
Epoch [197] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [197] Batch [20/26] Loss: 0.0002 LR: 0.000100

Epoch [198/350] - Time: 4.13s
Train Loss: 0.0456 | Val Loss: 10.6393
Train Acc: 0.9975 | Val Acc: 0.4162
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.619    Count 3: 0.463    Count 4: 0.486    Count 5: 0.186  
  Count 6: 0.337    Count 7: 0.000    Count 8: 0.121    Count 9: 0.500    Count 10: 0.148  
Epoch [198] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [198] Batch [10/26] Loss: 0.0655 LR: 0.000100
Epoch [198] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [199/350] - Time: 4.38s
Train Loss: 0.0295 | Val Loss: 9.8829
Train Acc: 0.9902 | Val Acc: 0.4553
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.619    Count 3: 0.213    Count 4: 0.667    Count 5: 0.412  
  Count 6: 0.296    Count 7: 0.021    Count 8: 0.293    Count 9: 0.356    Count 10: 0.307  
Epoch [199] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [199] Batch [10/26] Loss: 0.0050 LR: 0.000100
Epoch [199] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [200/350] - Time: 4.21s
Train Loss: 0.0820 | Val Loss: 9.6748
Train Acc: 0.9877 | Val Acc: 0.4274
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.500    Count 3: 0.444    Count 4: 0.533    Count 5: 0.235  
  Count 6: 0.255    Count 7: 0.021    Count 8: 0.222    Count 9: 0.400    Count 10: 0.341  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_199.pth
Epoch [200] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [200] Batch [10/26] Loss: 0.0698 LR: 0.000100
Epoch [200] Batch [20/26] Loss: 0.0031 LR: 0.000100

Epoch [201/350] - Time: 4.09s
Train Loss: 0.0163 | Val Loss: 9.7374
Train Acc: 0.9926 | Val Acc: 0.4460
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.975    Count 2: 0.540    Count 3: 0.361    Count 4: 0.562    Count 5: 0.314  
  Count 6: 0.449    Count 7: 0.052    Count 8: 0.172    Count 9: 0.356    Count 10: 0.284  
Epoch [201] Batch [0/26] Loss: 0.4884 LR: 0.000100
Epoch [201] Batch [10/26] Loss: 0.0003 LR: 0.000100
Epoch [201] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [202/350] - Time: 4.21s
Train Loss: 0.0195 | Val Loss: 10.3701
Train Acc: 0.9975 | Val Acc: 0.4190
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.532    Count 3: 0.491    Count 4: 0.695    Count 5: 0.294  
  Count 6: 0.367    Count 7: 0.000    Count 8: 0.101    Count 9: 0.211    Count 10: 0.170  
Epoch [202] Batch [0/26] Loss: 0.0015 LR: 0.000100
Epoch [202] Batch [10/26] Loss: 0.0617 LR: 0.000100
Epoch [202] Batch [20/26] Loss: 0.0737 LR: 0.000100

Epoch [203/350] - Time: 4.18s
Train Loss: 0.0138 | Val Loss: 9.8565
Train Acc: 0.9902 | Val Acc: 0.4544
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.563    Count 3: 0.426    Count 4: 0.781    Count 5: 0.196  
  Count 6: 0.296    Count 7: 0.010    Count 8: 0.273    Count 9: 0.389    Count 10: 0.318  
Epoch [203] Batch [0/26] Loss: 0.0234 LR: 0.000100
Epoch [203] Batch [10/26] Loss: 0.0005 LR: 0.000100
Epoch [203] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [204/350] - Time: 4.19s
Train Loss: 0.0638 | Val Loss: 8.4792
Train Acc: 0.9853 | Val Acc: 0.4600
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.484    Count 3: 0.500    Count 4: 0.619    Count 5: 0.324  
  Count 6: 0.296    Count 7: 0.010    Count 8: 0.354    Count 9: 0.444    Count 10: 0.318  
Epoch [204] Batch [0/26] Loss: 0.0044 LR: 0.000100
Epoch [204] Batch [10/26] Loss: 1.0457 LR: 0.000100
Epoch [204] Batch [20/26] Loss: 0.1344 LR: 0.000100

Epoch [205/350] - Time: 4.24s
Train Loss: 0.1485 | Val Loss: 10.4816
Train Acc: 0.9681 | Val Acc: 0.4274
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.809    Count 2: 0.619    Count 3: 0.407    Count 4: 0.676    Count 5: 0.353  
  Count 6: 0.296    Count 7: 0.021    Count 8: 0.131    Count 9: 0.378    Count 10: 0.239  
Epoch [205] Batch [0/26] Loss: 0.0447 LR: 0.000100
Epoch [205] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [205] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [206/350] - Time: 4.18s
Train Loss: 0.1188 | Val Loss: 9.6249
Train Acc: 0.9779 | Val Acc: 0.4395
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.540    Count 3: 0.481    Count 4: 0.638    Count 5: 0.157  
  Count 6: 0.327    Count 7: 0.031    Count 8: 0.303    Count 9: 0.356    Count 10: 0.205  
Epoch [206] Batch [0/26] Loss: 0.1553 LR: 0.000100
Epoch [206] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [206] Batch [20/26] Loss: 0.0022 LR: 0.000100

Epoch [207/350] - Time: 4.46s
Train Loss: 0.0090 | Val Loss: 9.2525
Train Acc: 0.9951 | Val Acc: 0.4590
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.563    Count 3: 0.528    Count 4: 0.638    Count 5: 0.147  
  Count 6: 0.357    Count 7: 0.031    Count 8: 0.313    Count 9: 0.311    Count 10: 0.386  
Epoch [207] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [207] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [207] Batch [20/26] Loss: 0.0011 LR: 0.000100

Epoch [208/350] - Time: 4.16s
Train Loss: 0.0414 | Val Loss: 10.1583
Train Acc: 0.9828 | Val Acc: 0.4395
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.611    Count 3: 0.546    Count 4: 0.552    Count 5: 0.098  
  Count 6: 0.398    Count 7: 0.021    Count 8: 0.202    Count 9: 0.500    Count 10: 0.057  
Epoch [208] Batch [0/26] Loss: 0.0004 LR: 0.000100
Epoch [208] Batch [10/26] Loss: 0.0037 LR: 0.000100
Epoch [208] Batch [20/26] Loss: 0.0026 LR: 0.000100

Epoch [209/350] - Time: 4.17s
Train Loss: 0.0369 | Val Loss: 8.9579
Train Acc: 0.9975 | Val Acc: 0.4674
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.635    Count 3: 0.639    Count 4: 0.533    Count 5: 0.196  
  Count 6: 0.316    Count 7: 0.042    Count 8: 0.253    Count 9: 0.467    Count 10: 0.250  
Epoch [209] Batch [0/26] Loss: 0.0254 LR: 0.000100
Epoch [209] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [209] Batch [20/26] Loss: 0.0002 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [210/350] - Time: 4.19s
Train Loss: 0.0383 | Val Loss: 9.7584
Train Acc: 0.9877 | Val Acc: 0.4683
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.643    Count 3: 0.583    Count 4: 0.705    Count 5: 0.216  
  Count 6: 0.327    Count 7: 0.000    Count 8: 0.162    Count 9: 0.500    Count 10: 0.193  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_209.pth
Epoch [210] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [210] Batch [10/26] Loss: 0.0008 LR: 0.000100
Epoch [210] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [211/350] - Time: 4.19s
Train Loss: 0.0294 | Val Loss: 8.9595
Train Acc: 0.9902 | Val Acc: 0.4683
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.595    Count 3: 0.454    Count 4: 0.724    Count 5: 0.147  
  Count 6: 0.357    Count 7: 0.062    Count 8: 0.384    Count 9: 0.444    Count 10: 0.250  
Epoch [211] Batch [0/26] Loss: 0.0004 LR: 0.000100
Epoch [211] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [211] Batch [20/26] Loss: 0.0097 LR: 0.000100

Epoch [212/350] - Time: 4.22s
Train Loss: 0.0054 | Val Loss: 10.5723
Train Acc: 0.9975 | Val Acc: 0.4320
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.587    Count 3: 0.398    Count 4: 0.590    Count 5: 0.382  
  Count 6: 0.286    Count 7: 0.052    Count 8: 0.141    Count 9: 0.311    Count 10: 0.284  
Epoch [212] Batch [0/26] Loss: 0.0030 LR: 0.000100
Epoch [212] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [212] Batch [20/26] Loss: 0.2032 LR: 0.000100

Epoch [213/350] - Time: 4.17s
Train Loss: 0.1232 | Val Loss: 9.8436
Train Acc: 0.9804 | Val Acc: 0.4320
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.975    Count 2: 0.532    Count 3: 0.454    Count 4: 0.610    Count 5: 0.324  
  Count 6: 0.235    Count 7: 0.010    Count 8: 0.131    Count 9: 0.333    Count 10: 0.295  
Epoch [213] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [213] Batch [10/26] Loss: 0.0002 LR: 0.000100
Epoch [213] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [214/350] - Time: 4.16s
Train Loss: 0.0098 | Val Loss: 11.0933
Train Acc: 0.9951 | Val Acc: 0.4283
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.627    Count 3: 0.509    Count 4: 0.581    Count 5: 0.225  
  Count 6: 0.337    Count 7: 0.000    Count 8: 0.111    Count 9: 0.344    Count 10: 0.114  
Epoch [214] Batch [0/26] Loss: 0.0201 LR: 0.000100
Epoch [214] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [214] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [215/350] - Time: 4.11s
Train Loss: 0.0104 | Val Loss: 12.0198
Train Acc: 0.9975 | Val Acc: 0.3892
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.975    Count 2: 0.587    Count 3: 0.407    Count 4: 0.638    Count 5: 0.284  
  Count 6: 0.184    Count 7: 0.042    Count 8: 0.081    Count 9: 0.111    Count 10: 0.068  
Epoch [215] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [215] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [215] Batch [20/26] Loss: 0.0003 LR: 0.000100

Epoch [216/350] - Time: 4.48s
Train Loss: 0.0282 | Val Loss: 13.3765
Train Acc: 0.9902 | Val Acc: 0.3827
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.500    Count 3: 0.481    Count 4: 0.467    Count 5: 0.147  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.081    Count 9: 0.411    Count 10: 0.011  
Epoch [216] Batch [0/26] Loss: 0.0205 LR: 0.000100
Epoch [216] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [216] Batch [20/26] Loss: 0.0473 LR: 0.000100

Epoch [217/350] - Time: 4.12s
Train Loss: 0.0980 | Val Loss: 9.5272
Train Acc: 0.9755 | Val Acc: 0.4348
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.858    Count 2: 0.540    Count 3: 0.259    Count 4: 0.590    Count 5: 0.412  
  Count 6: 0.296    Count 7: 0.073    Count 8: 0.212    Count 9: 0.367    Count 10: 0.432  
Epoch [217] Batch [0/26] Loss: 0.4775 LR: 0.000100
Epoch [217] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [217] Batch [20/26] Loss: 0.0016 LR: 0.000100

Epoch [218/350] - Time: 4.24s
Train Loss: 0.0599 | Val Loss: 10.4789
Train Acc: 0.9902 | Val Acc: 0.4292
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.957    Count 2: 0.627    Count 3: 0.407    Count 4: 0.419    Count 5: 0.245  
  Count 6: 0.235    Count 7: 0.031    Count 8: 0.111    Count 9: 0.367    Count 10: 0.500  
Epoch [218] Batch [0/26] Loss: 0.0038 LR: 0.000100
Epoch [218] Batch [10/26] Loss: 0.0016 LR: 0.000100
Epoch [218] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [219/350] - Time: 4.28s
Train Loss: 0.0314 | Val Loss: 10.8284
Train Acc: 0.9926 | Val Acc: 0.4190
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.651    Count 3: 0.380    Count 4: 0.686    Count 5: 0.294  
  Count 6: 0.184    Count 7: 0.031    Count 8: 0.162    Count 9: 0.267    Count 10: 0.193  
Epoch [219] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [219] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [219] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [220/350] - Time: 4.30s
Train Loss: 0.0048 | Val Loss: 11.4331
Train Acc: 0.9975 | Val Acc: 0.4236
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.611    Count 3: 0.444    Count 4: 0.657    Count 5: 0.235  
  Count 6: 0.245    Count 7: 0.000    Count 8: 0.162    Count 9: 0.467    Count 10: 0.011  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_219.pth
Epoch [220] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [220] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [220] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [221/350] - Time: 4.08s
Train Loss: 0.0056 | Val Loss: 10.4346
Train Acc: 0.9975 | Val Acc: 0.4348
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.957    Count 2: 0.619    Count 3: 0.472    Count 4: 0.514    Count 5: 0.235  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.182    Count 9: 0.322    Count 10: 0.375  
Epoch [221] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [221] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [221] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [222/350] - Time: 4.20s
Train Loss: 0.0295 | Val Loss: 10.6533
Train Acc: 0.9926 | Val Acc: 0.4479
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.476    Count 3: 0.546    Count 4: 0.543    Count 5: 0.235  
  Count 6: 0.378    Count 7: 0.062    Count 8: 0.313    Count 9: 0.356    Count 10: 0.273  
Epoch [222] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [222] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [222] Batch [20/26] Loss: 0.0005 LR: 0.000100

Epoch [223/350] - Time: 4.16s
Train Loss: 0.0151 | Val Loss: 11.2825
Train Acc: 0.9975 | Val Acc: 0.4236
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.643    Count 3: 0.380    Count 4: 0.752    Count 5: 0.275  
  Count 6: 0.204    Count 7: 0.010    Count 8: 0.192    Count 9: 0.256    Count 10: 0.125  
Epoch [223] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [223] Batch [10/26] Loss: 0.0002 LR: 0.000100
Epoch [223] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [224/350] - Time: 4.47s
Train Loss: 0.1187 | Val Loss: 10.6512
Train Acc: 0.9828 | Val Acc: 0.4143
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.484    Count 3: 0.296    Count 4: 0.571    Count 5: 0.490  
  Count 6: 0.245    Count 7: 0.083    Count 8: 0.232    Count 9: 0.322    Count 10: 0.284  
Epoch [224] Batch [0/26] Loss: 0.0007 LR: 0.000100
Epoch [224] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [224] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [225/350] - Time: 4.15s
Train Loss: 0.0080 | Val Loss: 11.7516
Train Acc: 0.9975 | Val Acc: 0.4069
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.500    Count 3: 0.519    Count 4: 0.543    Count 5: 0.186  
  Count 6: 0.439    Count 7: 0.000    Count 8: 0.131    Count 9: 0.200    Count 10: 0.136  
Epoch [225] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [225] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [225] Batch [20/26] Loss: 0.0020 LR: 0.000100

Epoch [226/350] - Time: 4.17s
Train Loss: 0.0023 | Val Loss: 10.6139
Train Acc: 0.9975 | Val Acc: 0.4395
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.651    Count 3: 0.343    Count 4: 0.600    Count 5: 0.363  
  Count 6: 0.265    Count 7: 0.042    Count 8: 0.172    Count 9: 0.378    Count 10: 0.261  
Epoch [226] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [226] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [226] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [227/350] - Time: 4.30s
Train Loss: 0.0011 | Val Loss: 11.8609
Train Acc: 1.0000 | Val Acc: 0.4227
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.579    Count 3: 0.417    Count 4: 0.600    Count 5: 0.225  
  Count 6: 0.327    Count 7: 0.031    Count 8: 0.131    Count 9: 0.356    Count 10: 0.239  
Epoch [227] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [227] Batch [10/26] Loss: 0.0002 LR: 0.000100
Epoch [227] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [228/350] - Time: 4.32s
Train Loss: 0.0140 | Val Loss: 11.9946
Train Acc: 0.9975 | Val Acc: 0.4274
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.651    Count 3: 0.444    Count 4: 0.486    Count 5: 0.196  
  Count 6: 0.306    Count 7: 0.021    Count 8: 0.162    Count 9: 0.378    Count 10: 0.250  
Epoch [228] Batch [0/26] Loss: 0.0042 LR: 0.000100
Epoch [228] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [228] Batch [20/26] Loss: 0.0014 LR: 0.000100

Epoch [229/350] - Time: 4.18s
Train Loss: 0.0005 | Val Loss: 11.1851
Train Acc: 1.0000 | Val Acc: 0.4385
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.714    Count 3: 0.352    Count 4: 0.648    Count 5: 0.225  
  Count 6: 0.255    Count 7: 0.021    Count 8: 0.182    Count 9: 0.389    Count 10: 0.273  
Epoch [229] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [229] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [229] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [230/350] - Time: 4.35s
Train Loss: 0.0015 | Val Loss: 11.4732
Train Acc: 1.0000 | Val Acc: 0.4311
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.698    Count 3: 0.435    Count 4: 0.733    Count 5: 0.343  
  Count 6: 0.265    Count 7: 0.000    Count 8: 0.162    Count 9: 0.144    Count 10: 0.216  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_229.pth
Epoch [230] Batch [0/26] Loss: 0.0475 LR: 0.000100
Epoch [230] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [230] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [231/350] - Time: 4.21s
Train Loss: 0.0149 | Val Loss: 11.7197
Train Acc: 0.9877 | Val Acc: 0.4013
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.595    Count 3: 0.398    Count 4: 0.695    Count 5: 0.235  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.192    Count 9: 0.144    Count 10: 0.159  
Epoch [231] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [231] Batch [10/26] Loss: 0.0010 LR: 0.000100
Epoch [231] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [232/350] - Time: 4.56s
Train Loss: 0.0479 | Val Loss: 10.6977
Train Acc: 0.9951 | Val Acc: 0.4218
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.508    Count 3: 0.407    Count 4: 0.724    Count 5: 0.441  
  Count 6: 0.214    Count 7: 0.010    Count 8: 0.121    Count 9: 0.256    Count 10: 0.307  
Epoch [232] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [232] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [232] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [233/350] - Time: 4.40s
Train Loss: 0.0004 | Val Loss: 10.4800
Train Acc: 1.0000 | Val Acc: 0.4441
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.413    Count 3: 0.500    Count 4: 0.590    Count 5: 0.392  
  Count 6: 0.296    Count 7: 0.021    Count 8: 0.323    Count 9: 0.433    Count 10: 0.205  
Epoch [233] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [233] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [233] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [234/350] - Time: 4.36s
Train Loss: 0.0000 | Val Loss: 10.9386
Train Acc: 1.0000 | Val Acc: 0.4404
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.452    Count 3: 0.583    Count 4: 0.562    Count 5: 0.324  
  Count 6: 0.327    Count 7: 0.000    Count 8: 0.253    Count 9: 0.444    Count 10: 0.148  
Epoch [234] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [234] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [234] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [235/350] - Time: 4.42s
Train Loss: 0.0001 | Val Loss: 10.4859
Train Acc: 1.0000 | Val Acc: 0.4460
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.484    Count 3: 0.519    Count 4: 0.552    Count 5: 0.304  
  Count 6: 0.286    Count 7: 0.052    Count 8: 0.253    Count 9: 0.456    Count 10: 0.250  
Epoch [235] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [235] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [235] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [236/350] - Time: 4.44s
Train Loss: 0.0010 | Val Loss: 10.8823
Train Acc: 1.0000 | Val Acc: 0.4460
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.579    Count 3: 0.472    Count 4: 0.695    Count 5: 0.304  
  Count 6: 0.255    Count 7: 0.052    Count 8: 0.253    Count 9: 0.422    Count 10: 0.273  
Epoch [236] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [236] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [236] Batch [20/26] Loss: 0.0084 LR: 0.000100

Epoch [237/350] - Time: 4.37s
Train Loss: 0.0044 | Val Loss: 12.3737
Train Acc: 0.9975 | Val Acc: 0.4106
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.611    Count 3: 0.435    Count 4: 0.552    Count 5: 0.176  
  Count 6: 0.224    Count 7: 0.010    Count 8: 0.141    Count 9: 0.411    Count 10: 0.205  
Epoch [237] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [237] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [237] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [238/350] - Time: 4.48s
Train Loss: 0.0029 | Val Loss: 10.4696
Train Acc: 1.0000 | Val Acc: 0.4562
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.627    Count 3: 0.333    Count 4: 0.724    Count 5: 0.402  
  Count 6: 0.224    Count 7: 0.031    Count 8: 0.374    Count 9: 0.344    Count 10: 0.193  
Epoch [238] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [238] Batch [10/26] Loss: 0.0011 LR: 0.000100
Epoch [238] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [239/350] - Time: 4.39s
Train Loss: 0.0187 | Val Loss: 10.8356
Train Acc: 0.9951 | Val Acc: 0.4376
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.667    Count 3: 0.426    Count 4: 0.533    Count 5: 0.304  
  Count 6: 0.316    Count 7: 0.000    Count 8: 0.152    Count 9: 0.500    Count 10: 0.205  
Epoch [239] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [239] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [239] Batch [20/26] Loss: 0.0001 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [240/350] - Time: 4.64s
Train Loss: 0.0171 | Val Loss: 11.6303
Train Acc: 0.9926 | Val Acc: 0.4385
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.635    Count 3: 0.472    Count 4: 0.543    Count 5: 0.245  
  Count 6: 0.388    Count 7: 0.010    Count 8: 0.141    Count 9: 0.411    Count 10: 0.261  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_239.pth
Epoch [240] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [240] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [240] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [241/350] - Time: 4.28s
Train Loss: 0.0717 | Val Loss: 11.3878
Train Acc: 0.9926 | Val Acc: 0.4199
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.571    Count 3: 0.278    Count 4: 0.629    Count 5: 0.471  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.273    Count 9: 0.222    Count 10: 0.216  
Epoch [241] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [241] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [241] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [242/350] - Time: 4.16s
Train Loss: 0.0033 | Val Loss: 10.8789
Train Acc: 1.0000 | Val Acc: 0.4469
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.484    Count 3: 0.398    Count 4: 0.590    Count 5: 0.373  
  Count 6: 0.429    Count 7: 0.010    Count 8: 0.162    Count 9: 0.500    Count 10: 0.273  
Epoch [242] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [242] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [242] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [243/350] - Time: 4.28s
Train Loss: 0.0677 | Val Loss: 9.9786
Train Acc: 0.9853 | Val Acc: 0.4553
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.690    Count 3: 0.296    Count 4: 0.762    Count 5: 0.343  
  Count 6: 0.204    Count 7: 0.062    Count 8: 0.212    Count 9: 0.300    Count 10: 0.466  
Epoch [243] Batch [0/26] Loss: 0.1164 LR: 0.000100
Epoch [243] Batch [10/26] Loss: 0.0005 LR: 0.000100
Epoch [243] Batch [20/26] Loss: 0.0002 LR: 0.000100

Epoch [244/350] - Time: 4.18s
Train Loss: 0.0523 | Val Loss: 12.5776
Train Acc: 0.9853 | Val Acc: 0.3892
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.500    Count 3: 0.509    Count 4: 0.562    Count 5: 0.147  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.111    Count 9: 0.300    Count 10: 0.091  
Epoch [244] Batch [0/26] Loss: 0.0190 LR: 0.000100
Epoch [244] Batch [10/26] Loss: 0.0080 LR: 0.000100
Epoch [244] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [245/350] - Time: 4.15s
Train Loss: 0.0015 | Val Loss: 9.0858
Train Acc: 1.0000 | Val Acc: 0.4730
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.571    Count 3: 0.481    Count 4: 0.705    Count 5: 0.206  
  Count 6: 0.337    Count 7: 0.052    Count 8: 0.343    Count 9: 0.422    Count 10: 0.398  
Epoch [245] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [245] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [245] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [246/350] - Time: 4.16s
Train Loss: 0.0301 | Val Loss: 9.6891
Train Acc: 0.9926 | Val Acc: 0.4525
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.635    Count 3: 0.407    Count 4: 0.629    Count 5: 0.363  
  Count 6: 0.316    Count 7: 0.073    Count 8: 0.202    Count 9: 0.367    Count 10: 0.318  
Epoch [246] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [246] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [246] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [247/350] - Time: 4.25s
Train Loss: 0.0030 | Val Loss: 11.0720
Train Acc: 1.0000 | Val Acc: 0.4348
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.611    Count 3: 0.472    Count 4: 0.590    Count 5: 0.225  
  Count 6: 0.347    Count 7: 0.010    Count 8: 0.091    Count 9: 0.433    Count 10: 0.307  
Epoch [247] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [247] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [247] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [248/350] - Time: 4.50s
Train Loss: 0.0001 | Val Loss: 10.6899
Train Acc: 1.0000 | Val Acc: 0.4385
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.683    Count 3: 0.352    Count 4: 0.676    Count 5: 0.412  
  Count 6: 0.235    Count 7: 0.010    Count 8: 0.131    Count 9: 0.233    Count 10: 0.409  
Epoch [248] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [248] Batch [10/26] Loss: 0.1360 LR: 0.000100
Epoch [248] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [249/350] - Time: 4.16s
Train Loss: 0.0061 | Val Loss: 10.6393
Train Acc: 0.9975 | Val Acc: 0.4339
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.563    Count 3: 0.296    Count 4: 0.571    Count 5: 0.569  
  Count 6: 0.276    Count 7: 0.021    Count 8: 0.202    Count 9: 0.278    Count 10: 0.341  
Epoch [249] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [249] Batch [10/26] Loss: 0.0013 LR: 0.000100
Epoch [249] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [250/350] - Time: 4.23s
Train Loss: 0.0068 | Val Loss: 10.4594
Train Acc: 0.9975 | Val Acc: 0.4358
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.840    Count 2: 0.492    Count 3: 0.583    Count 4: 0.410    Count 5: 0.216  
  Count 6: 0.449    Count 7: 0.052    Count 8: 0.212    Count 9: 0.367    Count 10: 0.443  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_249.pth
Epoch [250] Batch [0/26] Loss: 0.0026 LR: 0.000100
Epoch [250] Batch [10/26] Loss: 0.0263 LR: 0.000100
Epoch [250] Batch [20/26] Loss: 0.0027 LR: 0.000100

Epoch [251/350] - Time: 4.24s
Train Loss: 0.0410 | Val Loss: 10.8887
Train Acc: 0.9853 | Val Acc: 0.4181
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.452    Count 3: 0.287    Count 4: 0.571    Count 5: 0.461  
  Count 6: 0.337    Count 7: 0.042    Count 8: 0.485    Count 9: 0.244    Count 10: 0.114  
Epoch [251] Batch [0/26] Loss: 0.1424 LR: 0.000100
Epoch [251] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [251] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [252/350] - Time: 4.24s
Train Loss: 0.1436 | Val Loss: 10.5264
Train Acc: 0.9657 | Val Acc: 0.4581
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.540    Count 3: 0.343    Count 4: 0.629    Count 5: 0.333  
  Count 6: 0.204    Count 7: 0.156    Count 8: 0.162    Count 9: 0.356    Count 10: 0.580  
Epoch [252] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [252] Batch [10/26] Loss: 0.0007 LR: 0.000100
Epoch [252] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [253/350] - Time: 4.16s
Train Loss: 0.2212 | Val Loss: 10.1017
Train Acc: 0.9828 | Val Acc: 0.4358
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.595    Count 3: 0.398    Count 4: 0.657    Count 5: 0.284  
  Count 6: 0.265    Count 7: 0.031    Count 8: 0.182    Count 9: 0.322    Count 10: 0.284  
Epoch [253] Batch [0/26] Loss: 0.0007 LR: 0.000100
Epoch [253] Batch [10/26] Loss: 0.0004 LR: 0.000100
Epoch [253] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [254/350] - Time: 4.21s
Train Loss: 0.0018 | Val Loss: 10.0285
Train Acc: 1.0000 | Val Acc: 0.4553
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.870    Count 2: 0.619    Count 3: 0.481    Count 4: 0.610    Count 5: 0.235  
  Count 6: 0.306    Count 7: 0.073    Count 8: 0.303    Count 9: 0.400    Count 10: 0.307  
Epoch [254] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [254] Batch [10/26] Loss: 0.0279 LR: 0.000100
Epoch [254] Batch [20/26] Loss: 0.0011 LR: 0.000100

Epoch [255/350] - Time: 3.99s
Train Loss: 0.0291 | Val Loss: 11.1610
Train Acc: 0.9926 | Val Acc: 0.4292
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.809    Count 2: 0.730    Count 3: 0.407    Count 4: 0.724    Count 5: 0.441  
  Count 6: 0.163    Count 7: 0.031    Count 8: 0.061    Count 9: 0.211    Count 10: 0.330  
Epoch [255] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [255] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [255] Batch [20/26] Loss: 0.0353 LR: 0.000100

Epoch [256/350] - Time: 4.03s
Train Loss: 0.0178 | Val Loss: 10.5338
Train Acc: 0.9975 | Val Acc: 0.4553
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.698    Count 3: 0.426    Count 4: 0.610    Count 5: 0.294  
  Count 6: 0.337    Count 7: 0.052    Count 8: 0.162    Count 9: 0.433    Count 10: 0.250  
Epoch [256] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [256] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [256] Batch [20/26] Loss: 0.0002 LR: 0.000100

Epoch [257/350] - Time: 4.75s
Train Loss: 0.0089 | Val Loss: 10.2711
Train Acc: 0.9951 | Val Acc: 0.4600
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.659    Count 3: 0.463    Count 4: 0.571    Count 5: 0.324  
  Count 6: 0.327    Count 7: 0.042    Count 8: 0.162    Count 9: 0.422    Count 10: 0.284  
Epoch [257] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [257] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [257] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [258/350] - Time: 4.14s
Train Loss: 0.0135 | Val Loss: 10.5661
Train Acc: 0.9975 | Val Acc: 0.4562
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.714    Count 3: 0.472    Count 4: 0.581    Count 5: 0.216  
  Count 6: 0.316    Count 7: 0.031    Count 8: 0.152    Count 9: 0.400    Count 10: 0.307  
Epoch [258] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [258] Batch [10/26] Loss: 0.2883 LR: 0.000100
Epoch [258] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [259/350] - Time: 3.99s
Train Loss: 0.0114 | Val Loss: 10.9914
Train Acc: 0.9975 | Val Acc: 0.4479
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.643    Count 3: 0.481    Count 4: 0.619    Count 5: 0.216  
  Count 6: 0.337    Count 7: 0.021    Count 8: 0.141    Count 9: 0.389    Count 10: 0.261  
Epoch [259] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [259] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [259] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [260/350] - Time: 4.04s
Train Loss: 0.0000 | Val Loss: 11.0891
Train Acc: 1.0000 | Val Acc: 0.4441
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.698    Count 3: 0.463    Count 4: 0.581    Count 5: 0.216  
  Count 6: 0.316    Count 7: 0.021    Count 8: 0.131    Count 9: 0.389    Count 10: 0.250  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_259.pth
Epoch [260] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [260] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [260] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [261/350] - Time: 4.05s
Train Loss: 0.0000 | Val Loss: 10.7330
Train Acc: 1.0000 | Val Acc: 0.4451
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.675    Count 3: 0.407    Count 4: 0.638    Count 5: 0.255  
  Count 6: 0.306    Count 7: 0.021    Count 8: 0.172    Count 9: 0.400    Count 10: 0.250  
Epoch [261] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [261] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [261] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [262/350] - Time: 3.96s
Train Loss: 0.0000 | Val Loss: 10.6971
Train Acc: 1.0000 | Val Acc: 0.4497
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.675    Count 3: 0.407    Count 4: 0.638    Count 5: 0.294  
  Count 6: 0.306    Count 7: 0.031    Count 8: 0.172    Count 9: 0.411    Count 10: 0.250  
Epoch [262] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [262] Batch [10/26] Loss: 0.0142 LR: 0.000100
Epoch [262] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [263/350] - Time: 4.00s
Train Loss: 0.0152 | Val Loss: 11.9203
Train Acc: 0.9975 | Val Acc: 0.4385
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.627    Count 3: 0.500    Count 4: 0.467    Count 5: 0.167  
  Count 6: 0.378    Count 7: 0.021    Count 8: 0.162    Count 9: 0.556    Count 10: 0.159  
Epoch [263] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [263] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [263] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [264/350] - Time: 4.06s
Train Loss: 0.0452 | Val Loss: 13.1744
Train Acc: 0.9902 | Val Acc: 0.4190
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.957    Count 2: 0.611    Count 3: 0.491    Count 4: 0.429    Count 5: 0.078  
  Count 6: 0.388    Count 7: 0.000    Count 8: 0.212    Count 9: 0.533    Count 10: 0.057  
Epoch [264] Batch [0/26] Loss: 0.0016 LR: 0.000100
Epoch [264] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [264] Batch [20/26] Loss: 0.3238 LR: 0.000100

Epoch [265/350] - Time: 4.27s
Train Loss: 0.1136 | Val Loss: 13.0522
Train Acc: 0.9804 | Val Acc: 0.4283
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.397    Count 3: 0.639    Count 4: 0.305    Count 5: 0.069  
  Count 6: 0.541    Count 7: 0.021    Count 8: 0.212    Count 9: 0.478    Count 10: 0.364  
Epoch [265] Batch [0/26] Loss: 0.0024 LR: 0.000100
Epoch [265] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [265] Batch [20/26] Loss: 0.0005 LR: 0.000100

Epoch [266/350] - Time: 3.99s
Train Loss: 0.0675 | Val Loss: 11.2536
Train Acc: 0.9926 | Val Acc: 0.4395
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.532    Count 3: 0.463    Count 4: 0.600    Count 5: 0.392  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.212    Count 9: 0.356    Count 10: 0.295  
Epoch [266] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [266] Batch [10/26] Loss: 0.0215 LR: 0.000100
Epoch [266] Batch [20/26] Loss: 0.0067 LR: 0.000100

Epoch [267/350] - Time: 4.10s
Train Loss: 0.0504 | Val Loss: 12.7534
Train Acc: 0.9926 | Val Acc: 0.4302
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.556    Count 3: 0.481    Count 4: 0.676    Count 5: 0.314  
  Count 6: 0.235    Count 7: 0.010    Count 8: 0.101    Count 9: 0.422    Count 10: 0.261  
Epoch [267] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [267] Batch [10/26] Loss: 0.1318 LR: 0.000100
Epoch [267] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [268/350] - Time: 4.01s
Train Loss: 0.1465 | Val Loss: 11.2017
Train Acc: 0.9730 | Val Acc: 0.4358
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.667    Count 3: 0.491    Count 4: 0.467    Count 5: 0.275  
  Count 6: 0.194    Count 7: 0.031    Count 8: 0.162    Count 9: 0.356    Count 10: 0.307  
Epoch [268] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [268] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [268] Batch [20/26] Loss: 0.0034 LR: 0.000100

Epoch [269/350] - Time: 3.95s
Train Loss: 0.0007 | Val Loss: 12.1423
Train Acc: 1.0000 | Val Acc: 0.4404
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.690    Count 3: 0.444    Count 4: 0.667    Count 5: 0.265  
  Count 6: 0.214    Count 7: 0.010    Count 8: 0.101    Count 9: 0.356    Count 10: 0.227  
Epoch [269] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [269] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [269] Batch [20/26] Loss: 0.0043 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [270/350] - Time: 4.05s
Train Loss: 0.0675 | Val Loss: 11.5473
Train Acc: 0.9828 | Val Acc: 0.4339
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.579    Count 3: 0.176    Count 4: 0.667    Count 5: 0.598  
  Count 6: 0.173    Count 7: 0.073    Count 8: 0.202    Count 9: 0.322    Count 10: 0.273  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_269.pth
Epoch [270] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [270] Batch [10/26] Loss: 0.0002 LR: 0.000100
Epoch [270] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [271/350] - Time: 3.95s
Train Loss: 0.0217 | Val Loss: 10.7112
Train Acc: 0.9975 | Val Acc: 0.4488
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.571    Count 3: 0.361    Count 4: 0.581    Count 5: 0.402  
  Count 6: 0.265    Count 7: 0.031    Count 8: 0.343    Count 9: 0.367    Count 10: 0.216  
Epoch [271] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [271] Batch [10/26] Loss: 0.0831 LR: 0.000100
Epoch [271] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [272/350] - Time: 3.93s
Train Loss: 0.0658 | Val Loss: 12.9823
Train Acc: 0.9853 | Val Acc: 0.4032
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.690    Count 3: 0.380    Count 4: 0.495    Count 5: 0.098  
  Count 6: 0.276    Count 7: 0.000    Count 8: 0.131    Count 9: 0.522    Count 10: 0.068  
Epoch [272] Batch [0/26] Loss: 0.2878 LR: 0.000100
Epoch [272] Batch [10/26] Loss: 0.0067 LR: 0.000100
Epoch [272] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [273/350] - Time: 4.19s
Train Loss: 0.0405 | Val Loss: 10.8470
Train Acc: 0.9902 | Val Acc: 0.4544
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.635    Count 3: 0.417    Count 4: 0.676    Count 5: 0.304  
  Count 6: 0.235    Count 7: 0.052    Count 8: 0.212    Count 9: 0.367    Count 10: 0.295  
Epoch [273] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [273] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [273] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [274/350] - Time: 4.02s
Train Loss: 0.0383 | Val Loss: 10.6886
Train Acc: 0.9926 | Val Acc: 0.4507
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.675    Count 3: 0.444    Count 4: 0.505    Count 5: 0.216  
  Count 6: 0.327    Count 7: 0.073    Count 8: 0.111    Count 9: 0.511    Count 10: 0.364  
Epoch [274] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [274] Batch [10/26] Loss: 0.0013 LR: 0.000100
Epoch [274] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [275/350] - Time: 4.00s
Train Loss: 0.0247 | Val Loss: 10.4239
Train Acc: 0.9951 | Val Acc: 0.4348
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.714    Count 3: 0.380    Count 4: 0.610    Count 5: 0.245  
  Count 6: 0.255    Count 7: 0.010    Count 8: 0.152    Count 9: 0.356    Count 10: 0.273  
Epoch [275] Batch [0/26] Loss: 0.0359 LR: 0.000100
Epoch [275] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [275] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [276/350] - Time: 4.05s
Train Loss: 0.0067 | Val Loss: 11.7627
Train Acc: 0.9951 | Val Acc: 0.4367
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.659    Count 3: 0.370    Count 4: 0.657    Count 5: 0.235  
  Count 6: 0.255    Count 7: 0.021    Count 8: 0.172    Count 9: 0.422    Count 10: 0.205  
Epoch [276] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [276] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [276] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [277/350] - Time: 4.00s
Train Loss: 0.0162 | Val Loss: 11.0794
Train Acc: 0.9926 | Val Acc: 0.4236
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.563    Count 3: 0.315    Count 4: 0.676    Count 5: 0.441  
  Count 6: 0.204    Count 7: 0.031    Count 8: 0.232    Count 9: 0.289    Count 10: 0.307  
Epoch [277] Batch [0/26] Loss: 0.0037 LR: 0.000100
Epoch [277] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [277] Batch [20/26] Loss: 0.6147 LR: 0.000100

Epoch [278/350] - Time: 4.02s
Train Loss: 0.0403 | Val Loss: 12.0866
Train Acc: 0.9902 | Val Acc: 0.4190
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.643    Count 3: 0.306    Count 4: 0.743    Count 5: 0.304  
  Count 6: 0.153    Count 7: 0.010    Count 8: 0.131    Count 9: 0.311    Count 10: 0.239  
Epoch [278] Batch [0/26] Loss: 0.0029 LR: 0.000100
Epoch [278] Batch [10/26] Loss: 0.0361 LR: 0.000100
Epoch [278] Batch [20/26] Loss: 0.0042 LR: 0.000100

Epoch [279/350] - Time: 4.08s
Train Loss: 0.0125 | Val Loss: 12.4219
Train Acc: 0.9975 | Val Acc: 0.4069
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.659    Count 3: 0.407    Count 4: 0.657    Count 5: 0.206  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.121    Count 9: 0.322    Count 10: 0.091  
Epoch [279] Batch [0/26] Loss: 0.0047 LR: 0.000100
Epoch [279] Batch [10/26] Loss: 0.0033 LR: 0.000100
Epoch [279] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [280/350] - Time: 4.03s
Train Loss: 0.0166 | Val Loss: 11.8673
Train Acc: 0.9951 | Val Acc: 0.4041
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.667    Count 3: 0.454    Count 4: 0.448    Count 5: 0.176  
  Count 6: 0.265    Count 7: 0.031    Count 8: 0.131    Count 9: 0.333    Count 10: 0.136  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_279.pth
Epoch [280] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [280] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [280] Batch [20/26] Loss: 0.8668 LR: 0.000100

Epoch [281/350] - Time: 4.22s
Train Loss: 0.0424 | Val Loss: 10.1553
Train Acc: 0.9926 | Val Acc: 0.4469
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.627    Count 3: 0.250    Count 4: 0.590    Count 5: 0.431  
  Count 6: 0.235    Count 7: 0.115    Count 8: 0.303    Count 9: 0.367    Count 10: 0.261  
Epoch [281] Batch [0/26] Loss: 0.0790 LR: 0.000100
Epoch [281] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [281] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [282/350] - Time: 3.94s
Train Loss: 0.0328 | Val Loss: 11.1512
Train Acc: 0.9951 | Val Acc: 0.4255
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.579    Count 3: 0.481    Count 4: 0.610    Count 5: 0.186  
  Count 6: 0.388    Count 7: 0.052    Count 8: 0.182    Count 9: 0.289    Count 10: 0.148  
Epoch [282] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [282] Batch [10/26] Loss: 0.3359 LR: 0.000100
Epoch [282] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [283/350] - Time: 4.03s
Train Loss: 0.0133 | Val Loss: 10.2145
Train Acc: 0.9951 | Val Acc: 0.4274
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.508    Count 3: 0.481    Count 4: 0.486    Count 5: 0.186  
  Count 6: 0.306    Count 7: 0.052    Count 8: 0.364    Count 9: 0.389    Count 10: 0.170  
Epoch [283] Batch [0/26] Loss: 0.0003 LR: 0.000100
Epoch [283] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [283] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [284/350] - Time: 4.09s
Train Loss: 0.0007 | Val Loss: 11.1103
Train Acc: 1.0000 | Val Acc: 0.4358
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.651    Count 3: 0.463    Count 4: 0.533    Count 5: 0.206  
  Count 6: 0.286    Count 7: 0.021    Count 8: 0.374    Count 9: 0.300    Count 10: 0.136  
Epoch [284] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [284] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [284] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [285/350] - Time: 3.98s
Train Loss: 0.0276 | Val Loss: 10.9190
Train Acc: 0.9975 | Val Acc: 0.4153
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.833    Count 2: 0.571    Count 3: 0.278    Count 4: 0.676    Count 5: 0.343  
  Count 6: 0.214    Count 7: 0.042    Count 8: 0.475    Count 9: 0.222    Count 10: 0.125  
Epoch [285] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [285] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [285] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [286/350] - Time: 4.02s
Train Loss: 0.0453 | Val Loss: 9.4577
Train Acc: 0.9951 | Val Acc: 0.4432
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.500    Count 3: 0.565    Count 4: 0.705    Count 5: 0.186  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.253    Count 9: 0.267    Count 10: 0.432  
Epoch [286] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [286] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [286] Batch [20/26] Loss: 0.0063 LR: 0.000100

Epoch [287/350] - Time: 4.05s
Train Loss: 0.0020 | Val Loss: 10.0455
Train Acc: 1.0000 | Val Acc: 0.4469
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.738    Count 3: 0.519    Count 4: 0.648    Count 5: 0.206  
  Count 6: 0.255    Count 7: 0.010    Count 8: 0.253    Count 9: 0.222    Count 10: 0.318  
Epoch [287] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [287] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [287] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [288/350] - Time: 3.99s
Train Loss: 0.1211 | Val Loss: 11.3607
Train Acc: 0.9730 | Val Acc: 0.4134
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.603    Count 3: 0.481    Count 4: 0.524    Count 5: 0.147  
  Count 6: 0.276    Count 7: 0.031    Count 8: 0.101    Count 9: 0.322    Count 10: 0.239  
Epoch [288] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [288] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [288] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [289/350] - Time: 4.02s
Train Loss: 0.0055 | Val Loss: 10.9574
Train Acc: 0.9975 | Val Acc: 0.4395
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.635    Count 3: 0.565    Count 4: 0.648    Count 5: 0.235  
  Count 6: 0.194    Count 7: 0.031    Count 8: 0.101    Count 9: 0.367    Count 10: 0.205  
Epoch [289] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [289] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [289] Batch [20/26] Loss: 0.0001 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [290/350] - Time: 4.24s
Train Loss: 0.0194 | Val Loss: 11.0359
Train Acc: 0.9975 | Val Acc: 0.4572
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.675    Count 3: 0.537    Count 4: 0.676    Count 5: 0.196  
  Count 6: 0.224    Count 7: 0.062    Count 8: 0.111    Count 9: 0.456    Count 10: 0.284  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_289.pth
Epoch [290] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [290] Batch [10/26] Loss: 0.0026 LR: 0.000100
Epoch [290] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [291/350] - Time: 3.98s
Train Loss: 0.0015 | Val Loss: 11.7532
Train Acc: 1.0000 | Val Acc: 0.4302
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.722    Count 3: 0.343    Count 4: 0.648    Count 5: 0.275  
  Count 6: 0.204    Count 7: 0.010    Count 8: 0.141    Count 9: 0.389    Count 10: 0.273  
Epoch [291] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [291] Batch [10/26] Loss: 0.6112 LR: 0.000100
Epoch [291] Batch [20/26] Loss: 0.0006 LR: 0.000100

Epoch [292/350] - Time: 4.11s
Train Loss: 0.0468 | Val Loss: 12.0929
Train Acc: 0.9926 | Val Acc: 0.4255
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.683    Count 3: 0.454    Count 4: 0.638    Count 5: 0.333  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.152    Count 9: 0.178    Count 10: 0.250  
Epoch [292] Batch [0/26] Loss: 0.4937 LR: 0.000100
Epoch [292] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [292] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [293/350] - Time: 4.08s
Train Loss: 0.0204 | Val Loss: 11.0069
Train Acc: 0.9975 | Val Acc: 0.4395
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.643    Count 3: 0.537    Count 4: 0.429    Count 5: 0.206  
  Count 6: 0.337    Count 7: 0.010    Count 8: 0.242    Count 9: 0.367    Count 10: 0.250  
Epoch [293] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [293] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [293] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [294/350] - Time: 4.10s
Train Loss: 0.0001 | Val Loss: 11.9326
Train Acc: 1.0000 | Val Acc: 0.4246
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.722    Count 3: 0.333    Count 4: 0.743    Count 5: 0.284  
  Count 6: 0.163    Count 7: 0.000    Count 8: 0.141    Count 9: 0.300    Count 10: 0.193  
Epoch [294] Batch [0/26] Loss: 0.6438 LR: 0.000100
Epoch [294] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [294] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [295/350] - Time: 4.01s
Train Loss: 0.0261 | Val Loss: 10.9794
Train Acc: 0.9975 | Val Acc: 0.4376
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.651    Count 3: 0.380    Count 4: 0.552    Count 5: 0.225  
  Count 6: 0.265    Count 7: 0.010    Count 8: 0.131    Count 9: 0.411    Count 10: 0.398  
Epoch [295] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [295] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [295] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [296/350] - Time: 4.07s
Train Loss: 0.0011 | Val Loss: 10.9639
Train Acc: 1.0000 | Val Acc: 0.4534
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.698    Count 3: 0.370    Count 4: 0.724    Count 5: 0.245  
  Count 6: 0.265    Count 7: 0.010    Count 8: 0.141    Count 9: 0.322    Count 10: 0.364  
Epoch [296] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [296] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [296] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [297/350] - Time: 4.06s
Train Loss: 0.0085 | Val Loss: 10.1724
Train Acc: 0.9975 | Val Acc: 0.4665
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.698    Count 3: 0.343    Count 4: 0.667    Count 5: 0.245  
  Count 6: 0.214    Count 7: 0.104    Count 8: 0.242    Count 9: 0.300    Count 10: 0.523  
Epoch [297] Batch [0/26] Loss: 0.0012 LR: 0.000100
Epoch [297] Batch [10/26] Loss: 0.0005 LR: 0.000100
Epoch [297] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [298/350] - Time: 4.24s
Train Loss: 0.0491 | Val Loss: 12.2871
Train Acc: 0.9975 | Val Acc: 0.4339
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.698    Count 3: 0.583    Count 4: 0.629    Count 5: 0.127  
  Count 6: 0.286    Count 7: 0.000    Count 8: 0.152    Count 9: 0.278    Count 10: 0.250  
Epoch [298] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [298] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [298] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [299/350] - Time: 4.07s
Train Loss: 0.0130 | Val Loss: 13.1215
Train Acc: 0.9975 | Val Acc: 0.4060
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.643    Count 3: 0.370    Count 4: 0.638    Count 5: 0.265  
  Count 6: 0.194    Count 7: 0.010    Count 8: 0.101    Count 9: 0.233    Count 10: 0.307  
Epoch [299] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [299] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [299] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [300/350] - Time: 4.03s
Train Loss: 0.0017 | Val Loss: 12.4244
Train Acc: 1.0000 | Val Acc: 0.4190
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.827    Count 2: 0.571    Count 3: 0.463    Count 4: 0.686    Count 5: 0.206  
  Count 6: 0.306    Count 7: 0.031    Count 8: 0.141    Count 9: 0.356    Count 10: 0.250  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_299.pth
Epoch [300] Batch [0/26] Loss: 0.4924 LR: 0.000100
Epoch [300] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [300] Batch [20/26] Loss: 0.0008 LR: 0.000100

Epoch [301/350] - Time: 4.07s
Train Loss: 0.0304 | Val Loss: 11.0913
Train Acc: 0.9951 | Val Acc: 0.4330
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.883    Count 2: 0.730    Count 3: 0.324    Count 4: 0.667    Count 5: 0.245  
  Count 6: 0.276    Count 7: 0.073    Count 8: 0.141    Count 9: 0.389    Count 10: 0.193  
Epoch [301] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [301] Batch [10/26] Loss: 0.0029 LR: 0.000100
Epoch [301] Batch [20/26] Loss: 0.0049 LR: 0.000100

Epoch [302/350] - Time: 4.00s
Train Loss: 0.0186 | Val Loss: 11.3601
Train Acc: 0.9975 | Val Acc: 0.4488
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.951    Count 2: 0.595    Count 3: 0.426    Count 4: 0.686    Count 5: 0.206  
  Count 6: 0.235    Count 7: 0.083    Count 8: 0.121    Count 9: 0.467    Count 10: 0.330  
Epoch [302] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [302] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [302] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [303/350] - Time: 4.02s
Train Loss: 0.0042 | Val Loss: 10.9381
Train Acc: 0.9975 | Val Acc: 0.4525
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.571    Count 3: 0.352    Count 4: 0.695    Count 5: 0.196  
  Count 6: 0.255    Count 7: 0.094    Count 8: 0.283    Count 9: 0.500    Count 10: 0.284  
Epoch [303] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [303] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [303] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [304/350] - Time: 4.08s
Train Loss: 0.0338 | Val Loss: 11.2933
Train Acc: 0.9951 | Val Acc: 0.4497
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.524    Count 3: 0.491    Count 4: 0.610    Count 5: 0.284  
  Count 6: 0.327    Count 7: 0.052    Count 8: 0.212    Count 9: 0.444    Count 10: 0.250  
Epoch [304] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [304] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [304] Batch [20/26] Loss: 0.0027 LR: 0.000100

Epoch [305/350] - Time: 4.03s
Train Loss: 0.0562 | Val Loss: 15.6637
Train Acc: 0.9902 | Val Acc: 0.3631
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.683    Count 3: 0.259    Count 4: 0.552    Count 5: 0.176  
  Count 6: 0.133    Count 7: 0.000    Count 8: 0.030    Count 9: 0.156    Count 10: 0.261  
Epoch [305] Batch [0/26] Loss: 0.1840 LR: 0.000100
Epoch [305] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [305] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [306/350] - Time: 4.26s
Train Loss: 0.0780 | Val Loss: 13.4788
Train Acc: 0.9779 | Val Acc: 0.4115
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.556    Count 3: 0.463    Count 4: 0.724    Count 5: 0.216  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.111    Count 9: 0.322    Count 10: 0.193  
Epoch [306] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [306] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [306] Batch [20/26] Loss: 0.0024 LR: 0.000100

Epoch [307/350] - Time: 4.01s
Train Loss: 0.0125 | Val Loss: 11.2967
Train Acc: 0.9975 | Val Acc: 0.4488
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.975    Count 2: 0.595    Count 3: 0.417    Count 4: 0.638    Count 5: 0.196  
  Count 6: 0.245    Count 7: 0.042    Count 8: 0.343    Count 9: 0.378    Count 10: 0.239  
Epoch [307] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [307] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [307] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [308/350] - Time: 4.02s
Train Loss: 0.0017 | Val Loss: 12.0999
Train Acc: 1.0000 | Val Acc: 0.4376
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.635    Count 3: 0.417    Count 4: 0.629    Count 5: 0.353  
  Count 6: 0.173    Count 7: 0.042    Count 8: 0.081    Count 9: 0.322    Count 10: 0.318  
Epoch [308] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [308] Batch [10/26] Loss: 0.2923 LR: 0.000100
Epoch [308] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [309/350] - Time: 4.13s
Train Loss: 0.0133 | Val Loss: 11.4562
Train Acc: 0.9975 | Val Acc: 0.4451
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.643    Count 3: 0.472    Count 4: 0.600    Count 5: 0.392  
  Count 6: 0.296    Count 7: 0.031    Count 8: 0.040    Count 9: 0.278    Count 10: 0.330  
Epoch [309] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [309] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [309] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [310/350] - Time: 3.99s
Train Loss: 0.0004 | Val Loss: 11.7863
Train Acc: 1.0000 | Val Acc: 0.4534
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.500    Count 3: 0.685    Count 4: 0.419    Count 5: 0.333  
  Count 6: 0.429    Count 7: 0.021    Count 8: 0.081    Count 9: 0.433    Count 10: 0.318  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_309.pth
Epoch [310] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [310] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [310] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [311/350] - Time: 3.93s
Train Loss: 0.0137 | Val Loss: 11.6132
Train Acc: 0.9975 | Val Acc: 0.4609
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.540    Count 3: 0.528    Count 4: 0.524    Count 5: 0.422  
  Count 6: 0.337    Count 7: 0.052    Count 8: 0.152    Count 9: 0.433    Count 10: 0.318  
Epoch [311] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [311] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [311] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [312/350] - Time: 4.01s
Train Loss: 0.0033 | Val Loss: 12.4186
Train Acc: 0.9975 | Val Acc: 0.4181
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.981    Count 2: 0.476    Count 3: 0.407    Count 4: 0.619    Count 5: 0.284  
  Count 6: 0.265    Count 7: 0.010    Count 8: 0.101    Count 9: 0.356    Count 10: 0.261  
Epoch [312] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [312] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [312] Batch [20/26] Loss: 0.3952 LR: 0.000100

Epoch [313/350] - Time: 4.08s
Train Loss: 0.0248 | Val Loss: 12.1163
Train Acc: 0.9926 | Val Acc: 0.4050
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.981    Count 2: 0.556    Count 3: 0.426    Count 4: 0.467    Count 5: 0.137  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.091    Count 9: 0.344    Count 10: 0.364  
Epoch [313] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [313] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [313] Batch [20/26] Loss: 0.0060 LR: 0.000100

Epoch [314/350] - Time: 4.06s
Train Loss: 0.0027 | Val Loss: 12.6251
Train Acc: 0.9975 | Val Acc: 0.4143
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.540    Count 3: 0.620    Count 4: 0.448    Count 5: 0.088  
  Count 6: 0.367    Count 7: 0.000    Count 8: 0.121    Count 9: 0.311    Count 10: 0.250  
Epoch [314] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [314] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [314] Batch [20/26] Loss: 0.0007 LR: 0.000100

Epoch [315/350] - Time: 4.30s
Train Loss: 0.0077 | Val Loss: 12.8040
Train Acc: 0.9975 | Val Acc: 0.4199
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.957    Count 2: 0.532    Count 3: 0.454    Count 4: 0.752    Count 5: 0.275  
  Count 6: 0.276    Count 7: 0.010    Count 8: 0.111    Count 9: 0.156    Count 10: 0.227  
Epoch [315] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [315] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [315] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [316/350] - Time: 4.05s
Train Loss: 0.0438 | Val Loss: 11.1149
Train Acc: 0.9926 | Val Acc: 0.4078
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.914    Count 2: 0.556    Count 3: 0.333    Count 4: 0.676    Count 5: 0.333  
  Count 6: 0.296    Count 7: 0.000    Count 8: 0.141    Count 9: 0.189    Count 10: 0.216  
Epoch [316] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [316] Batch [10/26] Loss: 0.0007 LR: 0.000100
Epoch [316] Batch [20/26] Loss: 0.0023 LR: 0.000100

Epoch [317/350] - Time: 4.03s
Train Loss: 0.0078 | Val Loss: 10.8169
Train Acc: 0.9975 | Val Acc: 0.4395
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.963    Count 2: 0.690    Count 3: 0.454    Count 4: 0.524    Count 5: 0.196  
  Count 6: 0.235    Count 7: 0.042    Count 8: 0.202    Count 9: 0.278    Count 10: 0.375  
Epoch [317] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [317] Batch [10/26] Loss: 0.0006 LR: 0.000100
Epoch [317] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [318/350] - Time: 4.07s
Train Loss: 0.0248 | Val Loss: 13.9891
Train Acc: 0.9975 | Val Acc: 0.4004
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.587    Count 3: 0.324    Count 4: 0.762    Count 5: 0.373  
  Count 6: 0.194    Count 7: 0.000    Count 8: 0.091    Count 9: 0.078    Count 10: 0.170  
Epoch [318] Batch [0/26] Loss: 0.0002 LR: 0.000100
Epoch [318] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [318] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [319/350] - Time: 4.03s
Train Loss: 0.0124 | Val Loss: 11.4279
Train Acc: 0.9975 | Val Acc: 0.4618
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.556    Count 3: 0.481    Count 4: 0.695    Count 5: 0.206  
  Count 6: 0.316    Count 7: 0.083    Count 8: 0.263    Count 9: 0.344    Count 10: 0.352  
Epoch [319] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [319] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [319] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [320/350] - Time: 4.19s
Train Loss: 0.0001 | Val Loss: 12.0075
Train Acc: 1.0000 | Val Acc: 0.4553
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.548    Count 3: 0.556    Count 4: 0.667    Count 5: 0.196  
  Count 6: 0.337    Count 7: 0.031    Count 8: 0.263    Count 9: 0.389    Count 10: 0.239  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_319.pth
Epoch [320] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [320] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [320] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [321/350] - Time: 4.09s
Train Loss: 0.0001 | Val Loss: 11.3901
Train Acc: 1.0000 | Val Acc: 0.4367
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.603    Count 3: 0.250    Count 4: 0.771    Count 5: 0.275  
  Count 6: 0.255    Count 7: 0.104    Count 8: 0.263    Count 9: 0.344    Count 10: 0.284  
Epoch [321] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [321] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [321] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [322/350] - Time: 4.19s
Train Loss: 0.0002 | Val Loss: 12.4068
Train Acc: 1.0000 | Val Acc: 0.4292
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.969    Count 2: 0.587    Count 3: 0.426    Count 4: 0.543    Count 5: 0.137  
  Count 6: 0.357    Count 7: 0.052    Count 8: 0.172    Count 9: 0.400    Count 10: 0.227  
Epoch [322] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [322] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [322] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [323/350] - Time: 4.23s
Train Loss: 0.0103 | Val Loss: 14.6274
Train Acc: 0.9975 | Val Acc: 0.3920
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.821    Count 2: 0.667    Count 3: 0.278    Count 4: 0.714    Count 5: 0.333  
  Count 6: 0.255    Count 7: 0.000    Count 8: 0.091    Count 9: 0.144    Count 10: 0.205  
Epoch [323] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [323] Batch [10/26] Loss: 0.2494 LR: 0.000100
Epoch [323] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [324/350] - Time: 4.03s
Train Loss: 0.0099 | Val Loss: 12.9519
Train Acc: 0.9975 | Val Acc: 0.4190
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.920    Count 2: 0.595    Count 3: 0.370    Count 4: 0.476    Count 5: 0.373  
  Count 6: 0.306    Count 7: 0.010    Count 8: 0.222    Count 9: 0.278    Count 10: 0.227  
Epoch [324] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [324] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [324] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [325/350] - Time: 4.03s
Train Loss: 0.0758 | Val Loss: 12.2730
Train Acc: 0.9926 | Val Acc: 0.4460
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.571    Count 3: 0.361    Count 4: 0.600    Count 5: 0.392  
  Count 6: 0.255    Count 7: 0.042    Count 8: 0.384    Count 9: 0.278    Count 10: 0.295  
Epoch [325] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [325] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [325] Batch [20/26] Loss: 0.0002 LR: 0.000100

Epoch [326/350] - Time: 4.10s
Train Loss: 0.0084 | Val Loss: 12.0846
Train Acc: 0.9975 | Val Acc: 0.4199
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.864    Count 2: 0.524    Count 3: 0.407    Count 4: 0.524    Count 5: 0.363  
  Count 6: 0.194    Count 7: 0.021    Count 8: 0.414    Count 9: 0.267    Count 10: 0.261  
Epoch [326] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [326] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [326] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [327/350] - Time: 4.00s
Train Loss: 0.0132 | Val Loss: 12.3681
Train Acc: 0.9951 | Val Acc: 0.4469
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.603    Count 3: 0.426    Count 4: 0.657    Count 5: 0.333  
  Count 6: 0.255    Count 7: 0.010    Count 8: 0.303    Count 9: 0.222    Count 10: 0.307  
Epoch [327] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [327] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [327] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [328/350] - Time: 4.07s
Train Loss: 0.0154 | Val Loss: 12.6358
Train Acc: 0.9975 | Val Acc: 0.4199
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.846    Count 2: 0.683    Count 3: 0.389    Count 4: 0.524    Count 5: 0.235  
  Count 6: 0.235    Count 7: 0.010    Count 8: 0.253    Count 9: 0.344    Count 10: 0.307  
Epoch [328] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [328] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [328] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [329/350] - Time: 4.00s
Train Loss: 0.0387 | Val Loss: 12.4699
Train Acc: 0.9926 | Val Acc: 0.4106
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.907    Count 2: 0.603    Count 3: 0.417    Count 4: 0.381    Count 5: 0.186  
  Count 6: 0.286    Count 7: 0.010    Count 8: 0.242    Count 9: 0.444    Count 10: 0.239  
Epoch [329] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [329] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [329] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [330/350] - Time: 4.06s
Train Loss: 0.0028 | Val Loss: 12.1736
Train Acc: 0.9975 | Val Acc: 0.4413
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.858    Count 2: 0.508    Count 3: 0.389    Count 4: 0.600    Count 5: 0.216  
  Count 6: 0.316    Count 7: 0.073    Count 8: 0.424    Count 9: 0.378    Count 10: 0.341  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_329.pth
Epoch [330] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [330] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [330] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [331/350] - Time: 4.28s
Train Loss: 0.0175 | Val Loss: 12.5579
Train Acc: 0.9975 | Val Acc: 0.4218
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.556    Count 3: 0.361    Count 4: 0.724    Count 5: 0.284  
  Count 6: 0.184    Count 7: 0.062    Count 8: 0.313    Count 9: 0.333    Count 10: 0.114  
Epoch [331] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [331] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [331] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [332/350] - Time: 4.01s
Train Loss: 0.0001 | Val Loss: 12.6163
Train Acc: 1.0000 | Val Acc: 0.4507
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.484    Count 3: 0.444    Count 4: 0.571    Count 5: 0.186  
  Count 6: 0.327    Count 7: 0.062    Count 8: 0.444    Count 9: 0.556    Count 10: 0.159  
Epoch [332] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [332] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [332] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [333/350] - Time: 4.08s
Train Loss: 0.0000 | Val Loss: 12.6113
Train Acc: 1.0000 | Val Acc: 0.4264
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.532    Count 3: 0.435    Count 4: 0.648    Count 5: 0.216  
  Count 6: 0.265    Count 7: 0.031    Count 8: 0.313    Count 9: 0.411    Count 10: 0.125  
Epoch [333] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [333] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [333] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [334/350] - Time: 3.94s
Train Loss: 0.0000 | Val Loss: 12.4908
Train Acc: 1.0000 | Val Acc: 0.4236
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.532    Count 3: 0.426    Count 4: 0.648    Count 5: 0.216  
  Count 6: 0.265    Count 7: 0.031    Count 8: 0.303    Count 9: 0.400    Count 10: 0.125  
Epoch [334] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [334] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [334] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [335/350] - Time: 4.00s
Train Loss: 0.0000 | Val Loss: 12.4815
Train Acc: 1.0000 | Val Acc: 0.4246
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.532    Count 3: 0.426    Count 4: 0.648    Count 5: 0.225  
  Count 6: 0.245    Count 7: 0.031    Count 8: 0.313    Count 9: 0.411    Count 10: 0.125  
Epoch [335] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [335] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [335] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [336/350] - Time: 4.11s
Train Loss: 0.0001 | Val Loss: 11.8012
Train Acc: 1.0000 | Val Acc: 0.4469
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.895    Count 2: 0.476    Count 3: 0.444    Count 4: 0.619    Count 5: 0.353  
  Count 6: 0.296    Count 7: 0.062    Count 8: 0.434    Count 9: 0.411    Count 10: 0.125  
Epoch [336] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [336] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [336] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [337/350] - Time: 3.98s
Train Loss: 0.0009 | Val Loss: 13.5273
Train Acc: 1.0000 | Val Acc: 0.4181
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.889    Count 2: 0.762    Count 3: 0.352    Count 4: 0.686    Count 5: 0.294  
  Count 6: 0.122    Count 7: 0.021    Count 8: 0.152    Count 9: 0.200    Count 10: 0.250  
Epoch [337] Batch [0/26] Loss: 0.0001 LR: 0.000100
Epoch [337] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [337] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [338/350] - Time: 3.91s
Train Loss: 0.0241 | Val Loss: 11.6639
Train Acc: 0.9951 | Val Acc: 0.4516
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.901    Count 2: 0.508    Count 3: 0.491    Count 4: 0.562    Count 5: 0.353  
  Count 6: 0.276    Count 7: 0.031    Count 8: 0.354    Count 9: 0.344    Count 10: 0.352  
Epoch [338] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [338] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [338] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [339/350] - Time: 4.13s
Train Loss: 0.0000 | Val Loss: 11.8813
Train Acc: 1.0000 | Val Acc: 0.4562
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.587    Count 3: 0.407    Count 4: 0.619    Count 5: 0.324  
  Count 6: 0.245    Count 7: 0.031    Count 8: 0.333    Count 9: 0.344    Count 10: 0.352  
Epoch [339] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [339] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [339] Batch [20/26] Loss: 0.0000 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [340/350] - Time: 3.87s
Train Loss: 0.0000 | Val Loss: 11.8616
Train Acc: 1.0000 | Val Acc: 0.4553
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.611    Count 3: 0.407    Count 4: 0.629    Count 5: 0.304  
  Count 6: 0.245    Count 7: 0.031    Count 8: 0.323    Count 9: 0.322    Count 10: 0.352  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_339.pth
Epoch [340] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [340] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [340] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [341/350] - Time: 3.97s
Train Loss: 0.0000 | Val Loss: 11.8178
Train Acc: 1.0000 | Val Acc: 0.4562
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.595    Count 3: 0.417    Count 4: 0.629    Count 5: 0.304  
  Count 6: 0.245    Count 7: 0.031    Count 8: 0.333    Count 9: 0.322    Count 10: 0.364  
Epoch [341] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [341] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [341] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [342/350] - Time: 3.99s
Train Loss: 0.0002 | Val Loss: 13.2561
Train Acc: 1.0000 | Val Acc: 0.4348
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.858    Count 2: 0.714    Count 3: 0.278    Count 4: 0.705    Count 5: 0.382  
  Count 6: 0.214    Count 7: 0.052    Count 8: 0.131    Count 9: 0.311    Count 10: 0.318  
Epoch [342] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [342] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [342] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [343/350] - Time: 4.01s
Train Loss: 0.0086 | Val Loss: 12.9532
Train Acc: 0.9975 | Val Acc: 0.4320
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.944    Count 2: 0.524    Count 3: 0.380    Count 4: 0.667    Count 5: 0.333  
  Count 6: 0.286    Count 7: 0.031    Count 8: 0.111    Count 9: 0.322    Count 10: 0.330  
Epoch [343] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [343] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [343] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [344/350] - Time: 3.94s
Train Loss: 0.0023 | Val Loss: 14.8037
Train Acc: 0.9975 | Val Acc: 0.3752
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.802    Count 2: 0.619    Count 3: 0.491    Count 4: 0.524    Count 5: 0.127  
  Count 6: 0.235    Count 7: 0.000    Count 8: 0.101    Count 9: 0.211    Count 10: 0.250  
Epoch [344] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [344] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [344] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [345/350] - Time: 4.01s
Train Loss: 0.0395 | Val Loss: 12.7519
Train Acc: 0.9902 | Val Acc: 0.3929
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.790    Count 2: 0.508    Count 3: 0.398    Count 4: 0.657    Count 5: 0.284  
  Count 6: 0.337    Count 7: 0.000    Count 8: 0.212    Count 9: 0.200    Count 10: 0.193  
Epoch [345] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [345] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [345] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [346/350] - Time: 4.01s
Train Loss: 0.1612 | Val Loss: 12.0955
Train Acc: 0.9779 | Val Acc: 0.4451
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.877    Count 2: 0.690    Count 3: 0.500    Count 4: 0.505    Count 5: 0.216  
  Count 6: 0.327    Count 7: 0.042    Count 8: 0.192    Count 9: 0.456    Count 10: 0.273  
Epoch [346] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [346] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [346] Batch [20/26] Loss: 0.0001 LR: 0.000100

Epoch [347/350] - Time: 4.35s
Train Loss: 0.0328 | Val Loss: 11.8448
Train Acc: 0.9902 | Val Acc: 0.4646
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.957    Count 2: 0.571    Count 3: 0.491    Count 4: 0.533    Count 5: 0.127  
  Count 6: 0.388    Count 7: 0.094    Count 8: 0.141    Count 9: 0.356    Count 10: 0.648  
Epoch [347] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [347] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [347] Batch [20/26] Loss: 0.0029 LR: 0.000100

Epoch [348/350] - Time: 4.06s
Train Loss: 0.0411 | Val Loss: 11.3111
Train Acc: 0.9853 | Val Acc: 0.4255
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.926    Count 2: 0.635    Count 3: 0.472    Count 4: 0.686    Count 5: 0.118  
  Count 6: 0.276    Count 7: 0.031    Count 8: 0.202    Count 9: 0.233    Count 10: 0.239  
Epoch [348] Batch [0/26] Loss: 0.0000 LR: 0.000100
Epoch [348] Batch [10/26] Loss: 0.0001 LR: 0.000100
Epoch [348] Batch [20/26] Loss: 0.0000 LR: 0.000100

Epoch [349/350] - Time: 4.10s
Train Loss: 0.0375 | Val Loss: 11.5558
Train Acc: 0.9926 | Val Acc: 0.4609
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.938    Count 2: 0.548    Count 3: 0.426    Count 4: 0.667    Count 5: 0.147  
  Count 6: 0.337    Count 7: 0.062    Count 8: 0.354    Count 9: 0.356    Count 10: 0.420  
Epoch [349] Batch [0/26] Loss: 0.0012 LR: 0.000100
Epoch [349] Batch [10/26] Loss: 0.0000 LR: 0.000100
Epoch [349] Batch [20/26] Loss: 0.3225 LR: 0.000100
/net/scratch/k09562zs/Ball_counting_CNN/Train_single_image.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_checkpoint = torch.load(temp_path, map_location='cpu')

Epoch [350/350] - Time: 4.13s
Train Loss: 0.0180 | Val Loss: 12.2448
Train Acc: 0.9951 | Val Acc: 0.4413
Learning Rate: 0.000100
Per-class validation accuracy:
  Count 1: 0.932    Count 2: 0.484    Count 3: 0.333    Count 4: 0.695    Count 5: 0.176  
  Count 6: 0.388    Count 7: 0.052    Count 8: 0.222    Count 9: 0.511    Count 10: 0.273  
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/single_image_checkpoint_epoch_349.pth
✓ Checkpoint saved and validated: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/final_single_image_model.pth

训练完成!
最佳验证准确率: 0.5242
最佳验证损失: 2.4137
最终混淆矩阵保存到: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/final_confusion_matrix.png
详细报告保存到: ./scratch/Ball_counting_CNN/Final_result/Visual_CNN_only/10data/check_points/classification_report.txt

训练成功完成！
程序结束。
=== 完成 ===
结束时间: Sun 20 Jul 18:09:19 BST 2025
